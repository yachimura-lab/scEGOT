{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scegot import scEGOT\n",
    "import wot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scEGOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_INPUT_ROOT_PATH = \"../data/\"\n",
    "ANNDATA_DATASET_PATH = os.path.join(\n",
    "    DATASET_INPUT_ROOT_PATH, \"scRNAseq_hPGCLC_induction_Saitou.h5ad\"\n",
    ")\n",
    "# CSV_DATASET_FOLDER_PATH = os.path.join(DATASET_INPUT_ROOT_PATH, \"csv_folder/\")\n",
    "RANDOM_STATE = 2023\n",
    "PCA_N_COMPONENTS = 150\n",
    "GMM_CLUSTER_NUMBERS = [1, 2, 4, 5, 5]\n",
    "UMAP_N_NEIGHBORS = 1000\n",
    "DAY_NAMES = [\"day0\", \"day0.5\", \"day1\", \"day1.5\", \"day2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 11771 × 18922\n",
      "    obs: 'sample', 'percent.mito', 'day', 'cluster_day'\n",
      "    var: 'spliced', 'unspliced', 'mt', 'TF', 'gene_name'\n",
      "    layers: 'X_raw', 'spliced', 'unspliced'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<11771x18922 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 94477374 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>percent.mito</th>\n",
       "      <th>day</th>\n",
       "      <th>cluster_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iM.data_GTGGAAGGTCAATGGG-1</th>\n",
       "      <td>iM.data</td>\n",
       "      <td>0.056487</td>\n",
       "      <td>iM</td>\n",
       "      <td>day0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iM.data_TTCATGTCAACCCGCA-1</th>\n",
       "      <td>iM.data</td>\n",
       "      <td>0.216231</td>\n",
       "      <td>iM</td>\n",
       "      <td>day0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iM.data_GAGGGTATCCAGGACC-1</th>\n",
       "      <td>iM.data</td>\n",
       "      <td>0.076525</td>\n",
       "      <td>iM</td>\n",
       "      <td>day0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iM.data_AAGTCGTAGGCTTTCA-1</th>\n",
       "      <td>iM.data</td>\n",
       "      <td>0.080264</td>\n",
       "      <td>iM</td>\n",
       "      <td>day0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iM.data_ACCGTTCGTAACTTCG-1</th>\n",
       "      <td>iM.data</td>\n",
       "      <td>0.280788</td>\n",
       "      <td>iM</td>\n",
       "      <td>day0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2b.data_AAGCCATAGGGCGAGA-1</th>\n",
       "      <td>d2b.data</td>\n",
       "      <td>4.811476</td>\n",
       "      <td>d2b</td>\n",
       "      <td>day2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2b.data_CAACCAATCTTCCGTG-1</th>\n",
       "      <td>d2b.data</td>\n",
       "      <td>2.554428</td>\n",
       "      <td>d2b</td>\n",
       "      <td>day2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2b.data_AGGCCACGTGAGTAGC-1</th>\n",
       "      <td>d2b.data</td>\n",
       "      <td>3.142146</td>\n",
       "      <td>d2b</td>\n",
       "      <td>day2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2b.data_GATCAGTTCGAGTACT-1</th>\n",
       "      <td>d2b.data</td>\n",
       "      <td>4.287140</td>\n",
       "      <td>d2b</td>\n",
       "      <td>day2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2b.data_TCATCCGTCATGGGAG-1</th>\n",
       "      <td>d2b.data</td>\n",
       "      <td>2.835834</td>\n",
       "      <td>d2b</td>\n",
       "      <td>day2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11771 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sample  percent.mito  day cluster_day\n",
       "iM.data_GTGGAAGGTCAATGGG-1    iM.data      0.056487   iM        day0\n",
       "iM.data_TTCATGTCAACCCGCA-1    iM.data      0.216231   iM        day0\n",
       "iM.data_GAGGGTATCCAGGACC-1    iM.data      0.076525   iM        day0\n",
       "iM.data_AAGTCGTAGGCTTTCA-1    iM.data      0.080264   iM        day0\n",
       "iM.data_ACCGTTCGTAACTTCG-1    iM.data      0.280788   iM        day0\n",
       "...                               ...           ...  ...         ...\n",
       "d2b.data_AAGCCATAGGGCGAGA-1  d2b.data      4.811476  d2b        day2\n",
       "d2b.data_CAACCAATCTTCCGTG-1  d2b.data      2.554428  d2b        day2\n",
       "d2b.data_AGGCCACGTGAGTAGC-1  d2b.data      3.142146  d2b        day2\n",
       "d2b.data_GATCAGTTCGAGTACT-1  d2b.data      4.287140  d2b        day2\n",
       "d2b.data_TCATCCGTCATGGGAG-1  d2b.data      2.835834  d2b        day2\n",
       "\n",
       "[11771 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spliced</th>\n",
       "      <th>unspliced</th>\n",
       "      <th>mt</th>\n",
       "      <th>TF</th>\n",
       "      <th>gene_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FAM3A</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FAM3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLC25A1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SLC25A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBL1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RBL1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPP2R1A</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PPP2R1A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H3F3B</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>H3F3B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR2W5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OR2W5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ODF4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ODF4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRP</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KRTAP4-9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>KRTAP4-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THEMIS</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>THEMIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18922 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          spliced  unspliced  mt  TF gene_name\n",
       "FAM3A           1          1   0   0     FAM3A\n",
       "SLC25A1         1          1   0   0   SLC25A1\n",
       "RBL1            1          1   0   0      RBL1\n",
       "PPP2R1A         1          1   0   0   PPP2R1A\n",
       "H3F3B           1          1   0   0     H3F3B\n",
       "...           ...        ...  ..  ..       ...\n",
       "OR2W5           1          0   0   0     OR2W5\n",
       "ODF4            1          1   0   0      ODF4\n",
       "CRP             1          0   0   0       CRP\n",
       "KRTAP4-9        1          0   0   0  KRTAP4-9\n",
       "THEMIS          1          1   0   0    THEMIS\n",
       "\n",
       "[18922 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----- In the case of AnnData -----\n",
    "input_data = anndata.read_h5ad(ANNDATA_DATASET_PATH)\n",
    "print(input_data)\n",
    "display(input_data.X)\n",
    "display(input_data.obs)\n",
    "display(input_data.var)\n",
    "\n",
    "# ----- In the case of DataFrame (CSV) -----\n",
    "# input_file_paths = sorted(glob.glob(f\"{CSV_DATASET_FOLDER_PATH}*.csv\"))\n",
    "# input_data = [\n",
    "#     pd.read_csv(input_file_path, index_col=0) for input_file_path in input_file_paths\n",
    "# ]\n",
    "# print(f\"number of days: {len(input_data)}\")\n",
    "# print(\"shape of each day's data:\")\n",
    "# for i, data in enumerate(input_data):\n",
    "#     print(f\"    {DAY_NAMES[i]}: {data.shape}\")\n",
    "# print(\"data example: \")\n",
    "# input_data[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AnnData...\n"
     ]
    }
   ],
   "source": [
    "# ----- In the case of AnnData -----\n",
    "scegot = scEGOT(\n",
    "    input_data,\n",
    "    verbose=True,  # default=True\n",
    "    adata_day_key=\"cluster_day\",\n",
    ")\n",
    "\n",
    "# ----- In the case of DataFrame (CSV) -----\n",
    "# scegot = scEGOT(\n",
    "#     input_data,\n",
    "#     verbose=True,  # default=True\n",
    "#     day_names=DAY_NAMES, # uncomment this line if you use an array of DataFrames\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying RECODE...\n",
      "start RECODE for scRNA-seq data\n",
      "end RECODE for scRNA-seq\n",
      "log: {'seq_target': 'RNA', '#significant genes': 15820, '#non-significant genes': 2582, '#silent genes': 65, 'ell': 288, 'Elapsed time': '0h 0m 22s 061ms', 'solver': 'randomized', '#test_data': 2354}\n",
      "Applying UMI normalization...\n",
      "Applying log1p normalization...\n",
      "Applying PCA...\n",
      "\tsum of explained_variance_ratio = 93.67122272048897\n",
      "CPU times: user 1min 39s, sys: 17 s, total: 1min 56s\n",
      "Wall time: 31.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, pca_model = scegot.preprocess(\n",
    "    PCA_N_COMPONENTS,\n",
    "    recode_params={},\n",
    "    umi_target_sum=1e5,\n",
    "    pca_random_state=RANDOM_STATE,\n",
    "    pca_other_params={},\n",
    "    apply_recode=True,\n",
    "    apply_normalization_log1p=True,\n",
    "    apply_normalization_umi=True,\n",
    "    select_genes=True,\n",
    "    n_select_genes=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GMM models with each day's data and predicting labels for them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:17<00:00,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 1min 15s, total: 2min 41s\n",
      "Wall time: 17.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gmm_models, gmm_labels = scegot.fit_predict_gmm(\n",
    "    n_components_list=GMM_CLUSTER_NUMBERS,\n",
    "    covariance_type=\"full\",\n",
    "    max_iter=2000,\n",
    "    n_init=10,\n",
    "    random_state=RANDOM_STATE,\n",
    "    gmm_other_params={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.76 s, sys: 1.03 s, total: 10.8 s\n",
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scegot_ot_times = []\n",
    "for i in range(len(scegot.day_names) - 1):\n",
    "    start_time = time.time()\n",
    "    scegot.calculate_solution(\n",
    "        scegot.gmm_models[i],\n",
    "        scegot.gmm_models[i + 1],\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    scegot_ot_times.append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLE_COORDS_PATH = \"../data/wot/fle_coords.txt\"\n",
    "FULL_DS_PATH = \"../data/wot/ExprMatrix.h5ad\"\n",
    "# VAR_DS_PATH = 'data/ExprMatrix.var.genes.h5ad'\n",
    "CELL_DAYS_PATH = \"../data/wot/cell_days.txt\"\n",
    "GENE_SETS_PATH = \"../data/wot/gene_sets.gmx\"\n",
    "GENE_SET_SCORES_PATH = \"output/gene_set_scores.csv\"\n",
    "CELL_SETS_PATH = \"../data/wot/cell_sets.pkl\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_df = pd.read_csv(FLE_COORDS_PATH, index_col=\"id\", sep=\"\\t\")\n",
    "days_df = pd.read_csv(CELL_DAYS_PATH, index_col=\"id\", sep=\"\\t\")\n",
    "\n",
    "# Read expression matrix, cell days, and 2-d coordinates\n",
    "adata = wot.io.read_dataset(FULL_DS_PATH, obs=[days_df, coord_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = wot.io.read_sets(GENE_SETS_PATH, adata.var.index.values)\n",
    "gene_set_scores_df = pd.DataFrame(index=adata.obs.index)\n",
    "for j in range(gs.shape[1]):\n",
    "    gene_set_name = str(gs.var.index.values[j])\n",
    "    result = wot.score_gene_sets(\n",
    "        ds=adata, gs=gs[:, [j]], permutations=0, method=\"mean_z_score\"\n",
    "    )\n",
    "    gene_set_scores_df[gene_set_name] = result[\"score\"]\n",
    "gene_set_scores_df.to_csv(GENE_SET_SCORES_PATH, index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load proliferation and apoptosis scores\n",
    "gene_set_scores = pd.read_csv(\"output/gene_set_scores.csv\", index_col=0)\n",
    "proliferation = gene_set_scores[\"Cell.cycle\"]\n",
    "apoptosis = gene_set_scores[\"Apoptosis\"]\n",
    "\n",
    "\n",
    "# apply logistic function to transform to birth rate and death rate\n",
    "def logistic(x, L, k, x0=0):\n",
    "    f = L / (1 + np.exp(-k * (x - x0)))\n",
    "    return f\n",
    "\n",
    "\n",
    "def gen_logistic(p, beta_max, beta_min, pmax, pmin, center, width):\n",
    "    return beta_min + logistic(p, L=beta_max - beta_min, k=4 / width, x0=center)\n",
    "\n",
    "\n",
    "def beta(p, beta_max=1.7, beta_min=0.3, pmax=1.0, pmin=-0.5, center=0.25):\n",
    "    return gen_logistic(p, beta_max, beta_min, pmax, pmin, center, width=0.5)\n",
    "\n",
    "\n",
    "def delta(a, delta_max=1.7, delta_min=0.3, amax=0.5, amin=-0.4, center=0.1):\n",
    "    return gen_logistic(a, delta_max, delta_min, amax, amin, center, width=0.2)\n",
    "\n",
    "\n",
    "birth = beta(proliferation)\n",
    "death = delta(apoptosis)\n",
    "\n",
    "# growth rate is given by\n",
    "gr = np.exp(birth - death)\n",
    "growth_rates_df = pd.DataFrame(\n",
    "    index=gene_set_scores.index, data={\"cell_growth_rate\": gr}\n",
    ")\n",
    "growth_rates_df.to_csv(\"output/growth_gs_init.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7208, 2000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAR_GENE_DS_PATH = \"../data/wot/ExprMatrix.var.genes.h5ad\"\n",
    "SERUM_CELL_IDS_PATH = \"../data/wot/pgclc_cell_ids.txt\"\n",
    "CELL_GROWTH_PATH = \"output/growth_gs_init.txt\"\n",
    "\n",
    "# load data\n",
    "adata = wot.io.read_dataset(\n",
    "    VAR_GENE_DS_PATH,\n",
    "    obs=[CELL_DAYS_PATH, CELL_GROWTH_PATH],\n",
    "    obs_filter=SERUM_CELL_IDS_PATH,\n",
    ")\n",
    "adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_model = wot.ot.OTModel(\n",
    "    adata,\n",
    "    local_pca=PCA_N_COMPONENTS,\n",
    "    solver=\"fixed_iters\",\n",
    "    epsilon=0.01,\n",
    "    lambda1=1,\n",
    "    lambda2=50,\n",
    "    tau=1e8,\n",
    "    inner_iter_max=1e10,\n",
    "    growth_iters=3,\n",
    ")\n",
    "day_names_float = [0, 0.5, 1, 1.5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 46s, sys: 5min 54s, total: 31min 41s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wot_ot_times = []\n",
    "for i in range(len(day_names_float) - 1):\n",
    "    start_time = time.time()\n",
    "    tmap_annotated = ot_model.compute_transport_map(\n",
    "        day_names_float[i], day_names_float[i + 1]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    wot_ot_times.append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrajectoryNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/opt/anaconda3/lib/python3.11/site-packages/TrajectoryNet/main.py\n",
      "\"\"\" main.py\n",
      "\n",
      "Learns ODE from scrna data\n",
      "\n",
      "\"\"\"\n",
      "import os\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import time\n",
      "\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "\n",
      "from TrajectoryNet.lib.growth_net import GrowthNet\n",
      "from TrajectoryNet.lib import utils\n",
      "from TrajectoryNet.lib.visualize_flow import visualize_transform\n",
      "from TrajectoryNet.lib.viz_scrna import (\n",
      "    save_trajectory,\n",
      "    trajectory_to_video,\n",
      "    save_vectors,\n",
      ")\n",
      "from TrajectoryNet.lib.viz_scrna import save_trajectory_density\n",
      "\n",
      "\n",
      "# from train_misc import standard_normal_logprob\n",
      "from TrajectoryNet.train_misc import (\n",
      "    set_cnf_options,\n",
      "    count_nfe,\n",
      "    count_parameters,\n",
      "    count_total_time,\n",
      "    add_spectral_norm,\n",
      "    spectral_norm_power_iteration,\n",
      "    create_regularization_fns,\n",
      "    get_regularization,\n",
      "    append_regularization_to_log,\n",
      "    build_model_tabular,\n",
      ")\n",
      "\n",
      "from TrajectoryNet import dataset\n",
      "from TrajectoryNet.parse import parser\n",
      "\n",
      "matplotlib.use(\"Agg\")\n",
      "\n",
      "\n",
      "def get_transforms(device, args, model, integration_times):\n",
      "    \"\"\"\n",
      "    Given a list of integration points,\n",
      "    returns a function giving integration times\n",
      "    \"\"\"\n",
      "\n",
      "    def sample_fn(z, logpz=None):\n",
      "        int_list = [\n",
      "            torch.tensor([it - args.time_scale, it]).type(torch.float32).to(device)\n",
      "            for it in integration_times\n",
      "        ]\n",
      "        if logpz is not None:\n",
      "            # TODO this works right?\n",
      "            for it in int_list:\n",
      "                z, logpz = model(z, logpz, integration_times=it, reverse=True)\n",
      "            return z, logpz\n",
      "        else:\n",
      "            for it in int_list:\n",
      "                z = model(z, integration_times=it, reverse=True)\n",
      "            return z\n",
      "\n",
      "    def density_fn(x, logpx=None):\n",
      "        int_list = [\n",
      "            torch.tensor([it - args.time_scale, it]).type(torch.float32).to(device)\n",
      "            for it in integration_times[::-1]\n",
      "        ]\n",
      "        if logpx is not None:\n",
      "            for it in int_list:\n",
      "                x, logpx = model(x, logpx, integration_times=it, reverse=False)\n",
      "            return x, logpx\n",
      "        else:\n",
      "            for it in int_list:\n",
      "                x = model(x, integration_times=it, reverse=False)\n",
      "            return x\n",
      "\n",
      "    return sample_fn, density_fn\n",
      "\n",
      "\n",
      "def compute_loss(device, args, model, growth_model, logger, full_data):\n",
      "    \"\"\"\n",
      "    Compute loss by integrating backwards from the last time step\n",
      "    At each time step integrate back one time step, and concatenate that\n",
      "    to samples of the empirical distribution at that previous timestep\n",
      "    repeating over and over to calculate the likelihood of samples in\n",
      "    later timepoints iteratively, making sure that the ODE is evaluated\n",
      "    at every time step to calculate those later points.\n",
      "\n",
      "    The growth model is a single model of time independent cell growth /\n",
      "    death rate defined as a variation from uniform.\n",
      "    \"\"\"\n",
      "\n",
      "    # Backward pass accumulating losses, previous state and deltas\n",
      "    deltas = []\n",
      "    zs = []\n",
      "    z = None\n",
      "    interp_loss = 0.0\n",
      "    for i, (itp, tp) in enumerate(zip(args.int_tps[::-1], args.timepoints[::-1])):\n",
      "        # tp counts down from last\n",
      "        integration_times = torch.tensor([itp - args.time_scale, itp])\n",
      "        integration_times = integration_times.type(torch.float32).to(device)\n",
      "        # integration_times.requires_grad = True\n",
      "\n",
      "        # load data and add noise\n",
      "        idx = args.data.sample_index(args.batch_size, tp)\n",
      "        x = args.data.get_data()[idx]\n",
      "        if args.training_noise > 0.0:\n",
      "            x += np.random.randn(*x.shape) * args.training_noise\n",
      "        x = torch.from_numpy(x).type(torch.float32).to(device)\n",
      "\n",
      "        if i > 0:\n",
      "            x = torch.cat((z, x))\n",
      "            zs.append(z)\n",
      "        zero = torch.zeros(x.shape[0], 1).to(x)\n",
      "\n",
      "        # transform to previous timepoint\n",
      "        z, delta_logp = model(x, zero, integration_times=integration_times)\n",
      "        deltas.append(delta_logp)\n",
      "\n",
      "        # Straightline regularization\n",
      "        # Integrate to random point at time t and assert close to (1 - t) * end + t * start\n",
      "        if args.interp_reg:\n",
      "            t = np.random.rand()\n",
      "            int_t = torch.tensor([itp - t * args.time_scale, itp])\n",
      "            int_t = int_t.type(torch.float32).to(device)\n",
      "            int_x = model(x, integration_times=int_t)\n",
      "            int_x = int_x.detach()\n",
      "            actual_int_x = x * (1 - t) + z * t\n",
      "            interp_loss += F.mse_loss(int_x, actual_int_x)\n",
      "    if args.interp_reg:\n",
      "        print(\"interp_loss\", interp_loss)\n",
      "\n",
      "    logpz = args.data.base_density()(z)\n",
      "\n",
      "    # build growth rates\n",
      "    if args.use_growth:\n",
      "        growthrates = [torch.ones_like(logpz)]\n",
      "        for z_state, tp in zip(zs[::-1], args.timepoints[:-1]):\n",
      "            # Full state includes time parameter to growth_model\n",
      "            time_state = tp * torch.ones(z_state.shape[0], 1).to(z_state)\n",
      "            full_state = torch.cat([z_state, time_state], 1)\n",
      "            growthrates.append(growth_model(full_state))\n",
      "\n",
      "    # Accumulate losses\n",
      "    losses = []\n",
      "    logps = [logpz]\n",
      "    for i, delta_logp in enumerate(deltas[::-1]):\n",
      "        logpx = logps[-1] - delta_logp\n",
      "        if args.use_growth:\n",
      "            logpx += torch.log(torch.clamp(growthrates[i], 1e-4, 1e4))\n",
      "        logps.append(logpx[: -args.batch_size])\n",
      "        losses.append(-torch.mean(logpx[-args.batch_size :]))\n",
      "    losses = torch.stack(losses)\n",
      "    weights = torch.ones_like(losses).to(logpx)\n",
      "    if args.leaveout_timepoint >= 0:\n",
      "        weights[args.leaveout_timepoint] = 0\n",
      "    losses = torch.mean(losses * weights)\n",
      "\n",
      "    # Direction regularization\n",
      "    if args.vecint:\n",
      "        similarity_loss = 0\n",
      "        for i, (itp, tp) in enumerate(zip(args.int_tps, args.timepoints)):\n",
      "            itp = torch.tensor(itp).type(torch.float32).to(device)\n",
      "            idx = args.data.sample_index(args.batch_size, tp)\n",
      "            x = args.data.get_data()[idx]\n",
      "            v = args.data.get_velocity()[idx]\n",
      "            x = torch.from_numpy(x).type(torch.float32).to(device)\n",
      "            v = torch.from_numpy(v).type(torch.float32).to(device)\n",
      "            x += torch.randn_like(x) * 0.1\n",
      "            # Only penalizes at the time / place of visible samples\n",
      "            direction = -model.chain[0].odefunc.odefunc.diffeq(itp, x)\n",
      "            if args.use_magnitude:\n",
      "                similarity_loss += torch.mean(F.mse_loss(direction, v))\n",
      "            else:\n",
      "                similarity_loss -= torch.mean(F.cosine_similarity(direction, v))\n",
      "        logger.info(similarity_loss)\n",
      "        losses += similarity_loss * args.vecint\n",
      "\n",
      "    # Density regularization\n",
      "    if args.top_k_reg > 0:\n",
      "        density_loss = 0\n",
      "        tp_z_map = dict(zip(args.timepoints[:-1], zs[::-1]))\n",
      "        if args.leaveout_timepoint not in tp_z_map:\n",
      "            idx = args.data.sample_index(args.batch_size, tp)\n",
      "            x = args.data.get_data()[idx]\n",
      "            if args.training_noise > 0.0:\n",
      "                x += np.random.randn(*x.shape) * args.training_noise\n",
      "            x = torch.from_numpy(x).type(torch.float32).to(device)\n",
      "            t = np.random.rand()\n",
      "            int_t = torch.tensor([itp - t * args.time_scale, itp])\n",
      "            int_t = int_t.type(torch.float32).to(device)\n",
      "            int_x = model(x, integration_times=int_t)\n",
      "            samples_05 = int_x\n",
      "        else:\n",
      "            # If we are leaving out a timepoint the regularize there\n",
      "            samples_05 = tp_z_map[args.leaveout_timepoint]\n",
      "\n",
      "        # Calculate distance to 5 closest neighbors\n",
      "        # WARNING: This currently fails in the backward pass with cuda on pytorch < 1.4.0\n",
      "        #          works on CPU. Fixed in pytorch 1.5.0\n",
      "        # RuntimeError: CUDA error: invalid configuration argument\n",
      "        # The workaround is to run on cpu on pytorch <= 1.4.0 or upgrade\n",
      "        cdist = torch.cdist(samples_05, full_data)\n",
      "        values, _ = torch.topk(cdist, 5, dim=1, largest=False, sorted=False)\n",
      "        # Hinge loss\n",
      "        hinge_value = 0.1\n",
      "        values -= hinge_value\n",
      "        values[values < 0] = 0\n",
      "        density_loss = torch.mean(values)\n",
      "        print(\"Density Loss\", density_loss.item())\n",
      "        losses += density_loss * args.top_k_reg\n",
      "    losses += interp_loss\n",
      "    return losses\n",
      "\n",
      "\n",
      "def train(\n",
      "    device, args, model, growth_model, regularization_coeffs, regularization_fns, logger\n",
      "):\n",
      "    optimizer = optim.Adam(\n",
      "        model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
      "    )\n",
      "\n",
      "    time_meter = utils.RunningAverageMeter(0.93)\n",
      "    loss_meter = utils.RunningAverageMeter(0.93)\n",
      "    nfef_meter = utils.RunningAverageMeter(0.93)\n",
      "    nfeb_meter = utils.RunningAverageMeter(0.93)\n",
      "    tt_meter = utils.RunningAverageMeter(0.93)\n",
      "\n",
      "    full_data = (\n",
      "        torch.from_numpy(\n",
      "            args.data.get_data()[args.data.get_times() != args.leaveout_timepoint]\n",
      "        )\n",
      "        .type(torch.float32)\n",
      "        .to(device)\n",
      "    )\n",
      "\n",
      "    best_loss = float(\"inf\")\n",
      "    if args.use_growth:\n",
      "        growth_model.eval()\n",
      "    end = time.time()\n",
      "    for itr in range(1, args.niters + 1):\n",
      "        model.train()\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        # Train\n",
      "        if args.spectral_norm:\n",
      "            spectral_norm_power_iteration(model, 1)\n",
      "\n",
      "        loss = compute_loss(device, args, model, growth_model, logger, full_data)\n",
      "        loss_meter.update(loss.item())\n",
      "\n",
      "        if len(regularization_coeffs) > 0:\n",
      "            # Only regularize on the last timepoint\n",
      "            reg_states = get_regularization(model, regularization_coeffs)\n",
      "            reg_loss = sum(\n",
      "                reg_state * coeff\n",
      "                for reg_state, coeff in zip(reg_states, regularization_coeffs)\n",
      "                if coeff != 0\n",
      "            )\n",
      "            loss = loss + reg_loss\n",
      "        total_time = count_total_time(model)\n",
      "        nfe_forward = count_nfe(model)\n",
      "\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "\n",
      "        # Eval\n",
      "        nfe_total = count_nfe(model)\n",
      "        nfe_backward = nfe_total - nfe_forward\n",
      "        nfef_meter.update(nfe_forward)\n",
      "        nfeb_meter.update(nfe_backward)\n",
      "        time_meter.update(time.time() - end)\n",
      "        tt_meter.update(total_time)\n",
      "\n",
      "        log_message = (\n",
      "            \"Iter {:04d} | Time {:.4f}({:.4f}) | Loss {:.6f}({:.6f}) |\"\n",
      "            \" NFE Forward {:.0f}({:.1f})\"\n",
      "            \" | NFE Backward {:.0f}({:.1f})\".format(\n",
      "                itr,\n",
      "                time_meter.val,\n",
      "                time_meter.avg,\n",
      "                loss_meter.val,\n",
      "                loss_meter.avg,\n",
      "                nfef_meter.val,\n",
      "                nfef_meter.avg,\n",
      "                nfeb_meter.val,\n",
      "                nfeb_meter.avg,\n",
      "            )\n",
      "        )\n",
      "        if len(regularization_coeffs) > 0:\n",
      "            log_message = append_regularization_to_log(\n",
      "                log_message, regularization_fns, reg_states\n",
      "            )\n",
      "        logger.info(log_message)\n",
      "\n",
      "        if itr % args.val_freq == 0 or itr == args.niters:\n",
      "            with torch.no_grad():\n",
      "                train_eval(\n",
      "                    device, args, model, growth_model, itr, best_loss, logger, full_data\n",
      "                )\n",
      "\n",
      "        if itr % args.viz_freq == 0:\n",
      "            if args.data.get_shape()[0] > 2:\n",
      "                logger.warning(\"Skipping vis as data dimension is >2\")\n",
      "            else:\n",
      "                with torch.no_grad():\n",
      "                    visualize(device, args, model, itr)\n",
      "        if itr % args.save_freq == 0:\n",
      "            chkpt = {\n",
      "                \"state_dict\": model.state_dict(),\n",
      "            }\n",
      "            if args.use_growth:\n",
      "                chkpt.update({\"growth_state_dict\": growth_model.state_dict()})\n",
      "            utils.save_checkpoint(\n",
      "                chkpt,\n",
      "                args.save,\n",
      "                epoch=itr,\n",
      "            )\n",
      "        end = time.time()\n",
      "    logger.info(\"Training has finished.\")\n",
      "\n",
      "\n",
      "def train_eval(device, args, model, growth_model, itr, best_loss, logger, full_data):\n",
      "    model.eval()\n",
      "    test_loss = compute_loss(device, args, model, growth_model, logger, full_data)\n",
      "    test_nfe = count_nfe(model)\n",
      "    log_message = \"[TEST] Iter {:04d} | Test Loss {:.6f} |\" \" NFE {:.0f}\".format(\n",
      "        itr, test_loss, test_nfe\n",
      "    )\n",
      "    logger.info(log_message)\n",
      "    utils.makedirs(args.save)\n",
      "    with open(os.path.join(args.save, \"train_eval.csv\"), \"a\") as f:\n",
      "        import csv\n",
      "\n",
      "        writer = csv.writer(f)\n",
      "        writer.writerow((itr, test_loss))\n",
      "\n",
      "    if test_loss.item() < best_loss:\n",
      "        best_loss = test_loss.item()\n",
      "        chkpt = {\n",
      "            \"state_dict\": model.state_dict(),\n",
      "        }\n",
      "        if args.use_growth:\n",
      "            chkpt.update({\"growth_state_dict\": growth_model.state_dict()})\n",
      "        torch.save(\n",
      "            chkpt,\n",
      "            os.path.join(args.save, \"checkpt.pth\"),\n",
      "        )\n",
      "\n",
      "\n",
      "def visualize(device, args, model, itr):\n",
      "    model.eval()\n",
      "    for i, tp in enumerate(args.timepoints):\n",
      "        idx = args.data.sample_index(args.viz_batch_size, tp)\n",
      "        p_samples = args.data.get_data()[idx]\n",
      "        sample_fn, density_fn = get_transforms(\n",
      "            device, args, model, args.int_tps[: i + 1]\n",
      "        )\n",
      "        plt.figure(figsize=(9, 3))\n",
      "        visualize_transform(\n",
      "            p_samples,\n",
      "            args.data.base_sample(),\n",
      "            args.data.base_density(),\n",
      "            transform=sample_fn,\n",
      "            inverse_transform=density_fn,\n",
      "            samples=True,\n",
      "            npts=100,\n",
      "            device=device,\n",
      "        )\n",
      "        fig_filename = os.path.join(\n",
      "            args.save, \"figs\", \"{:04d}_{:01d}.jpg\".format(itr, i)\n",
      "        )\n",
      "        utils.makedirs(os.path.dirname(fig_filename))\n",
      "        plt.savefig(fig_filename)\n",
      "        plt.close()\n",
      "\n",
      "\n",
      "def plot_output(device, args, model):\n",
      "    save_traj_dir = os.path.join(args.save, \"trajectory\")\n",
      "    # logger.info('Plotting trajectory to {}'.format(save_traj_dir))\n",
      "    data_samples = args.data.get_data()[args.data.sample_index(2000, 0)]\n",
      "    np.random.seed(42)\n",
      "    start_points = args.data.base_sample()(1000, 2)\n",
      "    # idx = args.data.sample_index(50, 0)\n",
      "    # start_points = args.data.get_data()[idx]\n",
      "    # start_points = torch.from_numpy(start_points).type(torch.float32)\n",
      "    save_vectors(\n",
      "        args.data.base_density(),\n",
      "        model,\n",
      "        start_points,\n",
      "        args.data.get_data(),\n",
      "        args.data.get_times(),\n",
      "        args.save,\n",
      "        skip_first=(not args.data.known_base_density()),\n",
      "        device=device,\n",
      "        end_times=args.int_tps,\n",
      "        ntimes=100,\n",
      "    )\n",
      "    save_trajectory(\n",
      "        args.data.base_density(),\n",
      "        args.data.base_sample(),\n",
      "        model,\n",
      "        data_samples,\n",
      "        save_traj_dir,\n",
      "        device=device,\n",
      "        end_times=args.int_tps,\n",
      "        ntimes=25,\n",
      "    )\n",
      "    trajectory_to_video(save_traj_dir)\n",
      "\n",
      "    density_dir = os.path.join(args.save, \"density2\")\n",
      "    save_trajectory_density(\n",
      "        args.data.base_density(),\n",
      "        model,\n",
      "        data_samples,\n",
      "        density_dir,\n",
      "        device=device,\n",
      "        end_times=args.int_tps,\n",
      "        ntimes=25,\n",
      "        memory=0.1,\n",
      "    )\n",
      "    trajectory_to_video(density_dir)\n",
      "\n",
      "\n",
      "def main(args):\n",
      "    # logger\n",
      "    print(args.no_display_loss)\n",
      "    utils.makedirs(args.save)\n",
      "    logger = utils.get_logger(\n",
      "        logpath=os.path.join(args.save, \"logs\"),\n",
      "        filepath=os.path.abspath(__file__),\n",
      "        displaying=~args.no_display_loss,\n",
      "    )\n",
      "\n",
      "    if args.layer_type == \"blend\":\n",
      "        logger.info(\"!! Setting time_scale from None to 1.0 for Blend layers.\")\n",
      "        args.time_scale = 1.0\n",
      "\n",
      "    logger.info(args)\n",
      "\n",
      "    device = torch.device(\n",
      "        \"cuda:\" + str(args.gpu) if torch.cuda.is_available() else \"cpu\"\n",
      "    )\n",
      "    if args.use_cpu:\n",
      "        device = torch.device(\"cpu\")\n",
      "\n",
      "    args.data = dataset.SCData.factory(args.dataset, args)\n",
      "\n",
      "    args.timepoints = args.data.get_unique_times()\n",
      "    # Use maximum timepoint to establish integration_times\n",
      "    # as some timepoints may be left out for validation etc.\n",
      "    args.int_tps = (np.arange(max(args.timepoints) + 1) + 1.0) * args.time_scale\n",
      "\n",
      "    regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
      "    model = build_model_tabular(args, args.data.get_shape()[0], regularization_fns).to(\n",
      "        device\n",
      "    )\n",
      "    growth_model = None\n",
      "    if args.use_growth:\n",
      "        if args.leaveout_timepoint == -1:\n",
      "            growth_model_path = \"../data/externel/growth_model_v2.ckpt\"\n",
      "        elif args.leaveout_timepoint in [1, 2, 3]:\n",
      "            assert args.max_dim == 5\n",
      "            growth_model_path = \"../data/growth/model_%d\" % args.leaveout_timepoint\n",
      "        else:\n",
      "            print(\"WARNING: Cannot use growth with this timepoint\")\n",
      "\n",
      "        growth_model = torch.load(growth_model_path, map_location=device)\n",
      "    if args.spectral_norm:\n",
      "        add_spectral_norm(model)\n",
      "    set_cnf_options(args, model)\n",
      "\n",
      "    if args.test:\n",
      "        state_dict = torch.load(args.save + \"/checkpt.pth\", map_location=device)\n",
      "        model.load_state_dict(state_dict[\"state_dict\"])\n",
      "        # if \"growth_state_dict\" not in state_dict:\n",
      "        #    print(\"error growth model note in save\")\n",
      "        #    growth_model = None\n",
      "        # else:\n",
      "        #    checkpt = torch.load(args.save + \"/checkpt.pth\", map_location=device)\n",
      "        #    growth_model.load_state_dict(checkpt[\"growth_state_dict\"])\n",
      "        # TODO can we load the arguments from the save?\n",
      "        # eval_utils.generate_samples(\n",
      "        #    device, args, model, growth_model, timepoint=args.leaveout_timepoint\n",
      "        # )\n",
      "        # with torch.no_grad():\n",
      "        #    evaluate(device, args, model, growth_model)\n",
      "    #    exit()\n",
      "    else:\n",
      "        logger.info(model)\n",
      "        n_param = count_parameters(model)\n",
      "        logger.info(\"Number of trainable parameters: {}\".format(n_param))\n",
      "\n",
      "        train(\n",
      "            device,\n",
      "            args,\n",
      "            model,\n",
      "            growth_model,\n",
      "            regularization_coeffs,\n",
      "            regularization_fns,\n",
      "            logger,\n",
      "        )\n",
      "\n",
      "    if args.data.data.shape[1] == 2:\n",
      "        plot_output(device, args, model)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    args = parser.parse_args()\n",
      "    main(args)\n",
      "\n",
      "Namespace(test=False, dataset='../trajectorynet/output/pgclc_150dim.npz', use_growth=False, use_density=False, leaveout_timepoint=-1, layer_type='concatsquash', max_dim=10, dims='64-64-64', num_blocks=1, time_scale=0.5, train_T=True, divergence_fn='brute_force', nonlinearity='tanh', stochastic=False, alpha=0.0, solver='dopri5', atol=1e-05, rtol=1e-05, step_size=None, test_solver=None, test_atol=None, test_rtol=None, residual=False, rademacher=False, spectral_norm=False, batch_norm=False, bn_lag=0, niters=10000, num_workers=8, batch_size=1000, test_batch_size=1000, viz_batch_size=2000, lr=0.001, weight_decay=1e-05, l1int=None, l2int=None, sl2int=None, dl2int=None, dtl2int=None, JFrobint=None, JdiagFrobint=None, JoffdiagFrobint=None, vecint=None, use_magnitude=False, interp_reg=None, save='results/pgclc', save_freq=1000, viz_freq=100, viz_freq_growth=100, val_freq=100, log_freq=10, gpu=0, use_cpu=False, no_display_loss=True, top_k_reg=0.0, training_noise=0.1, embedding_name='original_embedding_150d', whiten=False)\n",
      "No velocity found for embedding original_embedding_150d skipping velocity\n",
      "Warning: Clipping dimensionality to 10\n",
      "SequentialFlow(\n",
      "  (chain): ModuleList(\n",
      "    (0): CNF(\n",
      "      (odefunc): RegularizedODEfunc(\n",
      "        (odefunc): ODEfunc(\n",
      "          (diffeq): ODEnet(\n",
      "            (layers): ModuleList(\n",
      "              (0): ConcatSquashLinear(\n",
      "                (_layer): Linear(in_features=10, out_features=64, bias=True)\n",
      "                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)\n",
      "                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)\n",
      "              )\n",
      "              (1-2): 2 x ConcatSquashLinear(\n",
      "                (_layer): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (_hyper_bias): Linear(in_features=1, out_features=64, bias=False)\n",
      "                (_hyper_gate): Linear(in_features=1, out_features=64, bias=True)\n",
      "              )\n",
      "              (3): ConcatSquashLinear(\n",
      "                (_layer): Linear(in_features=64, out_features=10, bias=True)\n",
      "                (_hyper_bias): Linear(in_features=1, out_features=10, bias=False)\n",
      "                (_hyper_gate): Linear(in_features=1, out_features=10, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (activation_fns): ModuleList(\n",
      "              (0-2): 3 x Tanh()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Number of trainable parameters: 10281\n",
      "Iter 0001 | Time 5.1843(5.1843) | Loss 329.812592(329.812592) | NFE Forward 14(14.0) | NFE Backward 99(99.0)\n",
      "Iter 0002 | Time 5.1012(5.1785) | Loss 329.525208(329.792475) | NFE Forward 14(14.0) | NFE Backward 111(99.8)\n",
      "Iter 0003 | Time 3.9980(5.0959) | Loss 330.286194(329.827035) | NFE Forward 14(14.0) | NFE Backward 93(99.4)\n",
      "Iter 0004 | Time 4.7355(5.0706) | Loss 327.827606(329.687075) | NFE Forward 14(14.0) | NFE Backward 105(99.8)\n",
      "Iter 0005 | Time 4.5245(5.0324) | Loss 328.485077(329.602935) | NFE Forward 14(14.0) | NFE Backward 99(99.7)\n",
      "Iter 0006 | Time 5.1409(5.0400) | Loss 325.066956(329.285417) | NFE Forward 14(14.0) | NFE Backward 93(99.2)\n",
      "Iter 0007 | Time 4.5662(5.0068) | Loss 325.018982(328.986766) | NFE Forward 14(14.0) | NFE Backward 93(98.8)\n",
      "Iter 0008 | Time 5.4014(5.0345) | Loss 323.624542(328.611410) | NFE Forward 14(14.0) | NFE Backward 117(100.1)\n",
      "Iter 0009 | Time 4.4620(4.9944) | Loss 322.776215(328.202947) | NFE Forward 14(14.0) | NFE Backward 111(100.8)\n",
      "Iter 0010 | Time 4.5792(4.9653) | Loss 321.627594(327.742672) | NFE Forward 14(14.0) | NFE Backward 117(102.0)\n",
      "Iter 0011 | Time 3.7493(4.8802) | Loss 320.743713(327.252745) | NFE Forward 14(14.0) | NFE Backward 111(102.6)\n",
      "Iter 0012 | Time 4.7462(4.8708) | Loss 320.221771(326.760577) | NFE Forward 14(14.0) | NFE Backward 123(104.0)\n",
      "Iter 0013 | Time 6.3018(4.9710) | Loss 318.159485(326.158500) | NFE Forward 14(14.0) | NFE Backward 111(104.5)\n",
      "Iter 0014 | Time 4.8038(4.9593) | Loss 316.193176(325.460928) | NFE Forward 14(14.0) | NFE Backward 111(105.0)\n",
      "Iter 0015 | Time 3.5224(4.8587) | Loss 315.690948(324.777029) | NFE Forward 14(14.0) | NFE Backward 111(105.4)\n",
      "Iter 0016 | Time 3.4673(4.7613) | Loss 317.779297(324.287188) | NFE Forward 14(14.0) | NFE Backward 123(106.6)\n",
      "Iter 0017 | Time 3.5121(4.6739) | Loss 313.332794(323.520380) | NFE Forward 14(14.0) | NFE Backward 123(107.8)\n",
      "Iter 0018 | Time 4.0581(4.6308) | Loss 313.508728(322.819565) | NFE Forward 14(14.0) | NFE Backward 111(108.0)\n",
      "Iter 0019 | Time 3.9650(4.5842) | Loss 311.941437(322.058096) | NFE Forward 14(14.0) | NFE Backward 123(109.0)\n",
      "Iter 0020 | Time 3.3495(4.4977) | Loss 311.901489(321.347133) | NFE Forward 14(14.0) | NFE Backward 123(110.0)\n",
      "Iter 0021 | Time 3.6671(4.4396) | Loss 310.194122(320.566422) | NFE Forward 14(14.0) | NFE Backward 123(110.9)\n",
      "Iter 0022 | Time 3.7807(4.3935) | Loss 310.562775(319.866167) | NFE Forward 14(14.0) | NFE Backward 129(112.2)\n",
      "Iter 0023 | Time 3.8391(4.3547) | Loss 309.848724(319.164946) | NFE Forward 14(14.0) | NFE Backward 129(113.4)\n",
      "Iter 0024 | Time 3.7125(4.3097) | Loss 307.359375(318.338556) | NFE Forward 14(14.0) | NFE Backward 129(114.5)\n",
      "Iter 0025 | Time 3.7224(4.2686) | Loss 304.973083(317.402973) | NFE Forward 14(14.0) | NFE Backward 129(115.5)\n",
      "Iter 0026 | Time 3.5993(4.2217) | Loss 304.977844(316.533214) | NFE Forward 14(14.0) | NFE Backward 123(116.0)\n",
      "Iter 0027 | Time 4.0186(4.2075) | Loss 305.083038(315.731702) | NFE Forward 14(14.0) | NFE Backward 123(116.5)\n",
      "Iter 0028 | Time 5.5843(4.3039) | Loss 301.404205(314.728777) | NFE Forward 14(14.0) | NFE Backward 123(117.0)\n",
      "Iter 0029 | Time 6.3534(4.4474) | Loss 300.379974(313.724361) | NFE Forward 14(14.0) | NFE Backward 123(117.4)\n",
      "Iter 0030 | Time 5.1635(4.4975) | Loss 298.504883(312.658997) | NFE Forward 14(14.0) | NFE Backward 123(117.8)\n",
      "Iter 0031 | Time 3.6043(4.4350) | Loss 297.774811(311.617104) | NFE Forward 14(14.0) | NFE Backward 123(118.1)\n",
      "Iter 0032 | Time 3.4397(4.3653) | Loss 298.242950(310.680914) | NFE Forward 14(14.0) | NFE Backward 123(118.5)\n",
      "Iter 0033 | Time 3.5571(4.3087) | Loss 297.310516(309.744986) | NFE Forward 14(14.0) | NFE Backward 123(118.8)\n",
      "Iter 0034 | Time 2.8672(4.2078) | Loss 294.936218(308.708372) | NFE Forward 14(14.0) | NFE Backward 105(117.8)\n",
      "Iter 0035 | Time 2.9172(4.1175) | Loss 294.649048(307.724219) | NFE Forward 14(14.0) | NFE Backward 99(116.5)\n",
      "Iter 0036 | Time 3.3121(4.0611) | Loss 293.192017(306.706965) | NFE Forward 14(14.0) | NFE Backward 99(115.3)\n",
      "Iter 0037 | Time 3.0913(3.9932) | Loss 294.039703(305.820257) | NFE Forward 14(14.0) | NFE Backward 99(114.1)\n",
      "Iter 0038 | Time 3.6185(3.9670) | Loss 289.669495(304.689703) | NFE Forward 14(14.0) | NFE Backward 99(113.1)\n",
      "Iter 0039 | Time 3.3736(3.9254) | Loss 289.399231(303.619370) | NFE Forward 14(14.0) | NFE Backward 99(112.1)\n",
      "Iter 0040 | Time 2.7152(3.8407) | Loss 288.908936(302.589640) | NFE Forward 14(14.0) | NFE Backward 99(111.2)\n",
      "Iter 0041 | Time 3.2201(3.7973) | Loss 287.261383(301.516662) | NFE Forward 14(14.0) | NFE Backward 99(110.3)\n",
      "Iter 0042 | Time 2.8315(3.7297) | Loss 284.869476(300.351359) | NFE Forward 14(14.0) | NFE Backward 87(108.7)\n",
      "Iter 0043 | Time 2.5984(3.6505) | Loss 286.008240(299.347341) | NFE Forward 14(14.0) | NFE Backward 87(107.2)\n",
      "Iter 0044 | Time 2.4107(3.5637) | Loss 285.285278(298.362996) | NFE Forward 14(14.0) | NFE Backward 87(105.8)\n",
      "Iter 0045 | Time 2.9012(3.5173) | Loss 281.823425(297.205226) | NFE Forward 14(14.0) | NFE Backward 99(105.3)\n",
      "Iter 0046 | Time 2.5697(3.4510) | Loss 280.659790(296.047046) | NFE Forward 14(14.0) | NFE Backward 87(104.0)\n",
      "Iter 0047 | Time 2.5800(3.3900) | Loss 280.888367(294.985938) | NFE Forward 14(14.0) | NFE Backward 87(102.8)\n",
      "Iter 0048 | Time 2.7015(3.3418) | Loss 278.889740(293.859204) | NFE Forward 14(14.0) | NFE Backward 87(101.7)\n",
      "Iter 0049 | Time 2.8127(3.3048) | Loss 277.664459(292.725572) | NFE Forward 14(14.0) | NFE Backward 99(101.5)\n",
      "Iter 0050 | Time 2.3453(3.2376) | Loss 277.771301(291.678773) | NFE Forward 14(14.0) | NFE Backward 75(99.7)\n",
      "Iter 0051 | Time 2.8826(3.2128) | Loss 275.651306(290.556851) | NFE Forward 14(14.0) | NFE Backward 87(98.8)\n",
      "Iter 0052 | Time 3.6065(3.2403) | Loss 274.640198(289.442685) | NFE Forward 14(14.0) | NFE Backward 75(97.1)\n",
      "Iter 0053 | Time 3.6981(3.2724) | Loss 273.980896(288.360360) | NFE Forward 14(14.0) | NFE Backward 87(96.4)\n",
      "Iter 0054 | Time 3.4993(3.2883) | Loss 271.541565(287.183044) | NFE Forward 14(14.0) | NFE Backward 87(95.7)\n",
      "Iter 0055 | Time 4.4667(3.3707) | Loss 273.101624(286.197345) | NFE Forward 14(14.0) | NFE Backward 75(94.3)\n",
      "Iter 0056 | Time 3.2946(3.3654) | Loss 270.432068(285.093775) | NFE Forward 14(14.0) | NFE Backward 75(92.9)\n",
      "Iter 0057 | Time 3.8631(3.4003) | Loss 269.906555(284.030670) | NFE Forward 14(14.0) | NFE Backward 87(92.5)\n",
      "Iter 0058 | Time 3.3417(3.3962) | Loss 272.600494(283.230558) | NFE Forward 14(14.0) | NFE Backward 87(92.1)\n",
      "Iter 0059 | Time 3.2218(3.3840) | Loss 267.522186(282.130972) | NFE Forward 14(14.0) | NFE Backward 99(92.6)\n",
      "Iter 0060 | Time 2.4375(3.3177) | Loss 265.764954(280.985350) | NFE Forward 14(14.0) | NFE Backward 75(91.4)\n",
      "Iter 0061 | Time 2.3889(3.2527) | Loss 265.681335(279.914069) | NFE Forward 14(14.0) | NFE Backward 75(90.2)\n",
      "Iter 0062 | Time 2.4284(3.1950) | Loss 266.241272(278.956973) | NFE Forward 14(14.0) | NFE Backward 75(89.2)\n",
      "Iter 0063 | Time 2.8959(3.1740) | Loss 262.925293(277.834756) | NFE Forward 14(14.0) | NFE Backward 75(88.2)\n",
      "Iter 0064 | Time 2.4544(3.1237) | Loss 264.004333(276.866626) | NFE Forward 14(14.0) | NFE Backward 75(87.3)\n",
      "Iter 0065 | Time 2.7422(3.0970) | Loss 261.104279(275.763262) | NFE Forward 14(14.0) | NFE Backward 99(88.1)\n",
      "Iter 0066 | Time 2.3531(3.0449) | Loss 262.105225(274.807199) | NFE Forward 14(14.0) | NFE Backward 75(87.2)\n",
      "Iter 0067 | Time 2.1889(2.9850) | Loss 260.542297(273.808656) | NFE Forward 14(14.0) | NFE Backward 75(86.3)\n",
      "Iter 0068 | Time 2.2667(2.9347) | Loss 258.771423(272.756050) | NFE Forward 14(14.0) | NFE Backward 75(85.5)\n",
      "Iter 0069 | Time 2.3459(2.8935) | Loss 257.103394(271.660364) | NFE Forward 14(14.0) | NFE Backward 87(85.6)\n",
      "Iter 0070 | Time 2.4138(2.8599) | Loss 256.922760(270.628732) | NFE Forward 14(14.0) | NFE Backward 75(84.9)\n",
      "Iter 0071 | Time 2.4394(2.8305) | Loss 256.129089(269.613757) | NFE Forward 14(14.0) | NFE Backward 81(84.6)\n",
      "Iter 0072 | Time 2.8861(2.8344) | Loss 254.983246(268.589621) | NFE Forward 14(14.0) | NFE Backward 99(85.6)\n",
      "Iter 0073 | Time 3.8063(2.9024) | Loss 253.189362(267.511603) | NFE Forward 14(14.0) | NFE Backward 93(86.1)\n",
      "Iter 0074 | Time 4.1574(2.9903) | Loss 253.409622(266.524464) | NFE Forward 14(14.0) | NFE Backward 81(85.8)\n",
      "Iter 0075 | Time 4.2600(3.0791) | Loss 251.143021(265.447763) | NFE Forward 14(14.0) | NFE Backward 93(86.3)\n",
      "Iter 0076 | Time 4.1180(3.1519) | Loss 250.786575(264.421480) | NFE Forward 14(14.0) | NFE Backward 93(86.8)\n",
      "Iter 0077 | Time 3.0773(3.1466) | Loss 248.161743(263.283298) | NFE Forward 14(14.0) | NFE Backward 87(86.8)\n",
      "Iter 0078 | Time 3.0902(3.1427) | Loss 247.883133(262.205287) | NFE Forward 14(14.0) | NFE Backward 87(86.8)\n",
      "Iter 0079 | Time 3.3003(3.1537) | Loss 246.504242(261.106214) | NFE Forward 20(14.4) | NFE Backward 81(86.4)\n",
      "Iter 0080 | Time 3.0840(3.1488) | Loss 246.181686(260.061497) | NFE Forward 14(14.4) | NFE Backward 93(86.8)\n",
      "Iter 0081 | Time 2.7933(3.1239) | Loss 247.210114(259.161900) | NFE Forward 14(14.4) | NFE Backward 81(86.4)\n",
      "Iter 0082 | Time 2.9919(3.1147) | Loss 244.799805(258.156553) | NFE Forward 14(14.3) | NFE Backward 93(86.9)\n",
      "Iter 0083 | Time 2.9378(3.1023) | Loss 244.482391(257.199362) | NFE Forward 20(14.7) | NFE Backward 93(87.3)\n",
      "Iter 0084 | Time 2.8796(3.0867) | Loss 243.955719(256.272307) | NFE Forward 20(15.1) | NFE Backward 81(86.9)\n",
      "Iter 0085 | Time 3.1614(3.0920) | Loss 240.549240(255.171692) | NFE Forward 20(15.4) | NFE Backward 105(88.1)\n",
      "Iter 0086 | Time 3.1120(3.0934) | Loss 242.009445(254.250335) | NFE Forward 20(15.8) | NFE Backward 93(88.5)\n",
      "Iter 0087 | Time 3.1168(3.0950) | Loss 237.522827(253.079409) | NFE Forward 20(16.1) | NFE Backward 93(88.8)\n",
      "Iter 0088 | Time 3.5117(3.1242) | Loss 237.442673(251.984838) | NFE Forward 20(16.3) | NFE Backward 99(89.5)\n",
      "Iter 0089 | Time 3.0308(3.1176) | Loss 236.604248(250.908197) | NFE Forward 20(16.6) | NFE Backward 87(89.3)\n",
      "Iter 0090 | Time 3.1464(3.1196) | Loss 236.533691(249.901981) | NFE Forward 20(16.8) | NFE Backward 87(89.2)\n",
      "Iter 0091 | Time 3.8783(3.1728) | Loss 235.897858(248.921693) | NFE Forward 20(17.1) | NFE Backward 93(89.4)\n",
      "Iter 0092 | Time 4.5473(3.2690) | Loss 234.852783(247.936869) | NFE Forward 20(17.3) | NFE Backward 93(89.7)\n",
      "Iter 0093 | Time 5.0713(3.3951) | Loss 231.796387(246.807035) | NFE Forward 20(17.5) | NFE Backward 93(89.9)\n",
      "Iter 0094 | Time 4.5284(3.4745) | Loss 230.806152(245.686973) | NFE Forward 20(17.6) | NFE Backward 99(90.6)\n",
      "Iter 0095 | Time 4.7326(3.5625) | Loss 231.496124(244.693614) | NFE Forward 20(17.8) | NFE Backward 93(90.7)\n",
      "Iter 0096 | Time 4.2206(3.6086) | Loss 228.718552(243.575360) | NFE Forward 20(18.0) | NFE Backward 99(91.3)\n",
      "Iter 0097 | Time 4.1175(3.6442) | Loss 228.998856(242.555004) | NFE Forward 20(18.1) | NFE Backward 99(91.8)\n",
      "Iter 0098 | Time 4.0053(3.6695) | Loss 227.933929(241.531529) | NFE Forward 20(18.2) | NFE Backward 99(92.3)\n",
      "Iter 0099 | Time 4.3330(3.7159) | Loss 226.292084(240.464768) | NFE Forward 20(18.4) | NFE Backward 99(92.8)\n",
      "Iter 0100 | Time 3.9999(3.7358) | Loss 225.335480(239.405718) | NFE Forward 20(18.5) | NFE Backward 93(92.8)\n",
      "[TEST] Iter 0100 | Test Loss 223.418900 | NFE 20\n",
      "Skipping vis as data dimension is >2\n",
      "Iter 0101 | Time 4.5656(3.7939) | Loss 224.325241(238.350084) | NFE Forward 20(18.6) | NFE Backward 105(93.7)\n",
      "Iter 0102 | Time 3.6253(3.7821) | Loss 223.675858(237.322888) | NFE Forward 20(18.7) | NFE Backward 99(94.1)\n",
      "Iter 0103 | Time 3.8178(3.7846) | Loss 223.585983(236.361305) | NFE Forward 20(18.8) | NFE Backward 105(94.8)\n",
      "Iter 0104 | Time 3.5056(3.7651) | Loss 223.325836(235.448822) | NFE Forward 20(18.9) | NFE Backward 105(95.5)\n",
      "Iter 0105 | Time 3.5727(3.7516) | Loss 221.092819(234.443902) | NFE Forward 20(18.9) | NFE Backward 99(95.8)\n",
      "Iter 0106 | Time 3.7328(3.7503) | Loss 219.670532(233.409766) | NFE Forward 20(19.0) | NFE Backward 93(95.6)\n",
      "Iter 0107 | Time 3.2429(3.7148) | Loss 220.051727(232.474703) | NFE Forward 20(19.1) | NFE Backward 99(95.8)\n",
      "Iter 0108 | Time 3.6906(3.7131) | Loss 218.091263(231.467863) | NFE Forward 20(19.1) | NFE Backward 111(96.9)\n",
      "Iter 0109 | Time 3.6844(3.7111) | Loss 216.861328(230.445405) | NFE Forward 20(19.2) | NFE Backward 105(97.4)\n",
      "Iter 0110 | Time 3.5167(3.6975) | Loss 216.235840(229.450736) | NFE Forward 20(19.3) | NFE Backward 105(98.0)\n",
      "Iter 0111 | Time 3.5890(3.6899) | Loss 215.866821(228.499862) | NFE Forward 20(19.3) | NFE Backward 99(98.0)\n",
      "Iter 0112 | Time 3.5207(3.6780) | Loss 214.645508(227.530057) | NFE Forward 20(19.4) | NFE Backward 105(98.5)\n",
      "Iter 0113 | Time 3.6038(3.6728) | Loss 213.810867(226.569714) | NFE Forward 20(19.4) | NFE Backward 99(98.6)\n",
      "Iter 0114 | Time 3.4807(3.6594) | Loss 214.273346(225.708968) | NFE Forward 20(19.4) | NFE Backward 99(98.6)\n",
      "Iter 0115 | Time 3.6373(3.6578) | Loss 211.209137(224.693980) | NFE Forward 20(19.5) | NFE Backward 105(99.0)\n",
      "Iter 0116 | Time 3.4349(3.6422) | Loss 210.720612(223.715844) | NFE Forward 20(19.5) | NFE Backward 105(99.5)\n",
      "Iter 0117 | Time 3.3418(3.6212) | Loss 209.655487(222.731619) | NFE Forward 20(19.6) | NFE Backward 105(99.9)\n",
      "Iter 0118 | Time 3.7148(3.6278) | Loss 208.402100(221.728553) | NFE Forward 20(19.6) | NFE Backward 111(100.6)\n",
      "Iter 0119 | Time 3.3757(3.6101) | Loss 206.852249(220.687211) | NFE Forward 20(19.6) | NFE Backward 111(101.4)\n",
      "Iter 0120 | Time 3.6413(3.6123) | Loss 208.142044(219.809050) | NFE Forward 20(19.6) | NFE Backward 111(102.0)\n",
      "Iter 0121 | Time 3.7551(3.6223) | Loss 204.940231(218.768232) | NFE Forward 20(19.7) | NFE Backward 111(102.7)\n",
      "Iter 0122 | Time 3.5995(3.6207) | Loss 205.853561(217.864205) | NFE Forward 20(19.7) | NFE Backward 111(103.2)\n",
      "Iter 0123 | Time 3.8167(3.6344) | Loss 204.444946(216.924857) | NFE Forward 20(19.7) | NFE Backward 111(103.8)\n",
      "Iter 0124 | Time 3.5003(3.6250) | Loss 203.813522(216.007064) | NFE Forward 20(19.7) | NFE Backward 111(104.3)\n",
      "Iter 0125 | Time 3.4514(3.6129) | Loss 203.344162(215.120661) | NFE Forward 20(19.8) | NFE Backward 105(104.3)\n",
      "Iter 0126 | Time 3.6339(3.6143) | Loss 201.252457(214.149886) | NFE Forward 20(19.8) | NFE Backward 111(104.8)\n",
      "Iter 0127 | Time 3.2323(3.5876) | Loss 201.558624(213.268498) | NFE Forward 20(19.8) | NFE Backward 99(104.4)\n",
      "Iter 0128 | Time 3.5473(3.5848) | Loss 200.233063(212.356018) | NFE Forward 20(19.8) | NFE Backward 111(104.9)\n",
      "Iter 0129 | Time 3.4038(3.5721) | Loss 199.305008(211.442447) | NFE Forward 20(19.8) | NFE Backward 111(105.3)\n",
      "Iter 0130 | Time 3.4235(3.5617) | Loss 196.486160(210.395507) | NFE Forward 20(19.8) | NFE Backward 111(105.7)\n",
      "Iter 0131 | Time 3.6167(3.5656) | Loss 197.512726(209.493712) | NFE Forward 20(19.8) | NFE Backward 111(106.1)\n",
      "Iter 0132 | Time 3.5743(3.5662) | Loss 196.975021(208.617404) | NFE Forward 20(19.8) | NFE Backward 111(106.4)\n",
      "Iter 0133 | Time 3.3059(3.5479) | Loss 195.359406(207.689344) | NFE Forward 20(19.9) | NFE Backward 111(106.7)\n",
      "Iter 0134 | Time 3.6488(3.5550) | Loss 193.971436(206.729090) | NFE Forward 20(19.9) | NFE Backward 111(107.0)\n",
      "Iter 0135 | Time 3.7605(3.5694) | Loss 192.644775(205.743188) | NFE Forward 20(19.9) | NFE Backward 111(107.3)\n",
      "Iter 0136 | Time 3.5814(3.5702) | Loss 193.489380(204.885422) | NFE Forward 20(19.9) | NFE Backward 105(107.1)\n",
      "Iter 0137 | Time 3.6810(3.5780) | Loss 191.877365(203.974858) | NFE Forward 20(19.9) | NFE Backward 105(107.0)\n",
      "Iter 0138 | Time 3.5417(3.5754) | Loss 190.938522(203.062314) | NFE Forward 20(19.9) | NFE Backward 105(106.9)\n",
      "Iter 0139 | Time 3.6524(3.5808) | Loss 190.342194(202.171906) | NFE Forward 20(19.9) | NFE Backward 111(107.1)\n",
      "Iter 0140 | Time 3.6779(3.5876) | Loss 189.923553(201.314521) | NFE Forward 20(19.9) | NFE Backward 105(107.0)\n",
      "Iter 0141 | Time 3.3740(3.5727) | Loss 189.392548(200.479983) | NFE Forward 20(19.9) | NFE Backward 111(107.3)\n",
      "Iter 0142 | Time 3.4382(3.5633) | Loss 187.720383(199.586811) | NFE Forward 20(19.9) | NFE Backward 105(107.1)\n",
      "Iter 0143 | Time 3.5807(3.5645) | Loss 188.419022(198.805066) | NFE Forward 20(19.9) | NFE Backward 105(107.0)\n",
      "Iter 0144 | Time 3.2241(3.5406) | Loss 184.864822(197.829249) | NFE Forward 26(20.4) | NFE Backward 99(106.4)\n",
      "Iter 0145 | Time 3.3915(3.5302) | Loss 185.720062(196.981606) | NFE Forward 20(20.3) | NFE Backward 105(106.3)\n",
      "Iter 0146 | Time 3.3736(3.5192) | Loss 183.814667(196.059920) | NFE Forward 26(20.7) | NFE Backward 105(106.2)\n",
      "Iter 0147 | Time 3.2149(3.4979) | Loss 182.551651(195.114341) | NFE Forward 26(21.1) | NFE Backward 105(106.1)\n",
      "Iter 0148 | Time 3.4915(3.4975) | Loss 182.220062(194.211742) | NFE Forward 26(21.4) | NFE Backward 105(106.1)\n",
      "Iter 0149 | Time 3.3460(3.4869) | Loss 183.440033(193.457722) | NFE Forward 26(21.8) | NFE Backward 99(105.6)\n",
      "Iter 0150 | Time 3.5601(3.4920) | Loss 180.716736(192.565853) | NFE Forward 26(22.1) | NFE Backward 105(105.5)\n",
      "Iter 0151 | Time 3.3660(3.4832) | Loss 180.349350(191.710698) | NFE Forward 26(22.3) | NFE Backward 99(105.1)\n",
      "Iter 0152 | Time 3.6900(3.4977) | Loss 178.729370(190.802005) | NFE Forward 26(22.6) | NFE Backward 105(105.1)\n",
      "Iter 0153 | Time 3.7630(3.5162) | Loss 181.051575(190.119475) | NFE Forward 26(22.8) | NFE Backward 105(105.1)\n",
      "Iter 0154 | Time 3.4960(3.5148) | Loss 176.572876(189.171213) | NFE Forward 26(23.1) | NFE Backward 105(105.1)\n",
      "Iter 0155 | Time 3.4711(3.5118) | Loss 176.116989(188.257417) | NFE Forward 26(23.3) | NFE Backward 105(105.0)\n",
      "Iter 0156 | Time 3.6762(3.5233) | Loss 175.792023(187.384840) | NFE Forward 26(23.4) | NFE Backward 105(105.0)\n",
      "Iter 0157 | Time 3.5819(3.5274) | Loss 175.529434(186.554961) | NFE Forward 26(23.6) | NFE Backward 105(105.0)\n",
      "Iter 0158 | Time 3.9775(3.5589) | Loss 175.383331(185.772947) | NFE Forward 26(23.8) | NFE Backward 105(105.0)\n",
      "Iter 0159 | Time 3.6382(3.5644) | Loss 173.977570(184.947271) | NFE Forward 26(23.9) | NFE Backward 105(105.0)\n",
      "Iter 0160 | Time 3.4052(3.5533) | Loss 172.539581(184.078732) | NFE Forward 26(24.1) | NFE Backward 105(105.0)\n",
      "Iter 0161 | Time 3.4124(3.5434) | Loss 172.722046(183.283764) | NFE Forward 26(24.2) | NFE Backward 105(105.0)\n",
      "Iter 0162 | Time 4.1350(3.5848) | Loss 170.448288(182.385281) | NFE Forward 26(24.3) | NFE Backward 105(105.0)\n",
      "Iter 0163 | Time 3.8349(3.6023) | Loss 170.107864(181.525862) | NFE Forward 26(24.5) | NFE Backward 105(105.0)\n",
      "Iter 0164 | Time 3.6476(3.6055) | Loss 169.130493(180.658186) | NFE Forward 26(24.6) | NFE Backward 105(105.0)\n",
      "Iter 0165 | Time 3.5077(3.5987) | Loss 167.834076(179.760498) | NFE Forward 26(24.7) | NFE Backward 99(104.6)\n",
      "Iter 0166 | Time 3.4107(3.5855) | Loss 168.196335(178.951007) | NFE Forward 26(24.8) | NFE Backward 105(104.6)\n",
      "Iter 0167 | Time 3.9951(3.6142) | Loss 167.312775(178.136331) | NFE Forward 26(24.9) | NFE Backward 105(104.7)\n",
      "Iter 0168 | Time 3.5989(3.6131) | Loss 168.223785(177.442452) | NFE Forward 26(24.9) | NFE Backward 105(104.7)\n",
      "Iter 0169 | Time 3.7294(3.6212) | Loss 165.322952(176.594087) | NFE Forward 26(25.0) | NFE Backward 105(104.7)\n",
      "Iter 0170 | Time 3.6019(3.6199) | Loss 165.094650(175.789127) | NFE Forward 26(25.1) | NFE Backward 105(104.7)\n",
      "Iter 0171 | Time 3.3653(3.6021) | Loss 163.318970(174.916216) | NFE Forward 26(25.1) | NFE Backward 105(104.7)\n",
      "Iter 0172 | Time 3.2185(3.5752) | Loss 164.106110(174.159508) | NFE Forward 26(25.2) | NFE Backward 105(104.8)\n",
      "Iter 0173 | Time 3.4368(3.5655) | Loss 162.597504(173.350168) | NFE Forward 26(25.3) | NFE Backward 105(104.8)\n",
      "Iter 0174 | Time 3.4091(3.5546) | Loss 161.809540(172.542324) | NFE Forward 26(25.3) | NFE Backward 105(104.8)\n",
      "Iter 0175 | Time 3.6313(3.5599) | Loss 161.867355(171.795076) | NFE Forward 26(25.4) | NFE Backward 105(104.8)\n",
      "Iter 0176 | Time 3.7796(3.5753) | Loss 161.144745(171.049553) | NFE Forward 26(25.4) | NFE Backward 105(104.8)\n",
      "Iter 0177 | Time 3.2022(3.5492) | Loss 158.901382(170.199181) | NFE Forward 26(25.4) | NFE Backward 99(104.4)\n",
      "Iter 0178 | Time 3.3900(3.5381) | Loss 157.591675(169.316656) | NFE Forward 26(25.5) | NFE Backward 105(104.5)\n",
      "Iter 0179 | Time 3.5765(3.5407) | Loss 157.585831(168.495498) | NFE Forward 26(25.5) | NFE Backward 105(104.5)\n",
      "Iter 0180 | Time 3.6419(3.5478) | Loss 156.611679(167.663631) | NFE Forward 26(25.6) | NFE Backward 105(104.5)\n",
      "Iter 0181 | Time 3.8002(3.5655) | Loss 156.375168(166.873438) | NFE Forward 26(25.6) | NFE Backward 105(104.6)\n",
      "Iter 0182 | Time 3.7535(3.5787) | Loss 155.781891(166.097030) | NFE Forward 26(25.6) | NFE Backward 105(104.6)\n",
      "Iter 0183 | Time 3.4022(3.5663) | Loss 156.770172(165.444150) | NFE Forward 26(25.6) | NFE Backward 105(104.6)\n",
      "Iter 0184 | Time 3.3147(3.5487) | Loss 154.297668(164.663896) | NFE Forward 26(25.7) | NFE Backward 105(104.6)\n",
      "Iter 0185 | Time 3.5779(3.5507) | Loss 152.979584(163.845994) | NFE Forward 26(25.7) | NFE Backward 105(104.7)\n",
      "Iter 0186 | Time 3.9079(3.5757) | Loss 152.611832(163.059603) | NFE Forward 26(25.7) | NFE Backward 105(104.7)\n",
      "Iter 0187 | Time 3.3751(3.5617) | Loss 151.060410(162.219659) | NFE Forward 20(25.3) | NFE Backward 105(104.7)\n",
      "Iter 0188 | Time 3.6435(3.5674) | Loss 152.600235(161.546300) | NFE Forward 26(25.4) | NFE Backward 105(104.7)\n",
      "Iter 0189 | Time 3.5616(3.5670) | Loss 150.803986(160.794338) | NFE Forward 20(25.0) | NFE Backward 105(104.8)\n",
      "Iter 0190 | Time 3.4728(3.5604) | Loss 148.745590(159.950925) | NFE Forward 26(25.1) | NFE Backward 105(104.8)\n",
      "Iter 0191 | Time 3.5024(3.5564) | Loss 148.797409(159.170179) | NFE Forward 26(25.1) | NFE Backward 105(104.8)\n",
      "Iter 0192 | Time 3.5934(3.5590) | Loss 150.442871(158.559268) | NFE Forward 20(24.8) | NFE Backward 105(104.8)\n",
      "Iter 0193 | Time 3.2959(3.5405) | Loss 149.041412(157.893018) | NFE Forward 20(24.4) | NFE Backward 105(104.8)\n",
      "Iter 0194 | Time 3.7184(3.5530) | Loss 148.587402(157.241625) | NFE Forward 26(24.5) | NFE Backward 105(104.8)\n",
      "Iter 0195 | Time 3.6172(3.5575) | Loss 147.193146(156.538231) | NFE Forward 26(24.6) | NFE Backward 105(104.8)\n",
      "Iter 0196 | Time 3.6708(3.5654) | Loss 146.127487(155.809479) | NFE Forward 26(24.7) | NFE Backward 105(104.9)\n",
      "Iter 0197 | Time 3.5158(3.5619) | Loss 144.631577(155.027026) | NFE Forward 26(24.8) | NFE Backward 105(104.9)\n",
      "Iter 0198 | Time 3.1244(3.5313) | Loss 143.301483(154.206238) | NFE Forward 20(24.5) | NFE Backward 105(104.9)\n",
      "Iter 0199 | Time 3.3072(3.5156) | Loss 143.340195(153.445615) | NFE Forward 26(24.6) | NFE Backward 99(104.5)\n",
      "Iter 0200 | Time 3.5548(3.5184) | Loss 144.170425(152.796352) | NFE Forward 20(24.3) | NFE Backward 105(104.5)\n",
      "[TEST] Iter 0200 | Test Loss 141.629486 | NFE 26\n",
      "Skipping vis as data dimension is >2\n",
      "Iter 0201 | Time 3.3781(3.5086) | Loss 143.185028(152.123559) | NFE Forward 20(24.0) | NFE Backward 105(104.5)\n",
      "Iter 0202 | Time 3.5801(3.5136) | Loss 141.447235(151.376216) | NFE Forward 26(24.1) | NFE Backward 105(104.6)\n",
      "Iter 0203 | Time 3.5956(3.5193) | Loss 142.084000(150.725761) | NFE Forward 20(23.8) | NFE Backward 105(104.6)\n",
      "Iter 0204 | Time 3.9192(3.5473) | Loss 140.786896(150.030041) | NFE Forward 20(23.6) | NFE Backward 105(104.6)\n",
      "Iter 0205 | Time 3.7629(3.5624) | Loss 139.128769(149.266952) | NFE Forward 20(23.3) | NFE Backward 105(104.7)\n",
      "Iter 0206 | Time 3.5782(3.5635) | Loss 138.959076(148.545400) | NFE Forward 20(23.1) | NFE Backward 105(104.7)\n",
      "Iter 0207 | Time 3.7673(3.5778) | Loss 138.584000(147.848102) | NFE Forward 20(22.9) | NFE Backward 105(104.7)\n",
      "Iter 0208 | Time 3.5335(3.5747) | Loss 137.550674(147.127282) | NFE Forward 26(23.1) | NFE Backward 105(104.7)\n",
      "Iter 0209 | Time 3.9632(3.6019) | Loss 137.097580(146.425203) | NFE Forward 20(22.9) | NFE Backward 105(104.7)\n",
      "Iter 0210 | Time 3.5828(3.6005) | Loss 135.529938(145.662535) | NFE Forward 20(22.7) | NFE Backward 105(104.8)\n",
      "Iter 0211 | Time 6.9364(3.8340) | Loss 135.518234(144.952434) | NFE Forward 20(22.5) | NFE Backward 105(104.8)\n",
      "Iter 0212 | Time 5.5365(3.9532) | Loss 134.318375(144.208049) | NFE Forward 20(22.3) | NFE Backward 105(104.8)\n",
      "Iter 0213 | Time 7.4647(4.1990) | Loss 136.314087(143.655472) | NFE Forward 20(22.1) | NFE Backward 105(104.8)\n",
      "Iter 0214 | Time 6.8036(4.3813) | Loss 135.268616(143.068392) | NFE Forward 26(22.4) | NFE Backward 105(104.8)\n",
      "Iter 0215 | Time 6.7209(4.5451) | Loss 132.998886(142.363527) | NFE Forward 26(22.7) | NFE Backward 105(104.8)\n",
      "Iter 0216 | Time 5.5550(4.6158) | Loss 132.967453(141.705802) | NFE Forward 20(22.5) | NFE Backward 105(104.8)\n",
      "Iter 0217 | Time 5.5561(4.6816) | Loss 132.708054(141.075959) | NFE Forward 20(22.3) | NFE Backward 105(104.9)\n",
      "Iter 0218 | Time 5.2577(4.7219) | Loss 132.094849(140.447281) | NFE Forward 20(22.1) | NFE Backward 105(104.9)\n",
      "Iter 0219 | Time 6.2927(4.8319) | Loss 131.349808(139.810458) | NFE Forward 26(22.4) | NFE Backward 105(104.9)\n",
      "Iter 0220 | Time 6.3110(4.9354) | Loss 130.569550(139.163595) | NFE Forward 20(22.2) | NFE Backward 105(104.9)\n",
      "Iter 0221 | Time 6.1027(5.0171) | Loss 130.070160(138.527054) | NFE Forward 20(22.1) | NFE Backward 105(104.9)\n",
      "Iter 0222 | Time 5.8391(5.0747) | Loss 128.746552(137.842419) | NFE Forward 20(21.9) | NFE Backward 105(104.9)\n",
      "Iter 0223 | Time 4.9809(5.0681) | Loss 127.613968(137.126427) | NFE Forward 20(21.8) | NFE Backward 105(104.9)\n",
      "Iter 0224 | Time 5.1293(5.0724) | Loss 128.426987(136.517467) | NFE Forward 20(21.7) | NFE Backward 105(104.9)\n",
      "Iter 0225 | Time 5.3661(5.0930) | Loss 126.277061(135.800638) | NFE Forward 20(21.6) | NFE Backward 105(104.9)\n",
      "Iter 0226 | Time 6.6982(5.2053) | Loss 126.661697(135.160912) | NFE Forward 20(21.5) | NFE Backward 105(104.9)\n",
      "Iter 0227 | Time 8.2493(5.4184) | Loss 124.780823(134.434306) | NFE Forward 20(21.4) | NFE Backward 105(104.9)\n",
      "Iter 0228 | Time 6.1989(5.4730) | Loss 126.457138(133.875904) | NFE Forward 20(21.3) | NFE Backward 105(104.9)\n",
      "Iter 0229 | Time 6.1069(5.5174) | Loss 123.944862(133.180731) | NFE Forward 20(21.2) | NFE Backward 105(104.9)\n",
      "Iter 0230 | Time 6.9081(5.6148) | Loss 124.408005(132.566641) | NFE Forward 20(21.1) | NFE Backward 105(104.9)\n",
      "Iter 0231 | Time 5.3128(5.5936) | Loss 123.184555(131.909895) | NFE Forward 26(21.4) | NFE Backward 105(104.9)\n",
      "Iter 0232 | Time 5.4177(5.5813) | Loss 123.559349(131.325356) | NFE Forward 20(21.3) | NFE Backward 105(105.0)\n",
      "Iter 0233 | Time 4.7077(5.5202) | Loss 123.997520(130.812408) | NFE Forward 20(21.2) | NFE Backward 105(105.0)\n",
      "Iter 0234 | Time 4.7741(5.4679) | Loss 122.248001(130.212899) | NFE Forward 20(21.2) | NFE Backward 105(105.0)\n",
      "Iter 0235 | Time 5.0433(5.4382) | Loss 121.632301(129.612258) | NFE Forward 20(21.1) | NFE Backward 105(105.0)\n",
      "Iter 0236 | Time 4.7789(5.3920) | Loss 121.015907(129.010513) | NFE Forward 26(21.4) | NFE Backward 105(105.0)\n",
      "Iter 0237 | Time 3.7689(5.2784) | Loss 120.382568(128.406557) | NFE Forward 20(21.3) | NFE Backward 105(105.0)\n",
      "Iter 0238 | Time 3.6524(5.1646) | Loss 120.798721(127.874008) | NFE Forward 20(21.2) | NFE Backward 105(105.0)\n",
      "Iter 0239 | Time 3.5345(5.0505) | Loss 119.924171(127.317520) | NFE Forward 26(21.6) | NFE Backward 105(105.0)\n",
      "Iter 0240 | Time 3.7061(4.9564) | Loss 118.550735(126.703845) | NFE Forward 32(22.3) | NFE Backward 105(105.0)\n",
      "Iter 0241 | Time 3.7584(4.8725) | Loss 118.201439(126.108676) | NFE Forward 26(22.5) | NFE Backward 105(105.0)\n",
      "Iter 0242 | Time 3.6662(4.7881) | Loss 117.625961(125.514886) | NFE Forward 26(22.8) | NFE Backward 105(105.0)\n",
      "Iter 0243 | Time 3.7799(4.7175) | Loss 117.855141(124.978704) | NFE Forward 26(23.0) | NFE Backward 105(105.0)\n",
      "Iter 0244 | Time 3.6190(4.6406) | Loss 117.075195(124.425459) | NFE Forward 32(23.6) | NFE Backward 105(105.0)\n",
      "Iter 0245 | Time 5.3134(4.6877) | Loss 118.473000(124.008786) | NFE Forward 26(23.8) | NFE Backward 105(105.0)\n",
      "Iter 0246 | Time 5.4195(4.7389) | Loss 116.200172(123.462183) | NFE Forward 26(24.0) | NFE Backward 105(105.0)\n",
      "Iter 0247 | Time 5.3191(4.7795) | Loss 115.537621(122.907464) | NFE Forward 26(24.1) | NFE Backward 105(105.0)\n",
      "Iter 0248 | Time 4.2620(4.7433) | Loss 115.366653(122.379607) | NFE Forward 32(24.7) | NFE Backward 105(105.0)\n",
      "Iter 0249 | Time 4.7899(4.7466) | Loss 113.500565(121.758074) | NFE Forward 26(24.8) | NFE Backward 105(105.0)\n",
      "Iter 0250 | Time 5.1783(4.7768) | Loss 114.173767(121.227173) | NFE Forward 26(24.8) | NFE Backward 105(105.0)\n",
      "Iter 0251 | Time 6.6927(4.9109) | Loss 113.076988(120.656660) | NFE Forward 32(25.3) | NFE Backward 111(105.4)\n",
      "Iter 0252 | Time 5.2375(4.9338) | Loss 112.881615(120.112407) | NFE Forward 32(25.8) | NFE Backward 105(105.4)\n",
      "Iter 0253 | Time 5.0723(4.9435) | Loss 111.737465(119.526161) | NFE Forward 26(25.8) | NFE Backward 105(105.4)\n",
      "Iter 0254 | Time 4.8934(4.9400) | Loss 111.792709(118.984819) | NFE Forward 26(25.8) | NFE Backward 105(105.3)\n",
      "Iter 0255 | Time 4.6360(4.9187) | Loss 110.995766(118.425585) | NFE Forward 32(26.3) | NFE Backward 111(105.7)\n",
      "Iter 0256 | Time 3.6603(4.8306) | Loss 110.744919(117.887939) | NFE Forward 32(26.7) | NFE Backward 105(105.7)\n",
      "Iter 0257 | Time 5.1051(4.8498) | Loss 110.412193(117.364637) | NFE Forward 26(26.6) | NFE Backward 105(105.6)\n",
      "Iter 0258 | Time 6.8206(4.9878) | Loss 110.190086(116.862418) | NFE Forward 26(26.6) | NFE Backward 111(106.0)\n",
      "Iter 0259 | Time 6.0232(5.0602) | Loss 108.748123(116.294417) | NFE Forward 26(26.5) | NFE Backward 111(106.4)\n",
      "Iter 0260 | Time 4.5771(5.0264) | Loss 108.847351(115.773123) | NFE Forward 26(26.5) | NFE Backward 111(106.7)\n",
      "Iter 0261 | Time 5.1137(5.0325) | Loss 108.241745(115.245926) | NFE Forward 32(26.9) | NFE Backward 111(107.0)\n",
      "Iter 0262 | Time 4.9653(5.0278) | Loss 107.978714(114.737221) | NFE Forward 26(26.8) | NFE Backward 111(107.3)\n",
      "Iter 0263 | Time 7.2789(5.1854) | Loss 107.518028(114.231878) | NFE Forward 32(27.2) | NFE Backward 111(107.5)\n",
      "Iter 0264 | Time 3.9312(5.0976) | Loss 107.036179(113.728179) | NFE Forward 32(27.5) | NFE Backward 111(107.8)\n",
      "Iter 0265 | Time 3.7269(5.0017) | Loss 106.546288(113.225447) | NFE Forward 26(27.4) | NFE Backward 111(108.0)\n",
      "Iter 0266 | Time 4.2591(4.9497) | Loss 105.582863(112.690466) | NFE Forward 32(27.7) | NFE Backward 111(108.2)\n",
      "Iter 0267 | Time 4.7483(4.9356) | Loss 105.578491(112.192628) | NFE Forward 26(27.6) | NFE Backward 111(108.4)\n",
      "Iter 0268 | Time 3.8261(4.8579) | Loss 105.935837(111.754652) | NFE Forward 32(27.9) | NFE Backward 111(108.6)\n",
      "Iter 0269 | Time 3.9366(4.7934) | Loss 104.439415(111.242586) | NFE Forward 26(27.8) | NFE Backward 111(108.8)\n",
      "Iter 0270 | Time 3.8720(4.7289) | Loss 103.578903(110.706128) | NFE Forward 32(28.1) | NFE Backward 111(108.9)\n",
      "Iter 0271 | Time 3.8506(4.6674) | Loss 103.272926(110.185804) | NFE Forward 26(27.9) | NFE Backward 111(109.1)\n",
      "Iter 0272 | Time 3.9571(4.6177) | Loss 102.840897(109.671660) | NFE Forward 32(28.2) | NFE Backward 111(109.2)\n",
      "Iter 0273 | Time 4.0917(4.5809) | Loss 102.917625(109.198878) | NFE Forward 26(28.1) | NFE Backward 111(109.3)\n",
      "Iter 0274 | Time 3.9678(4.5380) | Loss 101.887718(108.687097) | NFE Forward 26(27.9) | NFE Backward 111(109.4)\n",
      "Iter 0275 | Time 4.0369(4.5029) | Loss 102.310791(108.240755) | NFE Forward 26(27.8) | NFE Backward 111(109.5)\n",
      "Iter 0276 | Time 4.0423(4.4707) | Loss 102.294090(107.824489) | NFE Forward 32(28.1) | NFE Backward 111(109.6)\n",
      "Iter 0277 | Time 4.1850(4.4507) | Loss 101.935417(107.412254) | NFE Forward 32(28.4) | NFE Backward 111(109.7)\n",
      "Iter 0278 | Time 3.8716(4.4101) | Loss 101.319687(106.985774) | NFE Forward 26(28.2) | NFE Backward 111(109.8)\n",
      "Iter 0279 | Time 4.1139(4.3894) | Loss 99.945053(106.492924) | NFE Forward 26(28.0) | NFE Backward 111(109.9)\n",
      "Iter 0280 | Time 3.8247(4.3499) | Loss 99.645004(106.013569) | NFE Forward 26(27.9) | NFE Backward 111(110.0)\n",
      "Iter 0281 | Time 4.0564(4.3293) | Loss 99.136719(105.532190) | NFE Forward 32(28.2) | NFE Backward 111(110.1)\n",
      "Iter 0282 | Time 4.1348(4.3157) | Loss 99.362755(105.100329) | NFE Forward 26(28.0) | NFE Backward 111(110.1)\n",
      "Iter 0283 | Time 4.1917(4.3070) | Loss 98.931190(104.668489) | NFE Forward 32(28.3) | NFE Backward 111(110.2)\n",
      "Iter 0284 | Time 4.1024(4.2927) | Loss 98.368851(104.227515) | NFE Forward 32(28.6) | NFE Backward 111(110.2)\n",
      "Iter 0285 | Time 3.9089(4.2658) | Loss 98.430580(103.821729) | NFE Forward 32(28.8) | NFE Backward 111(110.3)\n",
      "Iter 0286 | Time 4.0885(4.2534) | Loss 95.905685(103.267606) | NFE Forward 32(29.0) | NFE Backward 111(110.3)\n",
      "Iter 0287 | Time 3.8971(4.2285) | Loss 97.916428(102.893024) | NFE Forward 26(28.8) | NFE Backward 111(110.4)\n",
      "Iter 0288 | Time 4.0624(4.2169) | Loss 96.876915(102.471896) | NFE Forward 38(29.5) | NFE Backward 111(110.4)\n",
      "Iter 0289 | Time 4.1452(4.2118) | Loss 96.828102(102.076831) | NFE Forward 32(29.6) | NFE Backward 111(110.5)\n",
      "Iter 0290 | Time 3.9331(4.1923) | Loss 95.829636(101.639527) | NFE Forward 26(29.4) | NFE Backward 111(110.5)\n",
      "Iter 0291 | Time 4.2174(4.1941) | Loss 95.334839(101.198199) | NFE Forward 26(29.1) | NFE Backward 117(111.0)\n",
      "Iter 0292 | Time 4.3326(4.2038) | Loss 94.713524(100.744272) | NFE Forward 26(28.9) | NFE Backward 117(111.4)\n",
      "Iter 0293 | Time 4.4587(4.2216) | Loss 94.788574(100.327373) | NFE Forward 38(29.6) | NFE Backward 117(111.8)\n",
      "Iter 0294 | Time 4.2609(4.2244) | Loss 93.640175(99.859269) | NFE Forward 26(29.3) | NFE Backward 117(112.1)\n",
      "Iter 0295 | Time 4.6440(4.2538) | Loss 93.383621(99.405974) | NFE Forward 26(29.1) | NFE Backward 111(112.1)\n",
      "Iter 0296 | Time 3.8794(4.2275) | Loss 93.894180(99.020148) | NFE Forward 32(29.3) | NFE Backward 111(112.0)\n",
      "Iter 0297 | Time 4.2593(4.2298) | Loss 93.076126(98.604066) | NFE Forward 26(29.1) | NFE Backward 117(112.3)\n",
      "Iter 0298 | Time 4.0542(4.2175) | Loss 92.377289(98.168192) | NFE Forward 26(28.8) | NFE Backward 111(112.2)\n",
      "Iter 0299 | Time 4.8039(4.2585) | Loss 92.382751(97.763211) | NFE Forward 44(29.9) | NFE Backward 117(112.6)\n",
      "Iter 0300 | Time 4.5478(4.2788) | Loss 92.928177(97.424759) | NFE Forward 44(30.9) | NFE Backward 111(112.5)\n",
      "[TEST] Iter 0300 | Test Loss 91.213272 | NFE 32\n",
      "Skipping vis as data dimension is >2\n",
      "Iter 0301 | Time 5.2547(4.3471) | Loss 91.433914(97.005400) | NFE Forward 44(31.8) | NFE Backward 111(112.4)\n",
      "Iter 0302 | Time 4.5700(4.3627) | Loss 92.203331(96.669255) | NFE Forward 38(32.2) | NFE Backward 111(112.3)\n",
      "Iter 0303 | Time 4.2609(4.3556) | Loss 90.956482(96.269361) | NFE Forward 26(31.8) | NFE Backward 111(112.2)\n",
      "Iter 0304 | Time 4.0393(4.3334) | Loss 90.206322(95.844948) | NFE Forward 44(32.7) | NFE Backward 111(112.1)\n",
      "Iter 0305 | Time 4.2709(4.3290) | Loss 90.129066(95.444836) | NFE Forward 38(33.0) | NFE Backward 111(112.0)\n",
      "Iter 0306 | Time 4.5084(4.3416) | Loss 90.182091(95.076444) | NFE Forward 32(33.0) | NFE Backward 111(112.0)\n",
      "Iter 0307 | Time 4.4507(4.3492) | Loss 89.596077(94.692818) | NFE Forward 38(33.3) | NFE Backward 117(112.3)\n",
      "Iter 0308 | Time 4.1989(4.3387) | Loss 88.723938(94.274997) | NFE Forward 38(33.6) | NFE Backward 111(112.2)\n",
      "Iter 0309 | Time 4.3560(4.3399) | Loss 89.142509(93.915723) | NFE Forward 38(33.9) | NFE Backward 111(112.1)\n",
      "Iter 0310 | Time 4.0586(4.3202) | Loss 87.835655(93.490118) | NFE Forward 38(34.2) | NFE Backward 111(112.0)\n",
      "Iter 0311 | Time 3.9983(4.2977) | Loss 88.637138(93.150409) | NFE Forward 38(34.5) | NFE Backward 111(112.0)\n",
      "Iter 0312 | Time 4.2679(4.2956) | Loss 87.764732(92.773412) | NFE Forward 44(35.2) | NFE Backward 111(111.9)\n",
      "Iter 0313 | Time 4.4480(4.3063) | Loss 87.456825(92.401251) | NFE Forward 38(35.4) | NFE Backward 117(112.3)\n",
      "Iter 0314 | Time 4.5008(4.3199) | Loss 88.293030(92.113675) | NFE Forward 38(35.5) | NFE Backward 117(112.6)\n",
      "Iter 0315 | Time 4.1175(4.3057) | Loss 87.089073(91.761953) | NFE Forward 38(35.7) | NFE Backward 111(112.5)\n",
      "Iter 0316 | Time 4.6895(4.3326) | Loss 87.112694(91.436505) | NFE Forward 38(35.9) | NFE Backward 111(112.4)\n",
      "Iter 0317 | Time 4.6059(4.3517) | Loss 85.785339(91.040924) | NFE Forward 38(36.0) | NFE Backward 111(112.3)\n",
      "Iter 0318 | Time 4.3726(4.3532) | Loss 85.919281(90.682409) | NFE Forward 32(35.7) | NFE Backward 111(112.2)\n",
      "Iter 0319 | Time 4.3386(4.3522) | Loss 85.746758(90.336913) | NFE Forward 32(35.5) | NFE Backward 111(112.1)\n",
      "Iter 0320 | Time 4.7510(4.3801) | Loss 85.234825(89.979767) | NFE Forward 44(36.1) | NFE Backward 117(112.5)\n",
      "Iter 0321 | Time 4.2944(4.3741) | Loss 85.800697(89.687232) | NFE Forward 38(36.2) | NFE Backward 111(112.4)\n",
      "Iter 0322 | Time 4.3504(4.3724) | Loss 84.299210(89.310070) | NFE Forward 44(36.8) | NFE Backward 111(112.3)\n",
      "Iter 0323 | Time 5.0513(4.4200) | Loss 84.555191(88.977229) | NFE Forward 44(37.3) | NFE Backward 111(112.2)\n",
      "Iter 0324 | Time 5.0031(4.4608) | Loss 84.492905(88.663326) | NFE Forward 44(37.7) | NFE Backward 111(112.1)\n",
      "Iter 0325 | Time 4.6052(4.4709) | Loss 83.899109(88.329831) | NFE Forward 38(37.8) | NFE Backward 111(112.0)\n",
      "Iter 0326 | Time 3.8907(4.4303) | Loss 83.024628(87.958467) | NFE Forward 44(38.2) | NFE Backward 117(112.4)\n",
      "Iter 0327 | Time 4.4416(4.4311) | Loss 82.549049(87.579807) | NFE Forward 50(39.0) | NFE Backward 123(113.1)\n",
      "Iter 0328 | Time 4.2302(4.4170) | Loss 82.885239(87.251188) | NFE Forward 38(38.9) | NFE Backward 117(113.4)\n",
      "Iter 0329 | Time 4.1892(4.4011) | Loss 83.008415(86.954194) | NFE Forward 50(39.7) | NFE Backward 111(113.2)\n",
      "Iter 0330 | Time 4.6439(4.4181) | Loss 82.052658(86.611086) | NFE Forward 44(40.0) | NFE Backward 123(113.9)\n",
      "Iter 0331 | Time 4.4176(4.4180) | Loss 81.395287(86.245980) | NFE Forward 38(39.9) | NFE Backward 117(114.1)\n",
      "Iter 0332 | Time 5.1389(4.4685) | Loss 81.375008(85.905012) | NFE Forward 44(40.2) | NFE Backward 123(114.7)\n",
      "Iter 0333 | Time 4.2532(4.4534) | Loss 81.327026(85.584553) | NFE Forward 44(40.4) | NFE Backward 111(114.5)\n",
      "Iter 0334 | Time 4.6717(4.4687) | Loss 80.952255(85.260292) | NFE Forward 44(40.7) | NFE Backward 123(115.1)\n",
      "Iter 0335 | Time 4.5717(4.4759) | Loss 81.581345(85.002766) | NFE Forward 38(40.5) | NFE Backward 123(115.6)\n",
      "Iter 0336 | Time 5.9002(4.5756) | Loss 80.961838(84.719901) | NFE Forward 50(41.2) | NFE Backward 123(116.1)\n",
      "Iter 0337 | Time 4.1931(4.5488) | Loss 80.026840(84.391387) | NFE Forward 44(41.4) | NFE Backward 117(116.2)\n",
      "Iter 0338 | Time 4.4478(4.5418) | Loss 80.130760(84.093143) | NFE Forward 44(41.5) | NFE Backward 123(116.7)\n",
      "Iter 0339 | Time 4.0997(4.5108) | Loss 79.600731(83.778674) | NFE Forward 38(41.3) | NFE Backward 117(116.7)\n",
      "Iter 0340 | Time 4.3118(4.4969) | Loss 80.562675(83.553554) | NFE Forward 44(41.5) | NFE Backward 117(116.7)\n",
      "Iter 0341 | Time 4.2917(4.4825) | Loss 79.305229(83.256171) | NFE Forward 44(41.7) | NFE Backward 123(117.2)\n",
      "Iter 0342 | Time 4.6493(4.4942) | Loss 79.334946(82.981686) | NFE Forward 44(41.8) | NFE Backward 123(117.6)\n",
      "Iter 0343 | Time 4.5966(4.5014) | Loss 78.884033(82.694850) | NFE Forward 44(42.0) | NFE Backward 123(117.9)\n",
      "Iter 0344 | Time 5.1621(4.5476) | Loss 79.520393(82.472638) | NFE Forward 50(42.5) | NFE Backward 123(118.3)\n",
      "Iter 0345 | Time 4.7651(4.5628) | Loss 78.065819(82.164161) | NFE Forward 44(42.6) | NFE Backward 123(118.6)\n",
      "Iter 0346 | Time 5.1351(4.6029) | Loss 77.694054(81.851253) | NFE Forward 44(42.7) | NFE Backward 123(118.9)\n",
      "Iter 0347 | Time 5.2846(4.6506) | Loss 78.093758(81.588228) | NFE Forward 44(42.8) | NFE Backward 117(118.8)\n",
      "Iter 0348 | Time 5.2630(4.6935) | Loss 77.520569(81.303492) | NFE Forward 44(42.9) | NFE Backward 123(119.1)\n",
      "Iter 0349 | Time 5.7560(4.7679) | Loss 77.650139(81.047758) | NFE Forward 50(43.4) | NFE Backward 123(119.4)\n",
      "Iter 0350 | Time 5.1707(4.7961) | Loss 77.557693(80.803453) | NFE Forward 44(43.4) | NFE Backward 123(119.6)\n",
      "Iter 0351 | Time 5.1748(4.8226) | Loss 76.903603(80.530464) | NFE Forward 50(43.9) | NFE Backward 123(119.9)\n",
      "Iter 0352 | Time 4.7476(4.8173) | Loss 76.461464(80.245634) | NFE Forward 44(43.9) | NFE Backward 123(120.1)\n",
      "Iter 0353 | Time 4.7300(4.8112) | Loss 76.439751(79.979222) | NFE Forward 50(44.3) | NFE Backward 123(120.3)\n",
      "Iter 0354 | Time 4.7430(4.8064) | Loss 75.822311(79.688238) | NFE Forward 44(44.3) | NFE Backward 123(120.5)\n",
      "Iter 0355 | Time 6.0672(4.8947) | Loss 76.907120(79.493560) | NFE Forward 44(44.3) | NFE Backward 129(121.1)\n",
      "Iter 0356 | Time 5.2652(4.9206) | Loss 75.726128(79.229839) | NFE Forward 44(44.3) | NFE Backward 123(121.2)\n",
      "Iter 0357 | Time 4.8601(4.9164) | Loss 75.156319(78.944693) | NFE Forward 50(44.7) | NFE Backward 123(121.3)\n",
      "Iter 0358 | Time 4.9704(4.9202) | Loss 75.070824(78.673522) | NFE Forward 44(44.6) | NFE Backward 129(121.9)\n",
      "Iter 0359 | Time 4.5489(4.8942) | Loss 75.411682(78.445193) | NFE Forward 44(44.6) | NFE Backward 123(121.9)\n",
      "Iter 0360 | Time 5.1171(4.9098) | Loss 75.102356(78.211195) | NFE Forward 50(45.0) | NFE Backward 123(122.0)\n",
      "Iter 0361 | Time 4.8035(4.9023) | Loss 74.371712(77.942431) | NFE Forward 50(45.3) | NFE Backward 123(122.1)\n",
      "Iter 0362 | Time 4.6081(4.8817) | Loss 74.921814(77.730988) | NFE Forward 50(45.6) | NFE Backward 123(122.2)\n",
      "Iter 0363 | Time 5.7066(4.9395) | Loss 73.779800(77.454405) | NFE Forward 44(45.5) | NFE Backward 129(122.6)\n",
      "Iter 0364 | Time 4.6792(4.9213) | Loss 73.327187(77.165499) | NFE Forward 44(45.4) | NFE Backward 123(122.7)\n",
      "Iter 0365 | Time 5.7114(4.9766) | Loss 73.627174(76.917817) | NFE Forward 44(45.3) | NFE Backward 123(122.7)\n",
      "Iter 0366 | Time 5.5484(5.0166) | Loss 74.131790(76.722795) | NFE Forward 50(45.6) | NFE Backward 123(122.7)\n",
      "Iter 0367 | Time 5.6334(5.0598) | Loss 72.843224(76.451225) | NFE Forward 44(45.5) | NFE Backward 123(122.7)\n",
      "Iter 0368 | Time 6.0227(5.1272) | Loss 73.052109(76.213287) | NFE Forward 44(45.4) | NFE Backward 123(122.7)\n",
      "Iter 0369 | Time 6.9101(5.2520) | Loss 72.373642(75.944512) | NFE Forward 50(45.7) | NFE Backward 123(122.8)\n",
      "Iter 0370 | Time 6.0132(5.3053) | Loss 72.970016(75.736297) | NFE Forward 50(46.0) | NFE Backward 123(122.8)\n",
      "Iter 0371 | Time 5.3507(5.3085) | Loss 72.518349(75.511041) | NFE Forward 50(46.3) | NFE Backward 123(122.8)\n",
      "Iter 0372 | Time 5.5979(5.3287) | Loss 72.024979(75.267016) | NFE Forward 50(46.6) | NFE Backward 123(122.8)\n",
      "Iter 0373 | Time 5.3125(5.3276) | Loss 72.489212(75.072570) | NFE Forward 44(46.4) | NFE Backward 123(122.8)\n",
      "Iter 0374 | Time 6.3434(5.3987) | Loss 72.035149(74.859950) | NFE Forward 44(46.2) | NFE Backward 123(122.8)\n",
      "Iter 0375 | Time 5.7543(5.4236) | Loss 71.508438(74.625345) | NFE Forward 44(46.1) | NFE Backward 123(122.8)\n",
      "Iter 0376 | Time 6.9113(5.5277) | Loss 71.420303(74.400992) | NFE Forward 50(46.3) | NFE Backward 123(122.9)\n",
      "Iter 0377 | Time 5.3546(5.5156) | Loss 71.165237(74.174489) | NFE Forward 50(46.6) | NFE Backward 123(122.9)\n",
      "Iter 0378 | Time 4.9283(5.4745) | Loss 71.456497(73.984229) | NFE Forward 50(46.8) | NFE Backward 123(122.9)\n",
      "Iter 0379 | Time 5.6553(5.4871) | Loss 70.858818(73.765451) | NFE Forward 44(46.6) | NFE Backward 123(122.9)\n",
      "Iter 0380 | Time 5.9852(5.5220) | Loss 70.499405(73.536827) | NFE Forward 50(46.9) | NFE Backward 123(122.9)\n",
      "Iter 0381 | Time 5.9897(5.5547) | Loss 70.275368(73.308525) | NFE Forward 44(46.7) | NFE Backward 123(122.9)\n",
      "Iter 0382 | Time 6.5076(5.6214) | Loss 70.203636(73.091183) | NFE Forward 50(46.9) | NFE Backward 123(122.9)\n",
      "Iter 0383 | Time 6.3982(5.6758) | Loss 69.742538(72.856778) | NFE Forward 50(47.1) | NFE Backward 123(122.9)\n",
      "Iter 0384 | Time 6.0910(5.7049) | Loss 69.870560(72.647743) | NFE Forward 50(47.3) | NFE Backward 123(122.9)\n",
      "Iter 0385 | Time 6.0777(5.7310) | Loss 69.427597(72.422332) | NFE Forward 44(47.1) | NFE Backward 123(122.9)\n",
      "Iter 0386 | Time 6.4186(5.7791) | Loss 69.465332(72.215342) | NFE Forward 44(46.9) | NFE Backward 123(122.9)\n",
      "Iter 0387 | Time 6.1877(5.8077) | Loss 68.556801(71.959245) | NFE Forward 44(46.7) | NFE Backward 123(122.9)\n",
      "Iter 0388 | Time 7.2115(5.9060) | Loss 69.050468(71.755630) | NFE Forward 44(46.5) | NFE Backward 123(122.9)\n",
      "Iter 0389 | Time 6.8857(5.9746) | Loss 68.399948(71.520732) | NFE Forward 50(46.7) | NFE Backward 123(122.9)\n",
      "Iter 0390 | Time 6.7131(6.0263) | Loss 68.554420(71.313091) | NFE Forward 44(46.5) | NFE Backward 123(122.9)\n",
      "Iter 0391 | Time 8.6022(6.2066) | Loss 68.032204(71.083429) | NFE Forward 44(46.4) | NFE Backward 123(123.0)\n",
      "Iter 0392 | Time 6.6737(6.2393) | Loss 68.545181(70.905751) | NFE Forward 44(46.2) | NFE Backward 123(123.0)\n",
      "Iter 0393 | Time 6.1608(6.2338) | Loss 68.265846(70.720958) | NFE Forward 50(46.5) | NFE Backward 123(123.0)\n",
      "Iter 0394 | Time 6.6127(6.2603) | Loss 67.700592(70.509532) | NFE Forward 44(46.3) | NFE Backward 123(123.0)\n",
      "Iter 0395 | Time 6.8087(6.2987) | Loss 67.509171(70.299507) | NFE Forward 44(46.1) | NFE Backward 123(123.0)\n",
      "Iter 0396 | Time 7.3286(6.3708) | Loss 67.903366(70.131777) | NFE Forward 50(46.4) | NFE Backward 123(123.0)\n",
      "Iter 0397 | Time 6.4856(6.3788) | Loss 68.080017(69.988154) | NFE Forward 50(46.7) | NFE Backward 123(123.0)\n",
      "Iter 0398 | Time 5.9947(6.3519) | Loss 67.052452(69.782655) | NFE Forward 50(46.9) | NFE Backward 123(123.0)\n",
      "Iter 0399 | Time 6.4686(6.3601) | Loss 66.902023(69.581011) | NFE Forward 44(46.7) | NFE Backward 123(123.0)\n",
      "Iter 0400 | Time 6.4818(6.3686) | Loss 67.385986(69.427359) | NFE Forward 44(46.5) | NFE Backward 123(123.0)\n",
      "[TEST] Iter 0400 | Test Loss 66.207779 | NFE 44\n",
      "Skipping vis as data dimension is >2\n",
      "Iter 0401 | Time 6.7125(6.3927) | Loss 65.866943(69.178130) | NFE Forward 44(46.3) | NFE Backward 123(123.0)\n",
      "Iter 0402 | Time 7.4894(6.4695) | Loss 66.378250(68.982138) | NFE Forward 56(47.0) | NFE Backward 123(123.0)\n",
      "Iter 0403 | Time 8.0199(6.5780) | Loss 66.289925(68.793683) | NFE Forward 50(47.2) | NFE Backward 123(123.0)\n",
      "Iter 0404 | Time 8.6569(6.7235) | Loss 66.254776(68.615960) | NFE Forward 44(47.0) | NFE Backward 123(123.0)\n",
      "Iter 0405 | Time 6.5817(6.7136) | Loss 65.997543(68.432671) | NFE Forward 44(46.8) | NFE Backward 123(123.0)\n",
      "Iter 0406 | Time 7.4073(6.7621) | Loss 65.797806(68.248230) | NFE Forward 44(46.6) | NFE Backward 123(123.0)\n",
      "Iter 0407 | Time 8.7611(6.9021) | Loss 65.921524(68.085361) | NFE Forward 50(46.8) | NFE Backward 123(123.0)\n",
      "Iter 0408 | Time 6.3731(6.8650) | Loss 65.485603(67.903378) | NFE Forward 44(46.6) | NFE Backward 123(123.0)\n",
      "Iter 0409 | Time 7.3532(6.8992) | Loss 64.467667(67.662878) | NFE Forward 50(46.9) | NFE Backward 123(123.0)\n",
      "Iter 0410 | Time 6.4473(6.8676) | Loss 65.457382(67.508493) | NFE Forward 44(46.7) | NFE Backward 123(123.0)\n",
      "Iter 0411 | Time 6.0926(6.8133) | Loss 65.020988(67.334368) | NFE Forward 50(46.9) | NFE Backward 123(123.0)\n",
      "Iter 0412 | Time 6.3100(6.7781) | Loss 64.479149(67.134502) | NFE Forward 44(46.7) | NFE Backward 123(123.0)\n",
      "Iter 0413 | Time 6.8684(6.7844) | Loss 64.655411(66.960966) | NFE Forward 44(46.5) | NFE Backward 123(123.0)\n",
      "Iter 0414 | Time 8.6702(6.9164) | Loss 65.019058(66.825033) | NFE Forward 44(46.3) | NFE Backward 123(123.0)\n",
      "Iter 0415 | Time 6.4370(6.8829) | Loss 64.303963(66.648558) | NFE Forward 44(46.2) | NFE Backward 123(123.0)\n",
      "Iter 0416 | Time 6.5228(6.8577) | Loss 64.234001(66.479539) | NFE Forward 50(46.4) | NFE Backward 123(123.0)\n",
      "Iter 0417 | Time 6.3933(6.8252) | Loss 64.211571(66.320781) | NFE Forward 50(46.7) | NFE Backward 123(123.0)\n",
      "Iter 0418 | Time 6.3318(6.7906) | Loss 63.953056(66.155040) | NFE Forward 44(46.5) | NFE Backward 123(123.0)\n",
      "Iter 0419 | Time 5.8073(6.7218) | Loss 63.695965(65.982905) | NFE Forward 44(46.3) | NFE Backward 123(123.0)\n",
      "Iter 0420 | Time 5.9599(6.6685) | Loss 63.386147(65.801132) | NFE Forward 44(46.2) | NFE Backward 123(123.0)\n",
      "Iter 0421 | Time 4.5449(6.5198) | Loss 62.640312(65.579874) | NFE Forward 44(46.0) | NFE Backward 123(123.0)\n",
      "Iter 0422 | Time 4.4029(6.3716) | Loss 63.504772(65.434617) | NFE Forward 44(45.9) | NFE Backward 123(123.0)\n",
      "Iter 0423 | Time 4.7331(6.2569) | Loss 63.458588(65.296295) | NFE Forward 44(45.7) | NFE Backward 123(123.0)\n",
      "Iter 0424 | Time 4.3984(6.1268) | Loss 62.811584(65.122365) | NFE Forward 44(45.6) | NFE Backward 123(123.0)\n",
      "Iter 0425 | Time 4.6198(6.0213) | Loss 62.516327(64.939943) | NFE Forward 50(45.9) | NFE Backward 123(123.0)\n",
      "Iter 0426 | Time 4.5644(5.9194) | Loss 63.048420(64.807536) | NFE Forward 44(45.8) | NFE Backward 123(123.0)\n",
      "Iter 0427 | Time 4.2914(5.8054) | Loss 61.894249(64.603606) | NFE Forward 44(45.7) | NFE Backward 123(123.0)\n",
      "Iter 0428 | Time 4.3195(5.7014) | Loss 62.460228(64.453570) | NFE Forward 44(45.5) | NFE Backward 123(123.0)\n",
      "Iter 0429 | Time 4.1237(5.5909) | Loss 62.243053(64.298833) | NFE Forward 44(45.4) | NFE Backward 123(123.0)\n",
      "Iter 0430 | Time 4.3512(5.5042) | Loss 62.569965(64.177813) | NFE Forward 44(45.3) | NFE Backward 123(123.0)\n",
      "Iter 0431 | Time 4.4678(5.4316) | Loss 62.126873(64.034247) | NFE Forward 50(45.7) | NFE Backward 123(123.0)\n",
      "Iter 0432 | Time 4.9076(5.3949) | Loss 62.160408(63.903078) | NFE Forward 50(46.0) | NFE Backward 123(123.0)\n",
      "Iter 0433 | Time 4.4870(5.3314) | Loss 61.537884(63.737515) | NFE Forward 44(45.8) | NFE Backward 123(123.0)\n",
      "Iter 0434 | Time 4.2381(5.2549) | Loss 61.721809(63.596415) | NFE Forward 44(45.7) | NFE Backward 123(123.0)\n",
      "Iter 0435 | Time 4.2274(5.1829) | Loss 61.455437(63.446547) | NFE Forward 44(45.6) | NFE Backward 123(123.0)\n",
      "Iter 0436 | Time 4.4519(5.1318) | Loss 61.624786(63.319024) | NFE Forward 44(45.5) | NFE Backward 123(123.0)\n",
      "Iter 0437 | Time 4.7284(5.1035) | Loss 60.964256(63.154190) | NFE Forward 44(45.4) | NFE Backward 123(123.0)\n",
      "Iter 0438 | Time 4.3618(5.0516) | Loss 61.105522(63.010783) | NFE Forward 38(44.9) | NFE Backward 123(123.0)\n",
      "Iter 0439 | Time 4.5262(5.0148) | Loss 60.097523(62.806855) | NFE Forward 44(44.8) | NFE Backward 123(123.0)\n",
      "Iter 0440 | Time 4.4833(4.9776) | Loss 61.104717(62.687705) | NFE Forward 44(44.7) | NFE Backward 123(123.0)\n",
      "Iter 0441 | Time 4.7880(4.9643) | Loss 60.911419(62.563365) | NFE Forward 56(45.5) | NFE Backward 123(123.0)\n",
      "Iter 0442 | Time 4.4994(4.9318) | Loss 60.223877(62.399601) | NFE Forward 44(45.4) | NFE Backward 123(123.0)\n",
      "Iter 0443 | Time 4.4711(4.8995) | Loss 60.736755(62.283202) | NFE Forward 44(45.3) | NFE Backward 123(123.0)\n",
      "Iter 0444 | Time 4.4691(4.8694) | Loss 60.016441(62.124529) | NFE Forward 44(45.2) | NFE Backward 123(123.0)\n",
      "Iter 0445 | Time 4.2482(4.8259) | Loss 60.036591(61.978373) | NFE Forward 44(45.1) | NFE Backward 123(123.0)\n",
      "Iter 0446 | Time 4.3796(4.7947) | Loss 59.800514(61.825923) | NFE Forward 50(45.5) | NFE Backward 123(123.0)\n",
      "Iter 0447 | Time 4.4056(4.7675) | Loss 59.894299(61.690709) | NFE Forward 44(45.4) | NFE Backward 123(123.0)\n",
      "Iter 0448 | Time 4.4962(4.7485) | Loss 59.578514(61.542855) | NFE Forward 50(45.7) | NFE Backward 123(123.0)\n",
      "Iter 0449 | Time 4.4444(4.7272) | Loss 59.288330(61.385039) | NFE Forward 50(46.0) | NFE Backward 123(123.0)\n",
      "Iter 0450 | Time 4.3257(4.6991) | Loss 59.311363(61.239881) | NFE Forward 50(46.3) | NFE Backward 123(123.0)\n",
      "Iter 0451 | Time 4.4355(4.6806) | Loss 59.043510(61.086135) | NFE Forward 44(46.1) | NFE Backward 123(123.0)\n",
      "Iter 0452 | Time 4.6376(4.6776) | Loss 59.265339(60.958680) | NFE Forward 50(46.4) | NFE Backward 123(123.0)\n",
      "Iter 0453 | Time 4.4051(4.6585) | Loss 58.710003(60.801272) | NFE Forward 50(46.6) | NFE Backward 123(123.0)\n",
      "Iter 0454 | Time 4.3507(4.6370) | Loss 59.404854(60.703523) | NFE Forward 44(46.5) | NFE Backward 123(123.0)\n",
      "Iter 0455 | Time 4.4870(4.6265) | Loss 58.323608(60.536929) | NFE Forward 56(47.1) | NFE Backward 123(123.0)\n",
      "Iter 0456 | Time 4.3306(4.6058) | Loss 58.953297(60.426075) | NFE Forward 44(46.9) | NFE Backward 123(123.0)\n",
      "Iter 0457 | Time 4.3966(4.5911) | Loss 57.974274(60.254449) | NFE Forward 50(47.1) | NFE Backward 123(123.0)\n",
      "Iter 0458 | Time 4.5312(4.5869) | Loss 58.546459(60.134889) | NFE Forward 44(46.9) | NFE Backward 123(123.0)\n",
      "Iter 0459 | Time 4.3987(4.5738) | Loss 58.487061(60.019541) | NFE Forward 44(46.7) | NFE Backward 123(123.0)\n",
      "Iter 0460 | Time 4.4401(4.5644) | Loss 58.409973(59.906872) | NFE Forward 44(46.5) | NFE Backward 123(123.0)\n",
      "Iter 0461 | Time 4.5362(4.5624) | Loss 57.362183(59.728743) | NFE Forward 38(45.9) | NFE Backward 123(123.0)\n",
      "Iter 0462 | Time 4.2485(4.5405) | Loss 58.283806(59.627598) | NFE Forward 44(45.8) | NFE Backward 123(123.0)\n",
      "Iter 0463 | Time 4.3471(4.5269) | Loss 57.928112(59.508634) | NFE Forward 50(46.1) | NFE Backward 123(123.0)\n",
      "Iter 0464 | Time 4.5244(4.5267) | Loss 58.077965(59.408487) | NFE Forward 50(46.4) | NFE Backward 123(123.0)\n",
      "Iter 0465 | Time 4.5214(4.5264) | Loss 57.783070(59.294708) | NFE Forward 44(46.2) | NFE Backward 123(123.0)\n",
      "Iter 0466 | Time 4.3242(4.5122) | Loss 57.916096(59.198205) | NFE Forward 44(46.0) | NFE Backward 123(123.0)\n",
      "Iter 0467 | Time 4.4323(4.5066) | Loss 56.992603(59.043813) | NFE Forward 50(46.3) | NFE Backward 123(123.0)\n",
      "Iter 0468 | Time 4.4926(4.5056) | Loss 57.178223(58.913221) | NFE Forward 44(46.2) | NFE Backward 123(123.0)\n",
      "Iter 0469 | Time 4.5677(4.5100) | Loss 56.736778(58.760870) | NFE Forward 44(46.0) | NFE Backward 123(123.0)\n",
      "Iter 0470 | Time 4.3529(4.4990) | Loss 56.995049(58.637263) | NFE Forward 44(45.9) | NFE Backward 123(123.0)\n",
      "Iter 0471 | Time 4.2863(4.4841) | Loss 56.769073(58.506490) | NFE Forward 38(45.3) | NFE Backward 123(123.0)\n",
      "Iter 0472 | Time 4.6109(4.4930) | Loss 57.469048(58.433869) | NFE Forward 50(45.6) | NFE Backward 123(123.0)\n",
      "Iter 0473 | Time 4.3033(4.4797) | Loss 57.496357(58.368243) | NFE Forward 50(45.9) | NFE Backward 123(123.0)\n",
      "Iter 0474 | Time 5.6730(4.5632) | Loss 56.888042(58.264629) | NFE Forward 44(45.8) | NFE Backward 123(123.0)\n",
      "Iter 0475 | Time 5.0181(4.5951) | Loss 56.048664(58.109511) | NFE Forward 44(45.7) | NFE Backward 123(123.0)\n",
      "Iter 0476 | Time 4.8525(4.6131) | Loss 56.379021(57.988377) | NFE Forward 38(45.1) | NFE Backward 123(123.0)\n",
      "Iter 0477 | Time 5.7062(4.6896) | Loss 55.924194(57.843884) | NFE Forward 44(45.1) | NFE Backward 129(123.4)\n",
      "Iter 0478 | Time 4.2709(4.6603) | Loss 56.683533(57.762660) | NFE Forward 44(45.0) | NFE Backward 123(123.4)\n",
      "Iter 0479 | Time 4.3139(4.6360) | Loss 55.969841(57.637162) | NFE Forward 38(44.5) | NFE Backward 123(123.4)\n",
      "Iter 0480 | Time 4.4751(4.6248) | Loss 55.956654(57.519527) | NFE Forward 44(44.5) | NFE Backward 123(123.3)\n",
      "Iter 0481 | Time 4.2142(4.5960) | Loss 56.444481(57.444273) | NFE Forward 44(44.4) | NFE Backward 129(123.7)\n",
      "Iter 0482 | Time 4.7689(4.6081) | Loss 55.804466(57.329487) | NFE Forward 50(44.8) | NFE Backward 123(123.7)\n",
      "Iter 0483 | Time 4.5765(4.6059) | Loss 55.723003(57.217033) | NFE Forward 50(45.2) | NFE Backward 123(123.6)\n",
      "Iter 0484 | Time 4.5461(4.6017) | Loss 55.407421(57.090360) | NFE Forward 50(45.5) | NFE Backward 123(123.6)\n",
      "Iter 0485 | Time 4.3484(4.5840) | Loss 55.257637(56.962070) | NFE Forward 44(45.4) | NFE Backward 123(123.5)\n",
      "Iter 0486 | Time 4.2821(4.5629) | Loss 55.610046(56.867428) | NFE Forward 44(45.3) | NFE Backward 123(123.5)\n",
      "Iter 0487 | Time 4.3584(4.5486) | Loss 55.128735(56.745719) | NFE Forward 38(44.8) | NFE Backward 123(123.5)\n",
      "Iter 0488 | Time 4.2534(4.5279) | Loss 55.171764(56.635543) | NFE Forward 44(44.7) | NFE Backward 123(123.4)\n",
      "Iter 0489 | Time 4.5736(4.5311) | Loss 54.810467(56.507787) | NFE Forward 44(44.7) | NFE Backward 123(123.4)\n",
      "Iter 0490 | Time 4.5885(4.5351) | Loss 54.633350(56.376577) | NFE Forward 44(44.6) | NFE Backward 123(123.4)\n",
      "Iter 0491 | Time 4.7399(4.5494) | Loss 54.766315(56.263858) | NFE Forward 50(45.0) | NFE Backward 123(123.4)\n",
      "Iter 0492 | Time 4.4267(4.5408) | Loss 54.918781(56.169703) | NFE Forward 44(44.9) | NFE Backward 123(123.3)\n",
      "Iter 0493 | Time 5.0323(4.5752) | Loss 54.715340(56.067898) | NFE Forward 44(44.9) | NFE Backward 141(124.6)\n",
      "Iter 0494 | Time 4.5738(4.5751) | Loss 54.481640(55.956860) | NFE Forward 44(44.8) | NFE Backward 123(124.5)\n",
      "Iter 0495 | Time 4.8745(4.5961) | Loss 53.918560(55.814179) | NFE Forward 44(44.8) | NFE Backward 135(125.2)\n",
      "Iter 0496 | Time 4.7070(4.6039) | Loss 54.304649(55.708512) | NFE Forward 50(45.1) | NFE Backward 123(125.0)\n",
      "Iter 0497 | Time 4.5205(4.5980) | Loss 54.141541(55.598824) | NFE Forward 44(45.1) | NFE Backward 123(124.9)\n",
      "Iter 0498 | Time 4.3579(4.5812) | Loss 53.848030(55.476268) | NFE Forward 44(45.0) | NFE Backward 123(124.8)\n",
      "Iter 0499 | Time 4.4439(4.5716) | Loss 54.006481(55.373383) | NFE Forward 50(45.3) | NFE Backward 123(124.6)\n",
      "Iter 0500 | Time 4.5593(4.5707) | Loss 53.804756(55.263579) | NFE Forward 38(44.8) | NFE Backward 129(124.9)\n",
      "[TEST] Iter 0500 | Test Loss 53.549744 | NFE 44\n",
      "Skipping vis as data dimension is >2\n",
      "Iter 0501 | Time 4.9150(4.5948) | Loss 53.357136(55.130128) | NFE Forward 44(44.8) | NFE Backward 123(124.8)\n",
      "Iter 0502 | Time 6.2499(4.7107) | Loss 53.268517(54.999815) | NFE Forward 50(45.1) | NFE Backward 123(124.7)\n",
      "Iter 0503 | Time 4.6465(4.7062) | Loss 53.368488(54.885622) | NFE Forward 50(45.5) | NFE Backward 123(124.6)\n",
      "Iter 0504 | Time 7.2843(4.8867) | Loss 53.032692(54.755917) | NFE Forward 44(45.4) | NFE Backward 129(124.9)\n",
      "Iter 0505 | Time 5.9607(4.9619) | Loss 52.870705(54.623952) | NFE Forward 44(45.3) | NFE Backward 129(125.2)\n",
      "Iter 0506 | Time 5.3033(4.9857) | Loss 52.862507(54.500651) | NFE Forward 44(45.2) | NFE Backward 123(125.0)\n",
      "Iter 0507 | Time 5.6409(5.0316) | Loss 53.214954(54.410652) | NFE Forward 44(45.1) | NFE Backward 123(124.9)\n",
      "Iter 0508 | Time 5.2412(5.0463) | Loss 52.725422(54.292686) | NFE Forward 44(45.0) | NFE Backward 123(124.7)\n",
      "Iter 0509 | Time 4.3728(4.9991) | Loss 52.706776(54.181673) | NFE Forward 44(44.9) | NFE Backward 123(124.6)\n",
      "Iter 0510 | Time 4.3650(4.9547) | Loss 52.619453(54.072317) | NFE Forward 44(44.9) | NFE Backward 123(124.5)\n",
      "Iter 0511 | Time 4.2810(4.9076) | Loss 52.225502(53.943040) | NFE Forward 44(44.8) | NFE Backward 123(124.4)\n",
      "Iter 0512 | Time 4.6992(4.8930) | Loss 52.571095(53.847004) | NFE Forward 44(44.8) | NFE Backward 135(125.1)\n",
      "Iter 0513 | Time 4.4617(4.8628) | Loss 52.121132(53.726193) | NFE Forward 44(44.7) | NFE Backward 123(125.0)\n",
      "Iter 0514 | Time 5.7069(4.9219) | Loss 51.954670(53.602186) | NFE Forward 44(44.7) | NFE Backward 123(124.9)\n",
      "Iter 0515 | Time 7.4692(5.1002) | Loss 51.782410(53.474802) | NFE Forward 44(44.6) | NFE Backward 123(124.7)\n",
      "Iter 0516 | Time 6.4706(5.1961) | Loss 51.705322(53.350938) | NFE Forward 44(44.6) | NFE Backward 123(124.6)\n",
      "Iter 0517 | Time 5.1180(5.1907) | Loss 51.205982(53.200791) | NFE Forward 44(44.5) | NFE Backward 123(124.5)\n",
      "Iter 0518 | Time 4.1264(5.1162) | Loss 51.655712(53.092636) | NFE Forward 44(44.5) | NFE Backward 129(124.8)\n",
      "Iter 0519 | Time 4.7118(5.0879) | Loss 51.006481(52.946605) | NFE Forward 44(44.5) | NFE Backward 123(124.7)\n",
      "Iter 0520 | Time 5.2308(5.0979) | Loss 50.637070(52.784938) | NFE Forward 44(44.4) | NFE Backward 129(125.0)\n",
      "Iter 0521 | Time 8.3455(5.3252) | Loss 50.680622(52.637635) | NFE Forward 44(44.4) | NFE Backward 123(124.8)\n",
      "Iter 0522 | Time 5.3500(5.3269) | Loss 50.474777(52.486235) | NFE Forward 44(44.4) | NFE Backward 129(125.1)\n",
      "Iter 0523 | Time 5.5395(5.3418) | Loss 50.226467(52.328052) | NFE Forward 44(44.3) | NFE Backward 129(125.4)\n",
      "Iter 0524 | Time 4.8720(5.3089) | Loss 50.459705(52.197267) | NFE Forward 44(44.3) | NFE Backward 123(125.2)\n",
      "Iter 0525 | Time 4.2831(5.2371) | Loss 50.757843(52.096508) | NFE Forward 44(44.3) | NFE Backward 123(125.1)\n",
      "Iter 0526 | Time 4.3632(5.1759) | Loss 49.880795(51.941408) | NFE Forward 44(44.3) | NFE Backward 129(125.4)\n",
      "Iter 0527 | Time 4.6220(5.1372) | Loss 50.454811(51.837346) | NFE Forward 44(44.3) | NFE Backward 129(125.6)\n",
      "Iter 0528 | Time 4.3485(5.0820) | Loss 49.727806(51.689678) | NFE Forward 44(44.2) | NFE Backward 129(125.8)\n",
      "Iter 0529 | Time 4.3720(5.0323) | Loss 50.218620(51.586704) | NFE Forward 44(44.2) | NFE Backward 123(125.6)\n",
      "Iter 0530 | Time 4.2561(4.9779) | Loss 49.928097(51.470602) | NFE Forward 44(44.2) | NFE Backward 123(125.5)\n",
      "Iter 0531 | Time 4.2376(4.9261) | Loss 49.661110(51.343937) | NFE Forward 44(44.2) | NFE Backward 129(125.7)\n",
      "Iter 0532 | Time 4.4946(4.8959) | Loss 49.561722(51.219182) | NFE Forward 44(44.2) | NFE Backward 123(125.5)\n",
      "Iter 0533 | Time 4.3458(4.8574) | Loss 49.977451(51.132261) | NFE Forward 44(44.2) | NFE Backward 123(125.3)\n",
      "Iter 0534 | Time 4.3300(4.8205) | Loss 49.311901(51.004836) | NFE Forward 44(44.2) | NFE Backward 123(125.2)\n",
      "Iter 0535 | Time 4.4711(4.7960) | Loss 49.312279(50.886357) | NFE Forward 44(44.1) | NFE Backward 123(125.0)\n",
      "Iter 0536 | Time 4.5979(4.7822) | Loss 49.244781(50.771447) | NFE Forward 44(44.1) | NFE Backward 123(124.9)\n",
      "Iter 0537 | Time 4.7973(4.7832) | Loss 49.243881(50.664517) | NFE Forward 44(44.1) | NFE Backward 129(125.2)\n",
      "Iter 0538 | Time 4.2078(4.7429) | Loss 48.880634(50.539645) | NFE Forward 44(44.1) | NFE Backward 129(125.4)\n",
      "Iter 0539 | Time 4.3513(4.7155) | Loss 49.089821(50.438157) | NFE Forward 44(44.1) | NFE Backward 129(125.7)\n",
      "Iter 0540 | Time 4.5533(4.7042) | Loss 48.703350(50.316721) | NFE Forward 44(44.1) | NFE Backward 129(125.9)\n",
      "Iter 0541 | Time 4.4058(4.6833) | Loss 48.923439(50.219191) | NFE Forward 44(44.1) | NFE Backward 123(125.7)\n",
      "Iter 0542 | Time 4.5399(4.6732) | Loss 48.426121(50.093676) | NFE Forward 44(44.1) | NFE Backward 129(125.9)\n",
      "Iter 0543 | Time 4.3609(4.6514) | Loss 48.539585(49.984890) | NFE Forward 44(44.1) | NFE Backward 123(125.7)\n",
      "Iter 0544 | Time 4.6046(4.6481) | Loss 48.099506(49.852913) | NFE Forward 44(44.1) | NFE Backward 129(126.0)\n",
      "Iter 0545 | Time 4.3199(4.6251) | Loss 48.397175(49.751011) | NFE Forward 44(44.1) | NFE Backward 123(125.8)\n",
      "Iter 0546 | Time 4.3656(4.6070) | Loss 48.468819(49.661258) | NFE Forward 44(44.1) | NFE Backward 129(126.0)\n",
      "Iter 0547 | Time 4.5115(4.6003) | Loss 48.210876(49.559731) | NFE Forward 44(44.1) | NFE Backward 129(126.2)\n",
      "Iter 0548 | Time 4.5188(4.5946) | Loss 48.292572(49.471030) | NFE Forward 44(44.1) | NFE Backward 123(126.0)\n",
      "Iter 0549 | Time 4.2268(4.5688) | Loss 47.784359(49.352963) | NFE Forward 44(44.1) | NFE Backward 123(125.8)\n",
      "Iter 0550 | Time 4.6036(4.5713) | Loss 47.307240(49.209762) | NFE Forward 44(44.0) | NFE Backward 123(125.6)\n",
      "Iter 0551 | Time 4.4918(4.5657) | Loss 47.419071(49.084414) | NFE Forward 44(44.0) | NFE Backward 123(125.4)\n",
      "Iter 0552 | Time 4.5250(4.5629) | Loss 47.655876(48.984416) | NFE Forward 44(44.0) | NFE Backward 123(125.2)\n",
      "Iter 0553 | Time 4.3180(4.5457) | Loss 47.637272(48.890116) | NFE Forward 44(44.0) | NFE Backward 123(125.1)\n",
      "Iter 0554 | Time 4.2816(4.5272) | Loss 47.656216(48.803743) | NFE Forward 44(44.0) | NFE Backward 129(125.3)\n",
      "Iter 0555 | Time 4.3143(4.5123) | Loss 47.809113(48.734119) | NFE Forward 44(44.0) | NFE Backward 123(125.2)\n",
      "Iter 0556 | Time 4.3729(4.5026) | Loss 47.149193(48.623174) | NFE Forward 44(44.0) | NFE Backward 123(125.0)\n",
      "Iter 0557 | Time 4.3069(4.4889) | Loss 47.552845(48.548251) | NFE Forward 44(44.0) | NFE Backward 123(124.9)\n",
      "Iter 0558 | Time 4.4584(4.4867) | Loss 46.776592(48.424235) | NFE Forward 44(44.0) | NFE Backward 129(125.2)\n",
      "Iter 0559 | Time 4.5550(4.4915) | Loss 47.072563(48.329618) | NFE Forward 44(44.0) | NFE Backward 129(125.4)\n",
      "Iter 0560 | Time 4.6584(4.5032) | Loss 46.997318(48.236357) | NFE Forward 44(44.0) | NFE Backward 129(125.7)\n",
      "Iter 0561 | Time 4.3476(4.4923) | Loss 46.503441(48.115053) | NFE Forward 44(44.0) | NFE Backward 123(125.5)\n",
      "Iter 0562 | Time 4.1348(4.4673) | Loss 46.754879(48.019841) | NFE Forward 44(44.0) | NFE Backward 123(125.3)\n",
      "Iter 0563 | Time 4.2854(4.4545) | Loss 46.153088(47.889168) | NFE Forward 44(44.0) | NFE Backward 123(125.2)\n",
      "Iter 0564 | Time 4.5038(4.4580) | Loss 46.406200(47.785360) | NFE Forward 44(44.0) | NFE Backward 123(125.0)\n",
      "Iter 0565 | Time 4.6157(4.4690) | Loss 46.668308(47.707167) | NFE Forward 44(44.0) | NFE Backward 129(125.3)\n",
      "Iter 0566 | Time 4.7716(4.4902) | Loss 46.484753(47.621598) | NFE Forward 44(44.0) | NFE Backward 123(125.1)\n",
      "Iter 0567 | Time 4.2611(4.4742) | Loss 46.292770(47.528580) | NFE Forward 44(44.0) | NFE Backward 123(125.0)\n",
      "Iter 0568 | Time 4.2994(4.4619) | Loss 46.310577(47.443320) | NFE Forward 44(44.0) | NFE Backward 123(124.8)\n",
      "Iter 0569 | Time 4.2604(4.4478) | Loss 46.540962(47.380155) | NFE Forward 44(44.0) | NFE Backward 123(124.7)\n",
      "Iter 0570 | Time 4.1945(4.4301) | Loss 46.135315(47.293016) | NFE Forward 44(44.0) | NFE Backward 123(124.6)\n",
      "Iter 0571 | Time 4.2769(4.4194) | Loss 45.955544(47.199393) | NFE Forward 44(44.0) | NFE Backward 123(124.5)\n",
      "Iter 0572 | Time 4.6775(4.4374) | Loss 45.760876(47.098697) | NFE Forward 44(44.0) | NFE Backward 123(124.4)\n",
      "Iter 0573 | Time 4.5362(4.4444) | Loss 46.092613(47.028271) | NFE Forward 44(44.0) | NFE Backward 123(124.3)\n",
      "Iter 0574 | Time 4.4462(4.4445) | Loss 46.007721(46.956832) | NFE Forward 44(44.0) | NFE Backward 123(124.2)\n",
      "Iter 0575 | Time 4.5210(4.4498) | Loss 45.764149(46.873344) | NFE Forward 44(44.0) | NFE Backward 123(124.1)\n",
      "Iter 0576 | Time 4.4180(4.4476) | Loss 45.686436(46.790261) | NFE Forward 44(44.0) | NFE Backward 123(124.0)\n",
      "Iter 0577 | Time 4.4541(4.4481) | Loss 45.665459(46.711525) | NFE Forward 44(44.0) | NFE Backward 123(124.0)\n",
      "Iter 0578 | Time 4.4574(4.4487) | Loss 45.754620(46.644541) | NFE Forward 44(44.0) | NFE Backward 123(123.9)\n",
      "Iter 0579 | Time 4.5296(4.4544) | Loss 45.549736(46.567905) | NFE Forward 44(44.0) | NFE Backward 123(123.8)\n",
      "Iter 0580 | Time 4.6445(4.4677) | Loss 45.180420(46.470781) | NFE Forward 44(44.0) | NFE Backward 129(124.2)\n",
      "Iter 0581 | Time 4.5738(4.4751) | Loss 45.318356(46.390111) | NFE Forward 44(44.0) | NFE Backward 123(124.1)\n",
      "Iter 0582 | Time 4.5421(4.4798) | Loss 45.294891(46.313446) | NFE Forward 44(44.0) | NFE Backward 123(124.0)\n",
      "Iter 0583 | Time 4.4555(4.4781) | Loss 45.240044(46.238308) | NFE Forward 44(44.0) | NFE Backward 123(124.0)\n",
      "Iter 0584 | Time 4.5463(4.4829) | Loss 45.175827(46.163934) | NFE Forward 44(44.0) | NFE Backward 123(123.9)\n",
      "Iter 0585 | Time 4.6182(4.4924) | Loss 44.959084(46.079594) | NFE Forward 44(44.0) | NFE Backward 123(123.8)\n",
      "Iter 0586 | Time 4.5170(4.4941) | Loss 44.777073(45.988418) | NFE Forward 44(44.0) | NFE Backward 123(123.8)\n",
      "Iter 0587 | Time 4.4521(4.4912) | Loss 44.778553(45.903727) | NFE Forward 44(44.0) | NFE Backward 123(123.7)\n",
      "Iter 0588 | Time 4.4915(4.4912) | Loss 45.022709(45.842056) | NFE Forward 44(44.0) | NFE Backward 123(123.7)\n",
      "Iter 0589 | Time 4.3659(4.4824) | Loss 45.204826(45.797450) | NFE Forward 44(44.0) | NFE Backward 123(123.6)\n",
      "Iter 0590 | Time 4.2611(4.4669) | Loss 44.855927(45.731543) | NFE Forward 44(44.0) | NFE Backward 129(124.0)\n",
      "Iter 0591 | Time 4.3799(4.4608) | Loss 44.763908(45.663809) | NFE Forward 44(44.0) | NFE Backward 129(124.3)\n",
      "Iter 0592 | Time 4.3682(4.4543) | Loss 44.921112(45.611820) | NFE Forward 44(44.0) | NFE Backward 123(124.3)\n",
      "Iter 0593 | Time 4.7372(4.4741) | Loss 44.952667(45.565679) | NFE Forward 44(44.0) | NFE Backward 123(124.2)\n",
      "Iter 0594 | Time 4.9957(4.5107) | Loss 44.893883(45.518654) | NFE Forward 44(44.0) | NFE Backward 129(124.5)\n",
      "Iter 0595 | Time 5.3095(4.5666) | Loss 44.510208(45.448062) | NFE Forward 44(44.0) | NFE Backward 129(124.8)\n",
      "Iter 0596 | Time 5.1785(4.6094) | Loss 44.673603(45.393850) | NFE Forward 44(44.0) | NFE Backward 123(124.7)\n",
      "Iter 0597 | Time 5.0137(4.6377) | Loss 44.779045(45.350814) | NFE Forward 44(44.0) | NFE Backward 129(125.0)\n",
      "Iter 0598 | Time 5.1479(4.6734) | Loss 44.563488(45.295701) | NFE Forward 44(44.0) | NFE Backward 123(124.9)\n",
      "Iter 0599 | Time 4.7948(4.6819) | Loss 44.288513(45.225198) | NFE Forward 44(44.0) | NFE Backward 123(124.7)\n",
      "Iter 0600 | Time 4.7398(4.6860) | Loss 44.398106(45.167302) | NFE Forward 44(44.0) | NFE Backward 129(125.0)\n",
      "[TEST] Iter 0600 | Test Loss 44.080002 | NFE 44\n",
      "Skipping vis as data dimension is >2\n",
      "Iter 0601 | Time 5.9434(4.7740) | Loss 44.233585(45.101941) | NFE Forward 44(44.0) | NFE Backward 129(125.3)\n",
      "Iter 0602 | Time 5.6128(4.8327) | Loss 44.042072(45.027751) | NFE Forward 44(44.0) | NFE Backward 123(125.1)\n",
      "Iter 0603 | Time 4.8693(4.8353) | Loss 44.151726(44.966429) | NFE Forward 44(44.0) | NFE Backward 123(125.0)\n",
      "Iter 0604 | Time 5.5365(4.8844) | Loss 44.027489(44.900703) | NFE Forward 44(44.0) | NFE Backward 123(124.9)\n",
      "Iter 0605 | Time 4.7225(4.8730) | Loss 44.068371(44.842440) | NFE Forward 44(44.0) | NFE Backward 129(125.1)\n",
      "Iter 0606 | Time 4.9118(4.8757) | Loss 43.998955(44.783396) | NFE Forward 44(44.0) | NFE Backward 129(125.4)\n",
      "Iter 0607 | Time 4.6539(4.8602) | Loss 43.925568(44.723348) | NFE Forward 44(44.0) | NFE Backward 129(125.7)\n",
      "Iter 0608 | Time 4.6469(4.8453) | Loss 43.783119(44.657532) | NFE Forward 44(44.0) | NFE Backward 123(125.5)\n",
      "Iter 0609 | Time 4.6051(4.8285) | Loss 43.937885(44.607157) | NFE Forward 44(44.0) | NFE Backward 129(125.7)\n",
      "Iter 0610 | Time 4.7289(4.8215) | Loss 43.759155(44.547796) | NFE Forward 44(44.0) | NFE Backward 129(126.0)\n",
      "Iter 0611 | Time 4.8859(4.8260) | Loss 43.494804(44.474087) | NFE Forward 44(44.0) | NFE Backward 129(126.2)\n",
      "Iter 0612 | Time 4.6089(4.8108) | Loss 43.875652(44.432197) | NFE Forward 44(44.0) | NFE Backward 129(126.4)\n",
      "Iter 0613 | Time 5.0076(4.8246) | Loss 43.811462(44.388745) | NFE Forward 44(44.0) | NFE Backward 129(126.5)\n",
      "Iter 0614 | Time 4.6007(4.8089) | Loss 43.730232(44.342649) | NFE Forward 44(44.0) | NFE Backward 129(126.7)\n",
      "Iter 0615 | Time 4.3915(4.7797) | Loss 43.247570(44.265994) | NFE Forward 44(44.0) | NFE Backward 123(126.5)\n",
      "Iter 0616 | Time 4.6260(4.7689) | Loss 43.357159(44.202375) | NFE Forward 44(44.0) | NFE Backward 129(126.6)\n",
      "Iter 0617 | Time 5.0423(4.7881) | Loss 43.431942(44.148445) | NFE Forward 44(44.0) | NFE Backward 123(126.4)\n",
      "Iter 0618 | Time 4.7615(4.7862) | Loss 43.410374(44.096780) | NFE Forward 44(44.0) | NFE Backward 129(126.6)\n",
      "Iter 0619 | Time 4.2164(4.7463) | Loss 43.439037(44.050738) | NFE Forward 44(44.0) | NFE Backward 129(126.7)\n",
      "Iter 0620 | Time 4.3501(4.7186) | Loss 43.461159(44.009467) | NFE Forward 44(44.0) | NFE Backward 123(126.5)\n",
      "Iter 0621 | Time 4.6944(4.7169) | Loss 43.419586(43.968176) | NFE Forward 44(44.0) | NFE Backward 129(126.7)\n",
      "Iter 0622 | Time 4.4119(4.6955) | Loss 43.628361(43.944389) | NFE Forward 44(44.0) | NFE Backward 129(126.8)\n",
      "Iter 0623 | Time 4.4433(4.6779) | Loss 43.103630(43.885536) | NFE Forward 44(44.0) | NFE Backward 123(126.5)\n",
      "Iter 0624 | Time 4.7066(4.6799) | Loss 43.018333(43.824831) | NFE Forward 44(44.0) | NFE Backward 129(126.7)\n",
      "Iter 0625 | Time 4.7653(4.6859) | Loss 42.898602(43.759995) | NFE Forward 44(44.0) | NFE Backward 129(126.9)\n",
      "Iter 0626 | Time 4.7215(4.6884) | Loss 42.957134(43.703795) | NFE Forward 44(44.0) | NFE Backward 123(126.6)\n",
      "Iter 0627 | Time 4.7012(4.6893) | Loss 42.903778(43.647794) | NFE Forward 44(44.0) | NFE Backward 123(126.4)\n",
      "Iter 0628 | Time 4.1869(4.6541) | Loss 43.061310(43.606740) | NFE Forward 44(44.0) | NFE Backward 129(126.5)\n",
      "Iter 0629 | Time 4.5411(4.6462) | Loss 43.018600(43.565570) | NFE Forward 44(44.0) | NFE Backward 123(126.3)\n",
      "Iter 0630 | Time 4.8200(4.6584) | Loss 43.242317(43.542943) | NFE Forward 44(44.0) | NFE Backward 129(126.5)\n",
      "Iter 0631 | Time 4.5627(4.6517) | Loss 42.796547(43.490695) | NFE Forward 44(44.0) | NFE Backward 123(126.2)\n",
      "Iter 0632 | Time 4.4557(4.6379) | Loss 42.901962(43.449484) | NFE Forward 44(44.0) | NFE Backward 123(126.0)\n",
      "Iter 0633 | Time 4.6296(4.6374) | Loss 42.892204(43.410474) | NFE Forward 44(44.0) | NFE Backward 123(125.8)\n",
      "Iter 0634 | Time 4.4490(4.6242) | Loss 43.045715(43.384941) | NFE Forward 44(44.0) | NFE Backward 123(125.6)\n",
      "Iter 0635 | Time 4.4426(4.6115) | Loss 42.698429(43.336885) | NFE Forward 44(44.0) | NFE Backward 123(125.4)\n",
      "Iter 0636 | Time 4.6504(4.6142) | Loss 42.446667(43.274570) | NFE Forward 44(44.0) | NFE Backward 123(125.3)\n",
      "Iter 0637 | Time 4.4266(4.6011) | Loss 42.519817(43.221737) | NFE Forward 44(44.0) | NFE Backward 123(125.1)\n",
      "Iter 0638 | Time 4.5064(4.5944) | Loss 42.490643(43.170560) | NFE Forward 44(44.0) | NFE Backward 123(124.9)\n",
      "Iter 0639 | Time 4.6010(4.5949) | Loss 42.649315(43.134073) | NFE Forward 44(44.0) | NFE Backward 123(124.8)\n",
      "Iter 0640 | Time 4.4395(4.5840) | Loss 42.312817(43.076585) | NFE Forward 44(44.0) | NFE Backward 123(124.7)\n",
      "Iter 0641 | Time 4.4833(4.5770) | Loss 42.550266(43.039743) | NFE Forward 44(44.0) | NFE Backward 123(124.6)\n",
      "Iter 0642 | Time 4.6160(4.5797) | Loss 42.287453(42.987083) | NFE Forward 44(44.0) | NFE Backward 123(124.5)\n",
      "Iter 0643 | Time 4.8361(4.5976) | Loss 42.273113(42.937105) | NFE Forward 44(44.0) | NFE Backward 123(124.4)\n",
      "Iter 0644 | Time 4.8485(4.6152) | Loss 42.609314(42.914159) | NFE Forward 44(44.0) | NFE Backward 123(124.3)\n",
      "Iter 0645 | Time 4.7456(4.6243) | Loss 42.006878(42.850650) | NFE Forward 44(44.0) | NFE Backward 123(124.2)\n",
      "Iter 0646 | Time 4.1984(4.5945) | Loss 42.421597(42.820616) | NFE Forward 44(44.0) | NFE Backward 123(124.1)\n",
      "Iter 0647 | Time 4.4243(4.5826) | Loss 42.061680(42.767490) | NFE Forward 44(44.0) | NFE Backward 123(124.0)\n",
      "Iter 0648 | Time 4.4448(4.5730) | Loss 41.991817(42.713193) | NFE Forward 44(44.0) | NFE Backward 123(123.9)\n",
      "Iter 0649 | Time 4.5793(4.5734) | Loss 42.020428(42.664700) | NFE Forward 44(44.0) | NFE Backward 123(123.9)\n",
      "Iter 0650 | Time 4.6468(4.5785) | Loss 42.041409(42.621069) | NFE Forward 44(44.0) | NFE Backward 123(123.8)\n",
      "Iter 0651 | Time 4.6563(4.5840) | Loss 42.167877(42.589346) | NFE Forward 44(44.0) | NFE Backward 123(123.8)\n",
      "Iter 0652 | Time 4.6308(4.5873) | Loss 42.414524(42.577108) | NFE Forward 44(44.0) | NFE Backward 123(123.7)\n",
      "Iter 0653 | Time 4.7117(4.5960) | Loss 41.813919(42.523685) | NFE Forward 44(44.0) | NFE Backward 123(123.7)\n",
      "Iter 0654 | Time 4.6811(4.6019) | Loss 41.843529(42.476074) | NFE Forward 44(44.0) | NFE Backward 123(123.6)\n",
      "Iter 0655 | Time 4.4967(4.5946) | Loss 42.418289(42.472029) | NFE Forward 44(44.0) | NFE Backward 123(123.6)\n",
      "Iter 0656 | Time 4.4851(4.5869) | Loss 41.527508(42.405913) | NFE Forward 44(44.0) | NFE Backward 123(123.5)\n",
      "Iter 0657 | Time 4.4030(4.5740) | Loss 41.952301(42.374160) | NFE Forward 44(44.0) | NFE Backward 123(123.5)\n",
      "Iter 0658 | Time 4.6455(4.5790) | Loss 41.545696(42.316167) | NFE Forward 44(44.0) | NFE Backward 123(123.5)\n",
      "Iter 0659 | Time 4.7411(4.5904) | Loss 41.802551(42.280214) | NFE Forward 44(44.0) | NFE Backward 123(123.4)\n",
      "Iter 0660 | Time 4.9247(4.6138) | Loss 41.399063(42.218534) | NFE Forward 44(44.0) | NFE Backward 123(123.4)\n",
      "Iter 0661 | Time 4.9179(4.6351) | Loss 41.577137(42.173636) | NFE Forward 44(44.0) | NFE Backward 123(123.4)\n",
      "Iter 0662 | Time 4.9762(4.6589) | Loss 41.770611(42.145424) | NFE Forward 44(44.0) | NFE Backward 123(123.3)\n",
      "Iter 0663 | Time 4.7238(4.6635) | Loss 41.356232(42.090181) | NFE Forward 44(44.0) | NFE Backward 123(123.3)\n",
      "Iter 0664 | Time 4.4909(4.6514) | Loss 41.546501(42.052123) | NFE Forward 44(44.0) | NFE Backward 123(123.3)\n",
      "Iter 0665 | Time 4.8224(4.6634) | Loss 41.401154(42.006555) | NFE Forward 44(44.0) | NFE Backward 123(123.3)\n",
      "Iter 0666 | Time 4.4814(4.6506) | Loss 41.612434(41.978967) | NFE Forward 44(44.0) | NFE Backward 123(123.3)\n",
      "Iter 0667 | Time 4.4117(4.6339) | Loss 41.182503(41.923214) | NFE Forward 44(44.0) | NFE Backward 123(123.2)\n",
      "Iter 0668 | Time 5.8102(4.7162) | Loss 41.322449(41.881161) | NFE Forward 44(44.0) | NFE Backward 123(123.2)\n",
      "Iter 0669 | Time 5.4791(4.7696) | Loss 41.279949(41.839076) | NFE Forward 44(44.0) | NFE Backward 123(123.2)\n",
      "Iter 0670 | Time 6.9606(4.9230) | Loss 41.379662(41.806917) | NFE Forward 44(44.0) | NFE Backward 123(123.2)\n",
      "Iter 0671 | Time 8.0331(5.1407) | Loss 41.253139(41.768153) | NFE Forward 44(44.0) | NFE Backward 123(123.2)\n",
      "Iter 0672 | Time 25.9421(6.5968) | Loss 41.533546(41.751730) | NFE Forward 44(44.0) | NFE Backward 123(123.2)\n",
      "Iter 0673 | Time 19.2462(7.4823) | Loss 40.896645(41.691874) | NFE Forward 44(44.0) | NFE Backward 123(123.2)\n",
      "Iter 0674 | Time 17.1751(8.1608) | Loss 41.170986(41.655412) | NFE Forward 44(44.0) | NFE Backward 123(123.1)\n",
      "Iter 0675 | Time 17.4752(8.8128) | Loss 41.239754(41.626316) | NFE Forward 44(44.0) | NFE Backward 123(123.1)\n",
      "Iter 0676 | Time 27.2501(10.1034) | Loss 41.006741(41.582946) | NFE Forward 44(44.0) | NFE Backward 123(123.1)\n",
      "Iter 0677 | Time 23.5073(11.0417) | Loss 41.082474(41.547913) | NFE Forward 44(44.0) | NFE Backward 129(123.5)\n",
      "Iter 0678 | Time 23.5167(11.9149) | Loss 41.109383(41.517215) | NFE Forward 44(44.0) | NFE Backward 129(123.9)\n",
      "Iter 0679 | Time 25.5971(12.8727) | Loss 40.946007(41.477231) | NFE Forward 44(44.0) | NFE Backward 129(124.3)\n",
      "Iter 0680 | Time 26.0680(13.7963) | Loss 40.639023(41.418556) | NFE Forward 44(44.0) | NFE Backward 129(124.6)\n",
      "Iter 0681 | Time 25.6297(14.6247) | Loss 41.023140(41.390877) | NFE Forward 44(44.0) | NFE Backward 123(124.5)\n",
      "Iter 0682 | Time 19.5861(14.9720) | Loss 40.586166(41.334547) | NFE Forward 44(44.0) | NFE Backward 123(124.4)\n",
      "Iter 0683 | Time 18.0015(15.1840) | Loss 40.900738(41.304181) | NFE Forward 44(44.0) | NFE Backward 123(124.3)\n",
      "Iter 0684 | Time 18.1215(15.3897) | Loss 41.076290(41.288228) | NFE Forward 44(44.0) | NFE Backward 129(124.6)\n",
      "Iter 0685 | Time 24.9979(16.0622) | Loss 40.973068(41.266167) | NFE Forward 44(44.0) | NFE Backward 123(124.5)\n",
      "Iter 0686 | Time 34.1125(17.3258) | Loss 40.249748(41.195018) | NFE Forward 44(44.0) | NFE Backward 123(124.4)\n",
      "Iter 0687 | Time 26.2152(17.9480) | Loss 40.441048(41.142240) | NFE Forward 44(44.0) | NFE Backward 129(124.7)\n",
      "Iter 0688 | Time 21.1153(18.1697) | Loss 40.715225(41.112349) | NFE Forward 44(44.0) | NFE Backward 123(124.6)\n",
      "Iter 0689 | Time 27.4699(18.8207) | Loss 40.440033(41.065287) | NFE Forward 44(44.0) | NFE Backward 123(124.5)\n",
      "Iter 0690 | Time 23.6757(19.1606) | Loss 40.434776(41.021151) | NFE Forward 44(44.0) | NFE Backward 123(124.4)\n",
      "Iter 0691 | Time 19.0689(19.1542) | Loss 40.573441(40.989811) | NFE Forward 44(44.0) | NFE Backward 123(124.3)\n",
      "Iter 0692 | Time 22.8860(19.4154) | Loss 40.323772(40.943189) | NFE Forward 44(44.0) | NFE Backward 123(124.2)\n",
      "Iter 0693 | Time 22.6952(19.6450) | Loss 40.435989(40.907685) | NFE Forward 44(44.0) | NFE Backward 123(124.1)\n",
      "Iter 0694 | Time 20.4149(19.6989) | Loss 40.710770(40.893901) | NFE Forward 44(44.0) | NFE Backward 123(124.0)\n",
      "Iter 0695 | Time 19.8245(19.7077) | Loss 40.329716(40.854408) | NFE Forward 44(44.0) | NFE Backward 123(124.0)\n",
      "Iter 0696 | Time 20.0924(19.7346) | Loss 40.428524(40.824596) | NFE Forward 44(44.0) | NFE Backward 123(123.9)\n",
      "Iter 0697 | Time 18.3124(19.6350) | Loss 40.044575(40.769994) | NFE Forward 44(44.0) | NFE Backward 123(123.8)\n",
      "Iter 0698 | Time 18.9986(19.5905) | Loss 40.223766(40.731758) | NFE Forward 44(44.0) | NFE Backward 123(123.8)\n",
      "Iter 0699 | Time 22.2563(19.7771) | Loss 40.186443(40.693586) | NFE Forward 44(44.0) | NFE Backward 129(124.1)\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# start_time = time.time()\n",
    "# !python -m TrajectoryNet.main \\\n",
    "#     --dataset ../trajectorynet/output/pgclc_150dim.npz \\\n",
    "#     --embedding_name \"original_embedding_150d\" \\\n",
    "#     --save results/pgclc\n",
    "# end_time = time.time()\n",
    "# trajectorynet_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAosAAAHrCAYAAACn9tfQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABwXUlEQVR4nO3deVxN6eMH8M9tjyhaiGwlKVo1ZQtZxr5l38m+hTImYxlLpiG7MLJvQ4Mww1i+1tGgkJKlqGxZUiiize3+/ujV+blTJ0W5V33er1cv7lmfc89zz/3cc57nHIlMJpOBiIiIiCgfKoouABEREREpL4ZFIiIiIhLFsEhEREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEREREJIphkYiIiIhEMSwSEeWDzyugksK6Rd8aNUUXgIhyREZGYseOHbhy5QpevXoFIyMjNGnSBGPGjEGNGjUUXTylEB8fj40bNyI4OBgvXryArq4uGjZsiMGDB6N58+bCdGvWrIG/v3+By6pevTrOnDmTZ3hmZiaWLl2Khg0bolu3bgAAb29vhIaG5jv9t8rb2xsHDx4UHW9gYIB///1Xbtjz58+xa9cunDt3Dk+ePAEA1K5dGx07dsSQIUOgra2dZznXrl3Dtm3bEBYWhjdv3gj1esSIETAzMxOmGzJkCEJDQwssc8+ePfHrr78WZTOVzr59+xAbGwtvb29FF4Wo0CR83B+R4u3evRu//PILnJ2d0bNnTxgZGeHhw4fYvHkzkpOTsX37dtSvX1/RxVSoS5cuYeLEiahatSqGDBkCMzMzvHr1CkeOHMH//vc/DBs2DD/99BOAnFDz/PlzYd59+/Zh//79CAwMFIZpaGjAysoqz3ri4+PRpk0b+Pr6ws3NDQDw6NEjpKam5jv9t8rb2xvBwcGioVpdXR0NGjQQXoeEhMDDwwO6uroYOHAgLCwskJ2djZCQEOzcuRNmZmbYvXs3NDU1hXkCAgKwfPlyNG/eHD179oShoSEePnyIPXv2ICYmBr6+vujcuTMAICYmBqmpqcK88+fPBwD8/PPPwrDKlSujZs2axfo+fG2tW7eGk5PTNx96qYyREZFCXb16VWZpaSnz8fHJM+7ly5cyFxcXWc+ePRVQMuXx/PlzmaOjo2zkyJGy9PT0POO3bt0qq1evnuyPP/7Id/7Vq1fL6tWrV6h1PX78WFavXj3ZgQMHvqjMyu7HH3+Uubq6Fmraly9fypo0aSLr27ev7N27d3nGh4eHyywtLWUbNmwQhp05c0ZWr1492Zo1a/JMn5mZKZs8ebKsYcOGsrt37+a7zsGDB8sGDx5cyK35dri6usp+/PFHRReDqEjYZpFIwTZv3owKFSrA09Mzz7jKlSvD29sbbdq0wfv37wEAUqkUu3fvRteuXWFjY4NWrVph6dKlyMjIEObz9vbGyJEjERgYiLZt28LGxgb9+/fH/fv3cfbsWXTt2hW2trbo06cP7ty5IzffkCFDsH//fri6usLe3h7Dhg1DVFSUXLmuXLmCkSNH4rvvvkPDhg3RunVrrFmzBtnZ2QByzs5ZWFhg69at6NChA2xtbXHgwAEAwN27dzF27Fg4ODjAwcEBEydOxOPHjwt8j7Zt24b379/Dx8dH7sxVruHDh8POzg7r16//ovZguWcVAWDmzJlo3bq18L7k/h/IOTvk7+8vnA22t7eHl5cX3r17h4CAALRo0QKNGjXC5MmT8fr1a7l17Nu3D507d0bDhg3RqlUrrFmzBlKpVBgfEhICCwsLBAUFiZYzOzsbK1asQOvWrYX3f9myZcjKyhKmSU1NxcKFC+Hi4gI7Ozv06tUL586d+6z35ffff8fLly/h4+ODcuXK5Rlva2uLYcOGyY3z9/eHqakpJk6cmGd6dXV1LFiwAKqqqti4ceNnlSlXWFgYLCwscPbsWbnhd+7cgYWFBf73v/8BAI4cOYJu3brBxsYGjRs3xvTp05GQkJDvMqOiouTmBYCrV6/CwsICK1euFIa9fv0alpaWOHLkCADgxYsXmDlzJlq2bAkbGxv07t0bp0+fFqZv3bo1njx5goMHD8LCwgLx8fFftO1EXwvbLBIpkEwmQ3BwMFq3bp1vey8A6NSpk9zruXPn4vDhwxg9ejQcHR1x+/ZtrF27Fnfu3MGmTZsgkUgAANevX8eLFy/g7e2NjIwMzJs3D2PGjIFEIoGHhwe0tbXx888/Y/r06Th69Kiw/Dt37iAuLg6enp7Q1dXF6tWrMXjwYPz9998wMjJCVFQUhg8fjg4dOmDFihWQyWT466+/hHCQe1kRyGk7OGvWLOjo6MDW1hb3799H//79YWpqisWLF+PDhw9Yv349BgwYgMOHD0NfXz/f9yA4OBiWlpaoWrWq6HvZsWNH+Pr64s6dO599udjIyAj+/v6YNGkSxo8fj++//1502i1btqBZs2ZYsWIFbt68iWXLluHWrVswMjLCwoULER8fj0WLFsHAwEC4lLphwwasWLECgwcPxsyZM3Hnzh2sWbMGz549wy+//AIAaNCgAQIDAwu83Lpx40bs2bMHP/74I2rUqIGIiAisWLEC6urq8PDwgFQqhbu7Ox48eAAPDw+Ympri4MGDmDhxIrZv3w5HR0dhWR8+fMh3HaqqqkJdOn36NCwsLGBubi5aph9//FH4/6tXr3Dz5k2MHDlSWMZ/6enpoWnTpnJh6nM4ODigZs2aOHr0KFxdXYXhR44cgZ6eHlq2bIlr165hxowZmDBhAr777js8f/4cfn5+8PLywq5du/Iss379+jA2NsbFixfRrl07ADnNIICc0Jjr33//hYqKClxcXJCUlITevXtDU1MT06ZNQ6VKlRAUFISJEydiyZIl6NatG/z9/TFmzBhYWVlhwoQJMDIy+qJtJ/paGBaJFOj169fIyMiAiYlJoaaPiYnB/v374eXlhTFjxgAAmjVrBiMjI8yYMQP//PMPWrZsCQB49+4dVq5cKXQiCA0Nxd69e7Ft2zY0adIEAPDw4UMsXrwYb968QcWKFQEAb9++xW+//SYEChsbG7Rt2xY7duzA9OnTERUVhaZNm8LPzw8qKipCGc6cOYOQkBC5sNixY0f06tVLeO3l5QVtbW1s27YNOjo6AIAmTZqgbdu22LRpk1zg+Fh8fDxatGhR4HtTq1YtAMCTJ08+OyxqaGjA0tISAFCzZs0Cl6Ojo4MVK1ZATU0NTZs2xcGDB5GQkIB9+/ahQoUKAIALFy4gLCwMQM77um7dOvTr1w+zZ88GADRv3hx6enqYPXs2RowYAXNzc+jo6MDOzq7AcoaGhqJhw4bCe+vk5ARtbW1hvf/88w8iIiKwdu1atG3bFgDQuHFjPH78GJcvXxb27ZMnT+TaJX5sxowZGDlyJICcNpvNmjXLM01+QVNNTU3o/FK9evUCt6NWrVo4ffo0UlJSoKurW+C0BenWrRu2bNmC9PR0aGlpQSaT4e+//0aHDh2goaGBa9euQUtLC2PGjIGGhgaAnLAaGRkJmUyWb6Bt0aIFLl68KLy+dOkSGjRogIiICGRkZEBTUxMXLlyAg4MDdHV14efnh1evXuHEiRPCdrds2RLDhw/HkiVL0KVLF1hZWUFDQwOVK1f+5D4mUiYMi0QKpKqqCgBylyELkttb9ONAlvt65syZCAkJEcKirq6uXG9TAwMDADmXDHPp6ekBgFxYNDExkTvzZGRkBHt7e1y5cgUA0KNHD/To0QMZGRm4f/8+Hj58iDt37kAqlcpdBgUgBK9cly9fhpOTE7S0tISgoaOjA0dHR7kv5v+SyWRQUyv4cJX7Xn7JZeiisLGxkSuTgYEBypUrJwQ2IOf9vXv3LoCcM73p6elo3bq1XMjKvbz977//Fnjm7mPOzs5YtmwZBg4ciNatW6NVq1YYPHiwMP7atWtQV1eXu3SuoqKCvXv3yi3H0NAQ69evz3cdxsbGwv9zmxd87MOHD/kGzejoaGEfqKurF7gdxbXPcs/anT17Fh07dkRYWBiePn2K7t27AwC+++47rFixAl26dEH79u3RsmVLNG/eXPis5KdVq1YIDAzEs2fPoKurixs3bmD58uWYPHkyIiIi8N133yE4OBju7u4Acj6b9vb2eQJyt27dMHPmTMTFxaFu3bpftJ1EisKwSKRAurq6KF++PJ4+fSo6zfv375GVlQVdXV2kpKQAyPmS/5iamhoqVaqEt2/fCsNyz9z9V35tzj5WpUqVPMP09fVx69YtAEB6ejoWLlyIw4cP48OHDzAxMYG9vT3U1NTyfOn/d13Jycn4+++/8ffff+dZR+XKlUXLVL16deFslZjcdo/VqlUrcLrikt/7W9B7m5ycDADCGeH/evHiRaHXPWrUKJQvXx4HDhzA0qVL4efnB3Nzc8yePRuNGzdGcnIy9PT0hDO/YjQ0NGBtbf3J9eX3/qupqWH//v3C6z/++AN//PGHMD2AQu2z8uXLCz9aPletWrVgb2+Po0ePomPHjjh69Chq1qwJBwcHAIC9vT0CAgKwbds2bN26FQEBATAwMMC4ceMwZMiQfJfZpEkTaGpq4uLFizAwMBDCd+3atREaGory5csjKSlJuPSdkpKS7y2ucn+kvXnz5ou2kUiRGBaJFKx58+YICQkRLm391x9//IHFixdj//79wqW6xMREuTMYWVlZeP36NSpVqvTF5flvhwwASEpKEtoTLlq0CCdOnMDKlSvRtGlTISDlXtouSIUKFdC0aVOMGDEiz7iCzhy2bt0aW7ZswZMnT0QvbR4/fhzGxsZKe3ub3DO3S5cuRe3atfOMzw0VhaGiooJBgwZh0KBBePnyJc6fP4/ffvsNkydPxr///osKFSogOTk5zyXW27dvQyaTiV56FtO6dWsEBATg8ePHcoHo46D5cecZfX192NnZ4cSJE5gyZUq+oTU1NRX//vuv3NnPL9GtWzf4+vri7du3OH78OAYMGCA33sXFBS4uLkhLS8Ply5exY8cO+Pj4wNbWFjY2NnmWp62tDScnJ1y6dAmGhoZwcHCAmpoanJ2dERoaClVVVdSqVQumpqYAcn74JSYm5llO7rDi+GwSKQp7QxMpmLu7O5KTk+V6WeZKTEzEli1bULduXTRo0ABOTk4AINchJfe1VCpFo0aNvrg8Dx48QGxsrPA6ISEB169fF8LgtWvX4OzsjLZt2wpB8ebNm3j16lW+lys/5uTkhJiYGFhaWsLa2hrW1tZo2LAhtm3bJtfz9L+GDBkCHR0dzJw5E+np6XnG//777wgNDcXYsWM/eTbtU3IvjRY3W1tbqKurIyEhQdh2a2trqKmpYfny5UXqGdu/f3/4+PgAyAlmbm5uGDRoEN68eYPU1FQ4OjoiKysL//zzjzCPTCbDzJkzsWHDhiKXfdCgQdDT04O3t7fcvRBzSaVSxMXFyQ2bNGkS7t+/j+XLl+c7/c8//4z09HSMGjWqyOXJT6dOnSCTybBq1Sq8fPlSuKE6ACxevBi9evWCTCaDtrY2XF1dhfaxBZ3Vb9WqFUJCQnD16lU4OzsDyGn7GR4ejlOnTsl1qPnuu+9w/fr1PGdT//zzTxgaGgptar+0fhIpAs8sEimYnZ0dpkyZgpUrVyI2NhY9evRApUqVcO/ePWzevBkZGRlCkKxbty569uyJ1atXIy0tDd999x3u3LkDf39/ODs7w8XF5YvLI5PJMG7cOEybNg2qqqrw9/eHrq6ucLnOxsYGx44dw549e2BmZoaoqCisX78eEokEaWlpBS57woQJ6N+/P8aOHYsBAwZAU1MTgYGBOHXqFFavXi06n5GREVatWgUPDw+4ublh6NChMDMzQ0pKCo4dO4ajR49i0KBBec4mfY7cNoeXLl2CmZmZXBvPL1GpUiWMGjUKq1atQmpqKpydnZGQkIBVq1ZBIpEIN11PTU1FTEwMatasKXpp/rvvvsOWLVtgYGAAe3t7JCQkYOvWrXByckLlypXRqlUr2Nvbw9vbG1OnTkWNGjVw+PBhxMbGYuHChcJyMjMzER4eLlpmCwsLaGtro0qVKvD398eUKVPQrVs39OvXDw0aNICKigpu3ryJAwcO4MGDB3IBzcXFBd7e3liyZAnu3LmDXr16wcjICPHx8dizZw/u3LmDRYsWFdvN5nN7Pv/++++wt7cXwhmQE/C2bt0Kb29vdOvWDVlZWdi0aRP09PTQuHFj0WW2bNkSCxcuxIsXLzBr1iwAOT94MjIycPPmTUyfPl2YdsSIEfjzzz8xfPhwTJo0CXp6ejh06BAuX76MX375RQiJFStWxO3btxEaGgobGxtoaWkVy/YTlSSGRSIlMH78eFhZWQlPcklJSYGxsTFatWqFcePGyXU2WLRoEWrVqoUDBw5g48aNMDIywtChQzFhwoRiOWtRrVo1uLu745dffkFaWhqaNm2K9evXC+3KvL29kZWVhZUrVyIzMxMmJiYYP348YmJicObMmQI769SvXx+7d+/GihUrMGPGDMhkMtSrVw9r164V7m8opnHjxjh06JDQ7uzZs2eoWLEirK2tsXHjxmIJykBOW8QRI0YgMDAQ58+fz/PIuy8xdepUGBoa4vfff8emTZugq6uLJk2awNPTUwipt27dwtChQ+WeIPNfU6ZMgYaGBg4cOIC1a9eiQoUKaN26Nby8vABAuH/h0qVLsWrVKqSlpcHCwgJbtmyRu+SamJiIfv36iZb30KFDQiclR0dH/PXXX9izZw+OHz+OjRs3IjMzE8bGxmjcuDFWrFiRpwnAiBEjYG9vj+3bt2Px4sV49eoVDA0N0axZMyxatKjYO3x0794dp06dQteuXeWGt2zZEkuXLsWWLVswadIkSCQSNGrUCDt27CiwvWSNGjVgZmaGZ8+eoWHDhgBymgvUrVsXCQkJch3BDA0NsWfPHixbtgw+Pj7IyspC/fr1sW7dOrm6nfvZGjlyJLZu3Sq3DCJlxcf9EZGgND4DmYiIvgwbTxARERGRKIZFIiIiIhLFy9BEREREJIpnFomIiIhIFMMiEREREYliWCQiIiIiUWX2PovZ2dn48OEDVFRU5B6HRURERFQWyGQyZGdnQ01NrcD79JbZsPjhwwdERkYquhhERERECmVtbQ0NDQ3R8WU2LOYmaGtr6xJ7FqyykkqliIyMLJPbTiWLdYtKAusVlZSyXrdyt/9TT/8qs2Ex99KzqqpqmawgQNnedipZrFtUElivqKSU9br1qeZ47OBSxmRmZqJbt264ffu2MOzq1atwc3ODnZ0dunfvjosXLwrjZDIZNm/ejNatW8PR0REzZ87Eu3fvCrWeLl26ICQkRBjm7e0NCwuLPH9Dhw4V1hUQEIDWrVvDwcEBw4YNQ0xMTDFuPRERERUVw2IZkpGRAU9PT7kA9vLlS4wbNw6dOnXCX3/9hY4dO2LChAl4/vw5ACAwMBD+/v7w9PTEnj17kJCQAC8vr0Kt5969e3LDZ82aheDgYOEvMDAQGhoaQljcu3cvtmzZgjlz5uDAgQMwMTHB6NGjkZaWVszvBBERERUWw2IZERMTg759++LRo0dyw8PCwqCqqopRo0ahRo0aGDduHDQ1NREeHg4A2LVrF0aMGIEuXbrA3Nwcv/76K86dO4e4uLgirQcAKlSoAENDQ+FvzZo16NChA9q2bQsAOHjwINzd3eHq6oo6depg3rx5SE5ORlhYWPG+GURERFRoZbbNYlkTGhoKZ2dnTJs2DXZ2dsJwPT09JCcn4+TJk2jXrh1Onz6Nd+/eoV69egCAx48fw9bWVpjeyMgIlStXRnh4OExNTQu9nv+6dOkSrly5ghMnTgjDZsyYARMTE+G1RCKBTCbD27dvv2DLiYjoa5FKpcjKylJ0MQpNKpUCANLT00tlm0VVVVWoqal98S0CGRbLiIEDB+Y73NHREYMGDYKHhwdUVFQglUrh6+srBEF9fX0kJCQI079//x4pKSl4/fp1kdbzXwEBAejZsyeMjY3lyvKxffv24cOHD2jUqFGhlklERIqTmpqK+Ph4yGQyRRel0GQyGdTU1PDw4cNSe8/lcuXKwdjYuMBb43wKw2IZ9+7dOzx+/BiTJk2Cq6srTp48CR8fH9ja2sLMzAydOnXChg0b0KhRI5iYmODXX38FgC/65fj48WNcvnwZs2bNEp0mIiICixcvxsiRI2FoaPjZ6yIiopInlUoRHx+PcuXKwdDQ8JsJXjKZDGlpadDW1v5mylxYMpkMmZmZSExMxP3792Fubv7JW+SIYVgs4zZt2gSZTIZJkyYBABo0aIAbN25gx44dmD9/PiZMmIDHjx+jc+fOUFNTQ//+/VG/fn3o6Oh89jpPnDgBS0tL1K1bN9/x169fx+jRo9GiRQtMmTLls9dDRERfR1ZWFmQyGQwNDaGtra3o4hRa7hNMtLS0Sl1YBABtbW2oq6vj4cOHyMzMhJaW1mcth2GxjLt16xbq168vN8zS0lLoyVyuXDmsWrUKb9++hUQigY6ODpo0aYLq1at/9jovXLiANm3a5DsuJCQE48aNQ7NmzbBs2bLP/hVERERfX2kMXN+64vge5TdxGWdkZJTnXoZxcXFCR5MlS5bg4MGDqFChAnR0dHDjxg28ffsW9vb2n7U+mUyGyMhIODg45Bl39+5djB8/Hi4uLli5ciXU1dU/ax1ERERUfHhmsYzr06cPBg4ciG3btqFNmzY4ffo0goODcfDgQQA5YdLf3x9mZmZQUVHBDz/8gAEDBkBPTw8A8PbtW0ilUuH1pzx58gTv3r3L9xL03LlzYWxsjJkzZ8p1oKlQocJnnzonIiKiL8OwWMbZ2dlhzZo1WL16NVatWoU6deogICAA5ubmAIAhQ4bgyZMnGD16NFRUVNC9e3dMnz5dmH/RokV48uQJdu7cWaj1vXz5EgCgq6srNzwxMRHXr18HALRq1UpunK+vL9zc3D53E4mIiIpNfHy8aFMqAIiOjhb+//79ewQEBOD48eN4+vQptLW14ezsjMmTJwvfs7kiIyPh7++Pa9euITs7GxYWFhg5cqRwL+JPrdfJyanQ38VFJZF9S33ci5FUKkV4eDjs7OxK5b2VClKWt51KFusWlQTWK+WXnp6O+/fvo06dOnJXgqTZMqiqfL12jEVdn0wmw/v371GuXLlCt7fMDW379u2Tu/1brtw7eLx79w4DBw7E+/fv4e3tjfr16+P169fYvXs3Tp48iUOHDqFGjRoActryT5gwAX379kWfPn2gqamJs2fPYtWqVRg/fjzGjRsHqVSKV69eCevp3bs33N3d0alTJwCAurp6vlf5xPYNUPjPFs8sEhERUYlQVZFgyt7riHmRWuLrqmukg1X9P689/eeoXLlygbd2W7t2LV6+fIm///4bFStWBABUr14dvr6+ePbsGbZt24Y5c+YgIyMD3t7ecHd3x7Rp04T569SpAxMTE0ydOhWtWrVC/fr15danqqoqPBmtpDEsEhERUYmJeZGKW0/fKLoYovbs2YPdu3cjKSkJ5ubm+Omnn+Do6IgbN27A19cXt2/fRtWqVeHh4YHOnTsXapnZ2dk4ePAgRo0aJQTFjy1ZskQYfubMGSQnJ2PUqFF5pvv+++9hZmaGAwcOFHhv4pLG3tBERERUJt2+fRsrV67E3LlzcezYMTg6OmLq1Kl4+fIl3N3dYWlpiYMHD2Ls2LH48ccfERUVVajlPnr0CK9evcrzZLJcRkZGwiXhmzdvonbt2qhQoUK+0zo4OCAyMvLzNrCY8MwiERERlUlPnjyBRCJBtWrVhEu+rq6uOHr0KHR1dTF79myoqKjA1NQUKSkpSE9PFx5K0aVLlzztHLt27YoFCxYId/T4uDPnxYsXMXHiROF1tWrVcPToUaSkpOR79jGXrq6u6CN2vxaGxTKK9zAkIqKyrnnz5qhbty66desGKysrtGnTBn369MHJkydhZWUld0PrESNGAMjp4AIAAQEBqFKlitzycoNkbvh78+b/L7/b29vj0KFDAICTJ09iz549AHLCYFJSkmgZX7x4gUqVKn3hln4ZXoYuoxpaWSpnr8JsqaJLQEREZYS2tjZ27NiBbdu2wcnJCUFBQXBzc0NWVtYn561WrRpq1aol96evrw8AqFWrFvT09IRbwuWu67/TAYCtrS2ePn0qevbw1q1baNiw4Rdu6ZfhmcUySkVNHTgwCki6q+ii/D+DekCvTYouBRERlRHXr1/HhQsX4OHhgSZNmsDLywtNmzZF1apVERoaCplMJlxqnjp1Kho2bIgOHTp8crlqamro1asXtm/fjl69eglnHHMlJCQI/2/RogUMDQ2xbt26PJ1Yjh8/jtjYWCxZsqQYtvbzMSyWZUl3gWcRii4FERGVYnWNdD49kYLWo6WlhYCAABgbG6Np06a4cuUK3r9/j2bNmmHHjh1YsmQJ+vXrh7CwMJw+fRpjx44V5n316hU0NTXzLFNPTw/q6uqYPHkyrl27hv79+2PSpElo0KABXr9+jX379mH//v3o0qWLUAZfX1+MHz8eMpkMffr0Qbly5XD27FmsWLECHh4esLS0/Pw3phgwLBIREVGJkGbLvuq9D4t6U25LS0v8/PPP2Lx5MxYuXIhq1arBz88P9vb22LBhA3755Rfs3LkTNWrUwLJly2BpaSm0WezTp0++y9y9ezccHR2hra2NnTt3Yvv27Vi3bh0ePnwIDQ0N2NjYYM2aNcKTWQCgSZMm2LNnD9auXYthw4YhIyMDlpaW8PPzk5tOUfgElzL4RACpVJqzzRtaKNeZRWNbYOw/ii4FfYGy/LmiksN6pfwKekqIMvucJ7h8a4rjCS7s4EJEREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEREREJIphkYiIiIhEMSwSERERkSiGRSIiIiISxbBIRERERKIYFomIiKhkZEtL9/oAHDt2DC9fvvzq6/2a+GxoIiIiKhkqqsCBUUDS3ZJfl0E9oNemkl/PR548eYKpU6fi9OnTX3W9XxvDIhEREZWcpLvAswhFl6JEyGQyRRfhq+BlaCIiIipzunXrhl27dgmvR4wYgcGDBwuvAwMDMWDAADx//hxTpkyBk5MTnJ2d4ePjg8zMTABAmzZthH+DgoK+7gZ8RQyLREREVOY0b94coaGhAICsrCyEh4cjMjISWVlZAIB///0XzZo1w7Bhw5CWloadO3di5cqVOHfuHJYsWQIA2Ldvn/Bvp06dFLMhXwHDIhEREZU5zZs3x9WrVyGTyXDr1i3UrFkTFStWxO3bt5GdnY2QkBAAQEJCAvz8/GBhYYEmTZpg7ty52LNnD969e4fKlSsDACpXrgwtLS1Fbk6JYptFIiIiKnMcHR2RlpaG2NhYXL16FY6Ojnjx4gWuXbsGVVVVqKioQENDA7Vr14aurq4wn4ODAz58+IBHjx6hQoUKCtyCr4dhkYiIiMocDQ0NODo64urVq7hy5Qp69OiBFy9e4OrVq5BKpWjWrBk0NTXzzCeVSuX+LQt4GZqIiIjKpObNm+PatWsIDw9Ho0aN0KhRI4SFhSE4OBguLi6oU6cOHjx4gOTkZGGe8PBwqKmpoWbNmpBIJIor/FfEM4tERERUcgzqKe16mjVrhqVLl6JKlSqoUqUKDAwMkJaWhitXrmDFihXQ1dVFjRo1MGPGDHh5eeH169dYuHAhunTpgooVK+LDhw8AgKioKFSqVAnly5cv7q1SCgyLREREVDKypV/3RtnZ0pwbgRdS3bp1UblyZTRq1AgAoKqqCnt7eyQnJwudV9atW4eFCxeib9++KF++PLp27QpPT08AOR1bunXrhqlTp2L69OkYPnx4sW+SMmBYJCIiopJRhOCmqPUdO3YM5cqVE15v2bJFbnyNGjUQEBAgOr+fnx/8/PyKvN5viVKExczMTLi5uWHOnDlwdnaGt7c3Dh48mGc6Z2dn7NixA0BOL6a3b9/KjQ8LCyu1p4CJiIiIFEHhYTEjIwNeXl64d++eMGzWrFnw8vISXj958gRDhgzB0KFDAeTc8+jt27c4deqU3H2NPv5lQERERERfTqFhMSYmBl5eXnmerVihQgW5exd5e3ujQ4cOaNu2LQAgNjYWhoaGqFGjxlctLxEREVFZo9Bb54SGhsLZ2RmBgYGi01y6dAlXrlwRGpMCOSGzTp06X6OIRERERGWaQs8sDhw48JPTBAQEoGfPnjA2NhaGxcbGIi0tDUOGDMH9+/dhaWmJn3766bMCZFm6qWau7OxsqKp+5UbHRVAW90lpURZvVkslj/VK+UmlUshkMmRnZ+e5WqjMcsv6LZW5qHL3iVQqzfMZKuxnSuFtFgvy+PFjXL58GbNmzZIbHhcXh5SUFHh6ekJHRwcbN27E8OHDcfToUejo6BRpHZGRkcVZ5G+CtrY2rKysFF0MUdHR0UhLS1N0MegLlMXPFZU81ivlpqqqirdv336Twas0f+ekpKQgIyMDUVFRn70MpQ6LJ06cgKWlJerWrSs3fPPmzcjKyhJ6Pi9duhQtW7bE2bNn0bVr1yKtw9raWqnPspWE7OxsRRehQBYWFoouAn0mqVSKyMjIMvm5opLDeqX8ZDIZ4uPj8fbtW+jo6EBF5dt4QJxMJkN6ejq0tLRK3dNYZDIZ3r9/j5SUFBgZGaFq1ap5psn9bH2KUofFCxcuoE2bNnmGa2hoQENDQ3itqakJExMTJCQkFHkdqqqqPPgoGe6Pbx8/V1QSWK+UW7Vq1XD//n08evRI0UUpNJlMhqysLKirq5e6sJhLT08PVatW/aLtU9qwKJPJEBkZiXHjxuUZ3q5dO0yYMAFubm4AgPfv3+Phw4cwNTVVRFGJiIjKPA0NDZibmyMzM1PRRSk0qVSKqKgo1K1bt1T+EFFXVy+W7VLasPjkyRO8e/cuzyVoiUSCVq1aYc2aNahevToqV66MVatWoWrVqmjZsqWCSktEREQqKipy9z9WdrkdPLS0tEplWCwuShsWX758CQDQ1dXNM+6HH36AmpoavLy8kJqaisaNGyMgIIA7moiIiKiYKU1YjI6Olntta2ubZ1guTU1NeHt7w9vb+2sUjYiIiKjM+ja6KxERERGRQjAsEhEREZEohkUiIiIiEsWwSERERESiGBaJiIiISBTDIhERERGJYlgkIiIiIlEMi0REREQkimGRiIiIiEQxLBIRERGRKIZFIiIiIhLFsEhEREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEREREJIphkYiIiIhEMSwSERERkSiGRSIiIiISxbBIRERERKIYFomIiIhIFMMiEREREYliWCQiIiIiUQyLRERERCSKYZGIiIiIRDEsEhEREZEohkUiIiIiEsWwSERERESiGBaJiIiISBTDIhERERGJYlgkIiIiIlEMi0REREQkimGRiIiIiEQxLBIRERGRKIZFIiIiIhLFsEhEREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEREREJIphkYiIiIhEMSwSERERkSilCIuZmZno0qULQkJChGE+Pj6wsLCQ+9u1a5cw/siRI2jbti1sbW0xceJEvHr1ShFFJyIiIirVFB4WMzIy4OnpiXv37skNj42NhZeXF4KDg4W/Xr16AQBu3LiBWbNmYdKkSQgMDMSbN28wc+ZMRRSfiIiIqFRTU+TKY2Ji4OXlBZlMlmdcbGwsRo4cCUNDwzzjdu3ahY4dO6JHjx4AgCVLlsDV1RWPHz9GjRo1SrrYRERERGWGQsNiaGgonJ2dMW3aNNjZ2QnDU1NTkZCQgNq1a+c7X0REBEaPHi28NjY2RrVq1RAREVHksCiVSj+n6N+07OxsqKqqKroYosriPiktcvcd9yEVJ9YrKillvW4VdrsVGhYHDhyY7/DY2FhIJBL89ttv+Oeff6Cnp4cRI0agZ8+eAIAXL17AyMhIbh59fX08f/68yGWIjIwsesG/cdra2rCyslJ0MURFR0cjLS1N0cWgL1AWP1dU8livqKSwbhVMoWFRTFxcHCQSCUxNTTF48GBcuXIFc+bMgY6ODtq1a4f09HRoaGjIzaOhoYHMzMwir8va2lqpz7KVhOzsbEUXoUAWFhaKLgJ9JqlUisjIyDL5uaKSw3pFJaWs163c7f8UpQyLPXr0gKurK/T09AAA9evXx4MHD7Bnzx60a9cOmpqaeYJhZmYmtLW1i7wuVVXVMllBlBn3x7ePnysqCaxXVFJYtwqm8N7Q+ZFIJEJQzGVqaoqEhAQAQJUqVZCUlCQ3PikpKd/OMERERET0+ZQyLK5atQrDhw+XGxYVFQVTU1MAgK2tLa5duyaMe/bsGZ49ewZbW9uvWUwiIiKiUk8pw6KrqyuuXLmCzZs349GjR/j9999x6NAhuLu7AwAGDBiAw4cPY9++fYiKisKMGTPQqlUr3jaHiIiIqJgpZZtFGxsbrFq1CqtXr8aqVatQvXp1LFu2DPb29gAAe3t7LFiwAKtXr0ZKSgqaNWuGhQsXKrjURERERKWP0oTF6Ohouddt27ZF27ZtRad3c3ODm5tbSReLiIiIqExTysvQRERERKQcGBaJiIiISBTDIhERERGJYlgkIiIiIlEMi0REREQkimGRiIiIiEQxLBIRERGRKIZFIiIiIhLFsEhEREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEREREJIphkYiIiIhEMSwSERERkSiGRSIiIiISxbBIRERERKIYFomIiIhIFMMiEREREYliWCQiIiIiUQyLRERERCSKYZGIiIiIRDEsEhEREZEohkUiIiIiEsWwSERERESiGBaJiIiISBTDIhERERGJYlgkIiIiIlEMi0REREQkimGRiIiIiEQxLBIRERGRKIZFIiIiIhLFsEhEREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEREREJIphkYiIiIhEMSwSERERkSiGRSIiIiISxbBIRERERKKUIixmZmaiS5cuCAkJEYaFh4ejf//+sLe3R/v27bFv3z65ebp16wYLCwu5v7t3737tohMRERGVamqKLkBGRga8vLxw7949YVhiYiJGjx6NAQMG4Ndff8WtW7cwc+ZMGBoaolWrVpBKpXjw4AF27dqF2rVrC/NVqlRJAVtAREREVHopNCzGxMTAy8sLMplMbvipU6dgYGAAT09PAEDt2rUREhKCv/76C61atUJ8fDyysrJgY2MDTU1NRRSdiIiIqExQaFgMDQ2Fs7Mzpk2bBjs7O2G4i4sLLC0t80yfmpoKICdkGhsbMygSERERlTCFhsWBAwfmO9zExAQmJibC65cvX+Lo0aOYPHkyACA2Nhbq6uoYO3Ysbt68iTp16mDGjBmwsbEpchmkUunnFf4blp2dDVVVVUUXQ1RZ3CelRe6+4z6k4sR6RSWlrNetwm63wtssfkp6ejomT54MAwMD9OvXDwBw//59pKSkoE+fPvDw8MAff/yBYcOG4e+//4axsXGRlh8ZGVkSxVZq2trasLKyUnQxREVHRyMtLU3RxaAvUBY/V1TyWK+opLBuFUypw+K7d+8wYcIEPHjwAL///ju0tbUBAAsXLkR6ejp0dHQAAPPmzUNYWBgOHz6McePGFWkd1tbWSn2WrSRkZ2cruggFsrCwUHQR6DNJpVJERkaWyc8VlRzWKyopZb1u5W7/pyhtWExNTcWoUaPw6NEjbN++Xa7Xs5qamhAUAUAikcDU1BQJCQlFXo+qqmqZrCDKjPvj28fPFZUE1isqKaxbBVOK+yz+V3Z2NiZNmoT4+Hjs3LkT5ubmcuOHDBkCf39/uemjo6Nhamr6tYtKREREVKop5ZnF/fv3IyQkBOvXr0fFihWRmJgIAFBXV4eenh5at26NtWvXwtLSEnXq1MGOHTvw9u1b9OzZU8ElJyIiIipdlDIsnjhxAtnZ2Rg7dqzccCcnJ+zcuRPDhw9HRkYGfHx8kJSUBFtbW2zdulXu0jQRERERfTmlCYvR0dHC/zdv3lzgtBKJBOPGjStyZxYiIiIiKhqlbLNIRERERMqBYZGIiIiIRDEsEhEREZEohkUiIiIiEsWwSERERESiGBaJiIiISBTDIhERERGJYlgkIiIiIlEMi0REREQkimGRiIiIiEQxLBIRERGRKIZFIiIiIhLFsEhEREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEREREJIphkYiIiIhEMSwSERERkSiGRSIiIiISxbBIRERERKIYFomIiIhIFMMiEREREYliWCQiIiIiUQyLRERERCRKragzXLx4ERcuXMCtW7fw6tUrSCQSGBoawsrKCi1atICTk1NJlJOIiIiIFKDQYfHgwYP47bff8O7dOzRp0gTNmjWDnp4esrOz8fr1a0RHR2P69OkoV64cRo8ejV69epVkuYmIiIjoKyhUWBwyZAhMTEzg5+cHGxubAqcNDQ1FYGAggoKCsHv37mIpJBEREREpRqHC4vz582FqalqoBTo5OcHJyQmxsbFfVDAiIiIiUrxCdXApKChmZGTgxo0bePv2rdxwMzOzLysZERERESlckXtDx8TEoG/fvggLC8ObN2/Qo0cP9O3bFy1atMDly5dLooxEREREpCBFDovz589HjRo1UKdOHezfvx9v375FcHAwxo0bh8WLF5dEGYmIiIhIQYocFm/cuIGpU6eiUqVKOHXqFNq1awcDAwN06dIFcXFxJVFGIiIiIlKQIofFChUqICkpCc+ePUN4eDhatWoFALhz5w709fWLu3xEREREpEBFvim3m5sbxo8fDw0NDZiYmKB58+bYs2cPlixZgilTppREGYmIiIhIQYocFj09PWFtbY0nT56gS5cuUFVVRbVq1bB8+XK4urqWRBmJiIiISEEKFRbv37+POnXqCK/btWsnN75ly5Z55omLiyv0vRmJiIiISDkVKizOnTsXJiYmGDBgwCef4HL16lXs3bsXz5494xNciIiIiL5xhQqLO3fuRFBQEKZPn4709HQ0adIEZmZmqFSpEqRSKZKTkxEdHY2wsDBoampi9OjR6N27d0mXnYiIiIhKWKHbLLq5ucHNzQ0XLlxAcHAwLly4gFevXkEikUBfXx9WVlbw9fVF48aNoaJS5E7WRERERKSEitzBxcXFBS4uLiVRFiIiIiJSMjwFSERERESilCIsZmZmokuXLggJCRGGPX78GMOHD4ednR06deqE4OBguXkuXryILl26wNbWFkOHDsXjx4+/drGJiIiISj2Fh8WMjAx4enri3r17wjCZTIaJEyfCwMAABw4cQPfu3TFp0iQ8ffoUAPD06VNMnDgRbm5u2L9/PypXrowJEyZAJpMpajOIiIiISiWFhsWYmBj07dsXjx49kht++fJlPH78GAsWLICZmRnGjh0LOzs7HDhwAACwb98+NGzYEO7u7jA3N4evry+ePHmC0NBQRWwGERERUan1WWHx8ePHWLx4MSZMmIAXL15g//79uHr1apGXExoaCmdnZwQGBsoNj4iIgJWVFcqVKycMa9SoEcLDw4Xxjo6OwjhtbW00aNBAGE9ERERExaPIvaGvXLmCMWPGwMXFBRcuXEBGRgbi4uIwb948LF++HN9//32hlzVw4MB8hycmJsLIyEhumL6+Pp4/f16o8UUhlUqLPM+3Ljs7G6qqqoouhqiyuE9Ki9x9x31IxYn1ikpKWa9bhd3uIodFPz8/eHl5YfDgwbC3twcAzJgxA0ZGRli9enWRwqKYtLQ0aGhoyA3T0NBAZmZmocYXRWRk5OcX9Bulra0NKysrRRdDVHR0NNLS0hRdDPoCZfFzRSWP9YpKCutWwYocFu/evZvvs6DbtGmD5cuXF0uhNDU1kZycLDcsMzMTWlpawvj/BsPMzExUrFixyOuytrZW6rNsJSE7O1vRRSiQhYWFootAn0kqlSIyMrJMfq6o5LBeUUkp63Urd/s/pchhsXr16oiMjESNGjXkhp87dw7Vq1cv6uLyVaVKFcTExMgNS0pKEi49V6lSBUlJSXnGW1paFnldqqqqZbKCKDPuj28fP1dUElivqKSwbhWsyGFx6tSp8Pb2RmRkJKRSKQ4dOoT4+HgcPXoUS5YsKZZC2draIiAgAOnp6cLZxGvXrqFRo0bC+GvXrgnTp6Wl4fbt25g0aVKxrJ+IiIiIchS5N3S7du2we/duvHz5Eubm5jh9+jQyMzOxe/dudOrUqVgK5eTkBGNjY8ycORP37t1DQEAAbty4gd69ewMAevXqhbCwMAQEBODevXuYOXMmTExM4OzsXCzrJyIiIqIcRT6zCAD169cvtrOI+VFVVcW6deswa9YsuLm5oVatWli7di2qVasGADAxMcGaNWvwyy+/YO3atbC3t8fatWshkUhKrExEREREZVGRw+KLFy+wadMmxMXF5dv7eMeOHZ9VkOjoaLnXtWrVwq5du0Snb9myZb4dbYiIiIio+BQ5LE6bNg2JiYn4/vvvhfaERERERFQ6FTks3rp1C3v37kX9+vVLojxEREREpESK3MHF1tY2z7OciYiIiKh0KvKZxUWLFmHAgAE4c+YMqlevnqdTCW9fQ0RERFR6FDksrlixAq9fv0ZcXByePHkiN469kYmIiIhKlyKHxdOnT2PLli1wcnIqifIQERERkRIpcpvFatWqQVtbuyTKQkRERERKpshnFj08PODt7Y3hw4fDxMQEamryi/juu++KrXBEREREpFif9WxoAJgzZ06ecRKJBHfu3PniQhERERGRcihyWIyKiiqJchARERGREipUWHz69CmMjY0hkUjw9OnTAqfNfX4zEREREX37ChUW27Rpg+DgYOjr66N169aQSCSQyWTC+NzXvAxNREREVLoUKiz+8ssvqFixIoCcW+cQERERUdlQqLD4008/oUWLFtDX10f16tVLukxEREREpCQKdZ/Fjy85ExEREVHZUeibcvNRfkRERERlT6FvndOrVy+oqHw6W7JNIxEREVHpUeiwOGLECFSoUKEky0JERERESqZQYVEikaBz587Q19cv6fIQERERkRJhBxciIiIiElWosNizZ09oamqWdFmIiIiISMkU6jK0r69vSZeDiIiIiJRQoW+dQ0RERERlD8MiEREREYliWCQiIiIiUQyLRERERCSKYZGIiIiIRDEsEhEREZEohkUiIiIiEsWwSERERESiGBaJiIiISBTDIhERERGJYlgkIiIiIlEMi0REREQkimGRiIiIiEQxLBIRERGRKIZFIiIiIhLFsEhEREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEREREJEpN0QUQExQUhJkzZ+YZLpFIEBUVhfHjx+PMmTNy43777Te4urp+rSISERERlXpKGxY7deoEFxcX4fWHDx8wbNgwtGrVCgAQGxsLPz8/NGnSRJhGV1f3axeTiIiIqFRT2rCopaUFLS0t4fWGDRsgk8kwffp0ZGZmIj4+HtbW1jA0NFRgKYmIiIhKt2+izWJycjI2btwILy8vaGhoIC4uDhKJBDVq1FB00YiIiIhKNaU9s/ixPXv2wMjICB06dAAAxMXFQUdHBzNmzEBoaCiqVq2KyZMno2XLlkVetlQqLe7iKr3s7GyoqqoquhiiyuI+KS1y9x33IRUn1isqKWW9bhV2u5U+LMpkMuzbtw+jRo0ShsXFxSE9PR3NmzfHmDFj8L///Q/jx49HYGAgrK2ti7T8yMjI4i6y0tPW1oaVlZWiiyEqOjoaaWlpii4GfYGy+Lmiksd6RSWFdatgSh8WIyMjkZCQgM6dOwvDJkyYgCFDhggdWurXr49bt27hjz/+KHJYtLa2VuqzbCUhOztb0UUokIWFhaKLQJ9JKpUiMjKyTH6uqOSwXlFJKet1K3f7P0Xpw+KFCxfg6Ogo19NZRUUlT89nU1NTxMTEFHn5qqqqZbKCKDPuj28fP1dUElivqKSwbhVM6Tu43LhxAw4ODnLDvL2989yDMSoqCqampl+zaERERESlntKHxXv37qFu3bpyw1q3bo2//voLhw4dwsOHD+Hv749r165h8ODBCiolERERUemk9Jehk5KSULFiRblh33//PX7++WesX78eT58+hbm5OTZt2gQTExMFlZKIiIiodFL6sHjjxo18h/fp0wd9+vT5yqUhIiIiKluU/jI0ERERESkOwyIRERERiWJYJCIiIiJRDItEREREJIphkYiIiIhEMSwSERERkSiGRSIiIiISxbBIRERERKIYFomIiIhIFMMiEREREYliWCQiIiIiUQyLRERERCSKYZGIiIiIRDEsEhEREZEohkUiIiIiEsWwSERERESiGBaJiIiISBTDIhERERGJYlgkIiIiIlEMi0REREQkimGRiIiIiEQxLBIRERGRKIZFIiIiIhLFsEhEREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEREREJIphkYiIiIhEMSwSERERkSiGRSIiIiISxbBIRERERKIYFomIiIhIFMMiEREREYliWCQiIiIiUQyLRERERCSKYZGIiIiIRDEsEhEREZEohkUiIiIiEsWwSERERESiGBaJiIiISBTDIhERERGJUuqw+L///Q8WFhZyfx4eHgCA27dvo0+fPrC1tUWvXr1w8+ZNBZeWiIiIqPRR6rAYExMDV1dXBAcHC38+Pj54//49xowZA0dHRwQFBcHe3h5jx47F+/fvFV1kIiIiolJFqcNibGws6tWrB0NDQ+GvYsWK+Pvvv6GpqYkZM2bAzMwMs2bNQvny5XH8+HFFF5mIiIioVFH6sFi7du08wyMiItCoUSNIJBIAgEQigYODA8LDw79uAYmIiIhKOTVFF0CMTCbD/fv3ERwcjA0bNkAqlaJDhw7w8PBAYmIi6tatKze9vr4+7t27V+T1SKXS4iryNyM7OxuqqqqKLoaosrhPSovcfcd9SMWJ9YpKSlmvW4XdbqUNi0+fPkVaWho0NDSwcuVKxMfHw8fHB+np6cLwj2loaCAzM7PI64mMjCyuIn8ztLW1YWVlpehiiIqOjkZaWpqii0FfoCx+rqjksV5RSWHdKpjShsXq1asjJCQEurq6kEgksLS0RHZ2Nn744Qc4OTnlCYaZmZnQ0tIq8nqsra2V+ixbScjOzlZ0EQpkYWGh6CLQZ5JKpYiMjCyTnysqOaxXVFLKet3K3f5PUdqwCAB6enpyr83MzJCRkQFDQ0MkJSXJjUtKSoKRkVGR16GqqlomK4gy4/749vFzRSWB9YpKCutWwZS2g8uFCxfg7Owsdznyzp070NPTQ6NGjXD9+nXIZDIAOe0bw8LCYGtrq6jiEhEREZVKShsW7e3toampidmzZyMuLg7nz5/HkiVLMGrUKHTo0AFv3rzBokWLEBMTg0WLFiEtLQ0dO3ZUdLGJiIiIShWlDYs6OjrYvHkzXr16hV69emHWrFno168fRo0aBR0dHWzYsAHXrl2Dm5sbIiIiEBAQgHLlyim62ERERESlilK3WTQ3N8fWrVvzHWdjY4ODBw9+5RIRERERlS1Ke2aRiIiIiBSPYZGIiIiIRDEsEhEREZEohkUiIiIiEsWwSERERESiGBaJiIiISBTDIhERERGJYlgkIiIiIlEMi0REREQkimGRiIiIiEQxLBIRERGRKIZFIiIiIhLFsEhEREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEREREJIphkYiIiIhEMSwSERERkSiGRSIiIiISxbBIRERERKIYFomIiIhIFMMiEREREYliWCQiIiIiUQyLRERERCSKYZGIiIiIRDEsEhEREZEohkUiIiIiEsWwSERERESiGBaJiIiISBTDIhERERGJYlgkIiIiIlEMi0REREQkimGRiIiIiEQxLBIRERGRKIZFIiIiIhLFsEhEREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEREREJIphkYiIiIhEKXVYTEhIgIeHB5ycnODi4gJfX19kZGQAAHx8fGBhYSH3t2vXLgWXmIiIiKh0UVN0AcTIZDJ4eHigYsWK2L17N1JSUvDTTz9BRUUFP/74I2JjY+Hl5YWePXsK8+jo6CiwxERERESlj9KeWYyLi0N4eDh8fX1hbm4OR0dHeHh44MiRIwCA2NhYWFlZwdDQUPjT1tZWcKmJiIiIShelPbNoaGiITZs2wcDAQG54amoqUlNTkZCQgNq1a3/xeqRS6Rcv41uTnZ0NVVVVRRdDVFncJ6VF7r7jPqTixHpFJaWs163CbrfShsWKFSvCxcVFeJ2dnY1du3ahcePGiI2NhUQiwW+//YZ//vkHenp6GDFihNwl6cKKjIwszmJ/E7S1tWFlZaXoYoiKjo5GWlqaootBX6Asfq6o5LFeUUlh3SqY0obF//Lz88Pt27exf/9+3Lp1CxKJBKamphg8eDCuXLmCOXPmQEdHB+3atSvScq2trZX6LFtJyM7OVnQRCmRhYaHoItBnkkqliIyMLJOfKyo5rFdUUsp63crd/k/5JsKin58ftm/fjhUrVqBevXowNzeHq6sr9PT0AAD169fHgwcPsGfPniKHRVVV1TJZQZQZ98e3j58rKgmsV1RSWLcKprQdXHItXLgQW7duhZ+fH9q3bw8AkEgkQlDMZWpqioSEBAWUkIiIiKj0Uuqw6O/vj71792L58uXo3LmzMHzVqlUYPny43LRRUVEwNTX9yiUkIiIiKt2UNizGxsZi3bp1GD16NBo1aoTExEThz9XVFVeuXMHmzZvx6NEj/P777zh06BDc3d0VXWwiIiKiUkVp2yyePn0aUqkU69evx/r16+XGRUdHY9WqVVi9ejVWrVqF6tWrY9myZbC3t1dQaYmIiIhKJ6UNi2PGjMGYMWNEx7dt2xZt27b9iiUiIiIiKnuU9jI0ERERESkewyIRERERiWJYJCIiIiJRDItEREREJIphkYiKRWZmJrp164bbt2/LDX/48CFsbGw+Of/x48fRvn172NnZwd3dHU+ePBHGJSQkwMPDA05OTnBxcYGvry8yMjKE8Y8fP8bw4cNhZ2eHTp06ITg4ON91REREwNLSEvHx8Z+5lUREZQ/DIhF9sYyMDHh6eiImJkZu+LNnzzB27Fi5YJefsLAweHl5YcSIEQgKCoKGhgY8PT0BADKZDB4eHkhLS8Pu3buxYsUKnD17FitXrhTGT5w4EQYGBjhw4AC6d++OSZMm4enTp3LryMrKwuzZs5X+2ehERMqGYZGIvkhMTAz69u2LR48eyQ0/deoU3NzcoKGh8cllbNmyBd26dUP//v1hamqKWbNmITExEa9evUJcXBzCw8Ph6+sLc3NzODo6wsPDA0eOHAEAXL58GY8fP8aCBQtgZmaGsWPHws7ODgcOHJBbx6ZNm6Cjo1N8G05EVEYwLBLRFwkNDYWzszMCAwPlhp87dw5TpkzBrFmzCrWMdu3aCa9r1KiBM2fOoHLlyjA0NMSmTZtgYGAgN09qaiqAnEvLVlZWKFeunDCuUaNGCA8PF17fv38fu3fvhre39+dsIhFRmaa0N+Umom/DwIED8x3u4+MDAAgJCSlw/jdv3iAlJQVSqRQjR45EVFQUbGxsMG/ePFSpUgUVK1aEi4uLMH12djZ27dqFxo0bAwASExNhZGQkt0x9fX08f/4cQM5l6rlz52Ly5MnQ19f/7O0kIiqreGaRiBTq/fv3AHLCZdeuXbF+/XpkZmZi7Nix+bYv9PPzw+3btzFt2jQAQFpaWp5L3RoaGsjMzAQA7N+/H1lZWejbt28JbwkRUenEsEhECqWqqgoA6NOnD3r06AEbGxssXboUd+/elbuUDOQExe3bt8PPzw/16tUDAGhqagrBMFdmZia0tLSQmJiIFStWYMGCBZBIJF9le4iIShtehiYihapUqRLU1dVhamoqN0xPT0+4lAwACxcuxJ49e+Dn54f27dsLw6tUqZKnF3ZSUhKMjIwQHByM169fo1+/fgByLkkDQJcuXTBu3DiMGzeuJDeNiKhUYFgkIoVSU1NDgwYNEBUVhU6dOgEAXr16hdevX6N69eoAAH9/f+zduxfLly9Hhw4d5Oa3tbVFQEAA0tPToaWlBQC4du0aGjVqhHbt2sHBwUGYNiEhAUOGDEFAQIBwZpKIiArGsEhEX11mZiZSUlJQuXJlqKqqYsSIEZg5cyYsLS1Rr149+Pn5wdLSEjY2NoiNjcW6deswZswYNGrUCImJicJyDA0N4eTkBGNjY8ycORMTJkzA2bNncePGDfj6+kJHR0fudjm5l7yrVasGPT29r73ZRETfJIZFIvrqrl+/jqFDh+L06dMwMTFBhw4d8ObNG/j5+eHly5dwcnLCunXrIJFIcPr0aUilUqxfvx7r16+XW050dDRUVVWxbt06zJo1C25ubqhVqxbWrl2LatWqKWjriIhKF4kstxFPGSOVShEeHg47OzvhbENZIZVKc7Z5QwvgWYSii/P/jG2Bsf8ouhT0Bcry54pKDusVlZSyXrcKu/3sDU1EREREohgWiYiIiEgUwyIRERERiWJYJCIiIiJRDItEVKzU1dUVXQQiIipGDItEVKwaWlkqX6/CbKmiS0BE9M3ifRaJqFipqKkDB0YBSXcVXZQcBvWAXpsUXQoiUgIPHz7EggULEBYWBl1dXQwcOBCNGjUqcJ6rV6/ixx9/xOnTp+WGHz9+HCtWrEBCQgIcHBywcOFC4alTz549w7x583DlyhXo6elh6NChGD58OABgyJAhCA0NzbMeNzc3+Pr6IisrCytXrsThw4fx4cMH9OzZE15eXlBTU1xkY1gkouKXdFe57uFJ35SEhAQsWrQIly9fhqamJjp27AhXV9d8p/3f//6H5cuX4/nz56hfvz5mz56NBg0a5Jlu9uzZqFKlCiZPniwM+29wGDx4MEaNGpVn3ocPH6Jr1664ceOG3PCtW7di+/bteP36NRwdHTFnzhzUrl37yzaeSkx2djbGjBkDa2trHDx4EA8fPoSnpyeGDRsGOzu7fOeJjo7GlClToKmpKTc8LCwMXl5emDNnDpycnLBkyRJ4enoiMDAQADB16lRUq1YNQUFBiImJwfTp01G9enW0a9cOa9asQVZWlrCsiIgITJ06FQMHDgQArF69GocOHcIvv/wCAwMDzJo1C7/++itmz55dMm9MIfAyNBERKQ2ZTAYPDw+kpaVh9+7dWLFiBc6ePYt9+/blmfbevXvw8vLC2LFjcfjwYVhaWmLs2LFIS0uTm27jxo155s8NDpUqVcLBgwcxf/58rF+/Hn/99ZfcdM+ePcPYsWORkZEhN/zPP//E2rVrMX/+fBw+fBh6enoYN24cyuhzLr4JSUlJsLS0xLx581C7dm20bNkSjRs3RnR0dL7T7927F/3794e+vn6ecVu2bEG3bt3Qv39/mJqaYtasWUhMTMSrV6+QkpKC8PBwjB8/HrVr10bbtm3h4uKCS5cuAQD09PRgaGgIQ0NDVK5cGStWrMCoUaNgbW0NmUyG3bt3w9PTEy1btkSDBg0wf/587N27F+/evSvR96cgDItERKQ04uLiEB4eDl9fX5ibm8PR0RGTJ0/GxYsX80z777//om7duujRowdq1qwJT09PJCYmIiYmBgCQmpoKDw8PbNy4EcbGxnLz5hccmjRpgmvXrgnTnDp1Cm5ubtDQ0Miz7rdv3+KHH35Ay5YtUbt2bYwePRr379/Hq1evivkdoeJiZGSElStXQkdHBzKZDNeuXcPVq1dhZWWV7/T//PMPFi9eLFw+/lhoaCjatWsnvK5RowbOnDmDypUrQ0tLC9ra2ggKCkJWVhbi4uIQFhYGS0vLPMsJCgpCSkoKRo8eDQB49eoV3r17B1tbW2EaCwsLZGVl4ebNm1/4Dnw+hkUiIlIahoaG2LRpEwwMDOSGv3//Ps+0enp6iImJwbVr15CdnY2goCDo6OigZs2aAID4+HhkZGQgKCgINWrUkJs3v+Bw5coVODk5CdOcO3cOU6ZMwaxZs/Kse9CgQejXrx+AnOD4+++/w9zcHJUrV/7i94BKXuvWrTFw4EDY2dnJ7fOPrVu3Dt9//32e4W/evEFKSgqkUilGjhyJZs2aYfz48UhISAAAaGpqYu7cuQgMDIStrS06duyIFi1aoE+fPnLLkclk2LRpE4YOHYry5csDAHR1daGuri4sC8g5uw0Ar1+/LpZt/xwMi0REpDQqVqwIFxcX4XV2djZ+//13NGzYMM+0nTp1QqtWrTBw4EA0bNgQS5YswerVq6GrqwsAqF+/PjZs2AATE5MC15kbHOzt7dG+fXthuI+PD/r371/gvPv374ejoyMOHjyIuXPnQiKRFGVzSUFWr16N3377DVFRUdi5c2eR5s394eLj44OuXbti/fr1yMzMxNixY5GdnQ0AiI2NhaurKwIDA+Hr64vjx4/jzz//lFtOSEgInj9/jr59+wrD1NTU0K5dO6Ed7tu3b7F48WKoqanJtXP82hgWib4RGRkZ+Omnn+Do6IjmzZtjy5Ytn5zn6tWraNOmTZ7hx48fR/v27WFnZwd3d3c8efIk3/nHjBkDb29vuWG3b99Gnz59YGtri169esldGpHJZAgICEDrTYlw2GeEYWcqISZFyW6jU8YVpR79+eefaN++PWxsbNC/f/88HTwKqkf/+9//YGFhIffn4eGRZx3x8fGwt7dHSEiIMCwlJUWYx9LSEtevX8ft27cBAGvWrBHGWVtb48SJEwAAfX19dO/eHTNnzsTLly+L9J7kBoc7d+7A19e3SPM2bdoUBw8eRN++fTFhwgQ8fvy4SPOXFZ9z/MqvbmRlZcHPzw/NmzdH48aNsXjxYnz48CHf+fM7fgUHB6Nbt24YOnQotm/fjhEjRuD06dPIzMws9Lbk3hqsT58+6NGjB2xsbLB06VLcvXsX4eHhuHTpEvbv349ffvkF1tbWcHNzw5gxY7B+/Xq55Zw4cQItWrSAnp6e3PDZs2ejfPnyaNmyJVq0aAEHBwfo6upCR0en0GUsbgyLX6i4vsCFL9nWreHg4IBhw4YJ7W6AnIPn9OnT4eTkBBcXFyxbtkz4BQMA4eHh6N+/v/DL+L+Nubt16yYcYK2srGBhYYG7STkfsHdZEswOrYjGQUZoccgQAbfLf8lbQiVkyZIluHnzJrZv346ff/4Z/v7+OH78uOj0ub34/tvgPrcX34gRIxAUFAQNDQ14enrmmf/o0aM4f/683LD3799jzJgxcHR0RFBQEOzt7TF27Fjhl3ZgYCC2bNmCOa0r4kD7lzApL8Xoc5WRlv+xnBSgsPXo6tWrmDVrFiZMmICjR4/C3t4eo0ePFhrZf6oexcTEwNXVFcHBwcKfj49PnvXMmzcvzyXmmJgY6OnpYeDAgVBVVcWCBQuwfPlyAIC7u7uwvPbt26NTp07Q09PDqFGjsHDhQmhra+PAgQNFek+sra3h6uqKmTNnYu/evUUKDtWqVYOVlRVmz54NY2NjHDp0qEjrLiuKevwC8q8buT2FFy1ahM2bN+PSpUv49ddf88yb3/ErNDQUo0ePRps2bXDgwAFYWVlhw4YN+PDhQ5E6j1SqVAnq6uowNTWVG6anp4fnz5/j5s2bqFWrFrS0tITxVlZWePr0qdxyLly4kO+PeX19fezYsQMhISG4ePEiBg8ejJcvXwq35VEEhsUvVFxf4Hv37s35kp0zBwcOHICJiQlGjx4t9OqbP38+Xrx4gd27d8PPzw8HDx7Ejh07AACJiYkYPXo0nJyccPDgQXh4eGDhwoU4d+4cAEAqleLBgwfYtWsXgoODcf78eQQHB8O0cs6vozmhFXHlhQbWurzG8qbJ2BtTDlujypXAu0Wf6/3799i3bx9mzZqFBg0aoF27dhg1ahR2796d7/Sf24svV3JyMpYsWQJra2u5ef/++29oampixowZMDMzw6xZs1C+fHmhzh86dAju7u5wNdVEnYpSzPvuDZIzJQhLzNtBgL6+otSjxMRETJgwAd27d0eNGjUwceJEJCcnIzY2FsCn61FsbCzq1asn9Po0NDRExYoV5dbx559/5vslHRcXBzU1NQQGBsLPzw+9e/cWLi2XL19eWF5MTAwSEhJQt25dDB06FCoqKqhfv36eL+X8JCUl4dSpU3LD6tati6ysLKSmpn5y/suXLyMuLk54LZFIYGpqqtB2ZcqqqMcvIP+6UdiewmLHr127diE7O1uosz/88ANUVVWhpaWFSpUqFXp71NTU0KBBA0RFRQnDXr16hdevX6N69eowMjLCw4cP5X50xMXFyTWHePXqFR4/fpzvPR5/+OEHBAcHQ09PD9ra2jh//jz09fVRt27dQpexuDEsfoHi/AI/ePBgzpesqyvq1KmDefPmITk5GWFhYQCA8+fPY8SIETA3N0fjxo3RpUsXoRv+qVOnYGBgAE9PT9SuXRudO3dGjx49hFtAxMfHIysrCzY2NnIHbjUVCV5lSHD0kTbmf/cGjQyz4GiUhem2b7E5imcXlUlUVBQ+fPgAe3t7YVijRo0QEREhd4Y51+f24su1ePFidO/ePc/BKSIiAo0aNRLaZUkkEjg4OCA8PBxAzkGuW7duwvQSADIZ8DaL7biUQVHqUceOHTF+/HgAQHp6OrZt2wZ9fX2YmZkB+HQ9io2NLfCeg69fv4afnx8WLFiQZ9z+/fvx8uVLLF++HJ07dxZdRoUKFXD9+nX8+OOPQp28f//+J9soAjnHxUmTJsl1JLh58yYqV65cqE4qGzduxLZt24TXUqkUUVFRwvtD/6+oxy+xulHYnsJix6/379/DwMAAP/30E2JiYvDPP/8gJSVFOGOXmJiI9PT0Qm3TiBEjsHPnThw7dgyxsbH46aefYGlpCRsbG7Ru3Rrq6uqYPXs27t+/jzNnzuC3337DkCFDhPnv3bsHTU3NfOuqnp4eVqxYgbt37yIkJAQLFy7EmDFjoKKiuMjGsPgFivMLfMaMGfJfshIJZDIZ3r59CyCn8vz5559IS0tDQkICLly4IHTDd3FxybedTe6v45iYGBgbG+e5qSgAxKfm3JfdVv//fwFZ6GUhMU0V8alsa6YsEhMTUalSJblbeBgYGCAjIwPJycl5pv/cXnwAcOnSJVy9ehUTJkzItxxGRkZyw/T19fH8+XMAOfW/atWqwrh9sdr4IJOgkaHiGmbT/ytqPQJy6oO9vT38/f3x008/oXz58p+sRzKZDPfv3xcuFbdt2xZLly6VO9Py66+/omfPnjA3N5dbX2xsLMLDw1GtWjWsX78eTZs2xaRJk/DgwQNhG3K/0HMv88XFxeHhw4dYunQpnj59ip49e37yvbC2tkaDBg2E4HD+/Hn4+flh3LhxhXovBw4ciKCgIPz111+Ii4vDvHnzkJ6ejh49ehRq/rKkqPVOrG4UpqdwQccvQ0ND2NnZQVtbG/369cOsWbOgr6+PChUqAACaN2+Ov//+u1Db1KFDB8ycORN+fn5wc3ODVCrFunXrIJFIUKFCBWzbtg2JiYno3bs3fH19MX78eKH3PAC8fPkSFStWzLdD1NSpU2FmZoaBAwfihx9+wPDhw/PNDV8Tn+DyBT71Afjvr9N169YByLmv0n85OjrKvd63bx8+fPggnKL++eefMWPGDDg4OCA7O1s4gAKAiYmJ3K+Tly9f4ujRo8KTCmJjY6Guro6xY8fi5s2bqF27Nn788UfYANDXynlmbkKaKmpXyPn/s/c5IfF1hgQmimtPSx9JS0vLc6+33NdFaV/1cS++adOmYcqUKVi1ahXGjh0r3BPs559/xty5c+Xa23yqHPmVISJJHYuvV8BIy3cw1M7744m+vs+pR+bm5ggKCsLZs2fh7e0NExMT4QeBWD169uyZsK6VK1ciPj4ePj4+SE9Px+zZs3Hx4kVcu3YNR44cybO+3EeqfdxZ5syZMzhz5gy6du2K5s2bw9fXF99//z1u3LiBwYMHY8OGDXj+/DksLS2xffv2fK/e/JeqqirWrVuHhQsXol+/ftDW1saQIUMwdOjQQr2Xbdq0wbx58+Dv749nz57Bzs4OW7ZsEW6BQv+vKPWuoLrxcU9hMzMzlC9fXq6ncEZGRoHHr44dO2LChAlYs2YNVq5cib/++guzZ88WbtMkdnNuNzc3uLm55Rnet29fuZ7MH6tbty62bt2a7zggpyd/p06d8h1Xvnx5LFmyRHReRWBY/ALF9QX+XxEREVi8eDFGjhwJQ0NDADmXVho2bIhJkyYhMTER8+fPx8aNG4XLRLnS09MxefJkGBgYCL9i7t+/j5SUFPTp0wceHh4IDAzEsGHD8PegcqhePht2+plYdK0i/JokIytbAv+bOQkxK5uXDpWFpqZmnjqV+zq/g6KY//biA4ClS5eiWbNmCA8Px9mzZ9GwYUO5W5cUphz/LcP1p5kYfa4SWlTLxBTrT7f/oq/jc+qRgYEBDAwMYGlpiYiICOzduxdeXl4AxOuRg4MDQkJCoKurC4lEAktLS2RnZ+OHH36Ap6cn5s6di59//jnfdY4ZMwZDhgyBRCIRxr948QItWrTAjRs3hC/0Y8eOQUtLCzNnzizU5bn8bo9SpUoV+Pv7f3JeZ2fnfINE79690bt370/OX9YVtt6lp6cXWDeAnJ7C06ZNQ8uWLVGuXDmMHz8eN27cgI6ODvz9/Qs8frVo0QITJ07E5MmTIZVK4ezsjG7duiE+Pr6YtrT0Ylj8AsX1Bf6x69evY/To0WjRogWmTJkCAHjw4AEWL16Mc+fOCZcA09LSMG/ePIwePVp4uPi7d+8wYcIEPHjwAL///ju0tbUBAAsXLkR6errQ7X7u3Lm4fv06Dt9+inE1gSVNUuARrIfGQUaooC6Dp+1bXE/SgI46H1ulLKpUqYLXr1/jw4cPwv5OTEyElpZWnk4DBflUL76jR48iKSlJaFqRW59PnDiB69evo0qVKkhKSpJbZlJSktyl6ZCQEIw7kIxmVTKxrGkyVPibQ2kUpR7duHEDqqqqcs9ZNjMzQ2xs7CfrEYA8twMxMzNDRkYGbt68icePH+e5jc7o0aPRo0cPLFiwQDh25cq9VPjx5ccLFy7A1dVVoe24qHAKW+9u3LjxybqR21M4OTkZmpqakMlkWLZsGapXr46FCxcWePwCgPHjx2PkyJF4+/Yt9PX14eHhIZyUIXEMi1+guL7Ac4WEhGDcuHFo1qwZli1bJhwEb9++jUqVKsl9IVtZWeHdu3dISUmBvr4+UlNTMWrUKDx69Ajbt2+Xa1iupqYmd3+m3F57Cc9y7gdWq4IUhzu+xMt0FVRQz8ajVFWoSGSoVl76OW8LlQBLS0uoqakhPDxcaLJw7do1WFtbF+nL8uNefLmXQD7uxbdz5065e5YtXboUADB9+nQAgK2tLTZu3AiZTCa0qw0LCxPaed27dw/jx4+HS20NLHd4BjV+jyuVotSj/fv348mTJ9i8ebMw7NatW7CysvpkPbpw4QKmT5+Oc+fOCcHvzp070NPTg42NDU6ePCm3ru+//x4+Pj5o1qwZUlNT4erqijVr1qBx48YAgISEBLx9+1YunN64cUPh7biocApb7z5VN4CcTnTdu3dH8+bNAeScYc7tKfyp49eRI0cQEREhtFVMT09HaGgoRo0aVXIbX0rwUP4FPv4A5PqcL3AAuHv3bs6XrIsLVq5cCXV1dWGckZERXr9+LXej2bi4OJQrVw6VK1dGdnY2Jk2ahPj4eOzcuTNPo+AhQ4bIXWrJzs5GdHQ0TCurIVsGuJ+thOhkNehrZUNDFTj3VBNWlT7wzKIS0dbWRo8ePTBv3jzcuHEDp06dwpYtW4T2VcXVi6969eqoVauW8Fe+fHmUL18etWrVApDTqPvNmzdYtGgRYmJisGjRIqSlpaFjx44Acu6LZmxsjJmtKuB1hgoS03L+0nmfRaVQlHrUr18/XL58Gdu3b8eDBw+wevVquYBWUD2yt7eHpqYmZs+ejbi4OJw/fx5LlizBqFGjoKWlJVfHcutWlSpVoK+vDx0dHTRq1Ai+vr64ceMGbt26BS8vL9jY2KBevXoAgA8fPuD+/fsKvZUIFV5h692n6gZQcE/hTx2/ateujb179+LkyZN48OABvLy8ULVqVbne1ZQ/hsUvUJxf4HPnzs35kp05E69fv0ZiYqIwv52dHczMzDBjxgzcu3cPoaGhWLJkCQYPHgyJRIL9+/cjJCQEPj4+qFixojBvbi+z1q1bY9u2bTh9+jTi4uLg4+ODt2/fomcDLahIAC1VGZZF6ODBW1WcitfE2ps6GGfFdmbKZubMmWjQoAGGDRuG+fPnY/LkyUKP5+LqxfcpOjo62LBhA65duwY3NzdEREQgICAA5cqVQ2JiIq5fv46YmBi02piE5oeMhL+/H2l/ctn0dRS2HjVo0AD+/v7Yv38/unXrhvPnz2Pz5s2oUqUKgILrkY6ODjZv3oxXr16hV69emDVrFvr161foMziLFy+GlZWV0H6xevXqmDhxojA+OTkZHz58+KwrOKQYxXX8+pKewg0bNsS8efPw66+/Ch1Wfvvtt3zvFELyJLL/3h26jJBKpQgPD4ednZ3Q6P9z5LYdPHnyJHR0dDBy5Eih4lpYWMDX1zdPL6qgoCD4+/vjzJkzAHJCZe4p9f/Knf/58+dYtGgRQkJCUK5cOXTv3h2TJk2Curo6Ro4cieDg4DzzOjk5YefOnZDJZNiwYQMCAwORlJQEGxsb/Pzzz6h3dhTwLAKJaSqYc6UiQhI0oK+VjfEN3qGXadpnvyefzdgWGPvP118vFRupVJrzedrQAngWoeji5GC9+uZJpVLcunULDRo0+KLjNdF/SaVSSGTZUFFT//TEX1O2FFAp+bpe2CzEsPiFYfFbpJRf6AC/1EsBpaxbrFffPKX9Qge+2pc6lQzhmHVgFJB0V9HFyWFQD+i16ausqrBZ6Jvu4JKRkYH58+fj5MmT0NLSgru7O9zd3RVdLCIiKmYqaurK9YUOfNUvdSphSXeV5weuEvqmw+LHz2V++vQpfvzxR1SrVg0dOnRQdNGIiKi48QudSCG+2bCY+1zmjRs3okGDBmjQoAHu3buH3bt3MywSERERFZNvtjd0UZ/LTERERERF982eWSzqc5n/K7dfT2ZmZpnr4CKEacMGgIoS3TJAvy4glUIq5c3Av1VKWbdYr4pOogJVJXv0jlQqVa56BbBuFZUS1itACevWV6xXuev4VF/nbzYsfulzmXO/1G7fvl38hftW1BoF1FJ0If7joxuc0zdM2eoW61XpoGz1CmDdKi2UrW595Xr1qSuy32xY/NLnMqupqQlPWinMzYiJiIiIShOZTIbs7GzhkcVivtmw+KXPZVZRUclzZpKIiIiI5H2zHVyK87nMRERERJS/bzZVfeq5zERERET05b7px/0V9FxmIiIiIvpy33RYJCIiIqKS9c1ehiYiIiKiksewSERERESiGBaJiIiISBTDIhERERGJYlgsIWvWrMGQIUOKZVkXL15Ely5dYGtri6FDh+Lx48ei0z5+/Bjnz58vlvUCQOvWrREUFPTFy5HJZFi6dCkaN24MJycnLFmypMDHC/n4+MDCwkLub9euXV9cjm+dourV7du38+wPNze3fKeVyWTYvXt3sZQRAIKCgtC6detiWx4AXL16FW3atCnWZX7rirNu5frzzz8/uUxlPWblkslkcHd3/+QyeczKn6LqVWk5Zp07dw7du3eHvb09unbtitOnTxfLcouKYVHJPX36FBMnToSbmxv279+PypUrY8KECaIP/f7pp59w48aNr1zKT9u6dSuOHDkCf39/rF69Gn/99Re2bt0qOn1sbCy8vLwQHBws/PXq1esrlrh0K2q9iomJgaWlpdz+2Lx5c77TXrlyBQsWLCjJ4n+R6OhoTJkyRXRbqXhcvnwZc+fO/eR0ynrMAnKel+vj44N///33k9PymPV1FLZelYZjVlRUFCZNmoRevXrh0KFD6N+/P6ZMmYKoqKivXhaGRSW3b98+NGzYEO7u7jA3N4evry+ePHmC0NBQRRetSHbs2AEPDw84OjqicePGmD59eoG/5GJjY2FlZQVDQ0PhT1tb+yuWuHQrar2KjY2FmZmZ3P6oVKlSvtMqcwjbu3cv+vfvD319fUUXpVTz9/fH6NGjUaNGDUUX5bMlJCRg2LBhOHPmTKEeIctjVskrSr0qDcesI0eOoHHjxhg6dChq1aqFQYMGwdnZGceOHfvqZWFYLCYxMTEYMGCAcEnv9evXcuP37duHDh06oGHDhnB2dsb8+fMhlUrx7Nkz1K9fH7du3RKmffnyJaysrPDw4UNERETA0dFRGKetrY0GDRrIPeYwl7e3N0JDQ+Hv7y+con/+/DmmTJkCJycnODs7w8fHB5mZmaLbsXfvXrRq1QoODg5Yt26d3LjU1FTMnDkTTZo0QcOGDdGhQwecOnUKALB+/Xp07dpVbvotW7Zg4MCBSEhIwLNnz/Ddd98J4xo1aoQnT57gxYsXecqQmpqKhIQE1K5dW7ScZYUy1Csg58BbmP0RHx8vPEXJwsICISEhAHIuy3Ts2BE2NjZwc3PDlStXRJeRkJCAUaNGwc7ODj179sSjR4/kxp8+fRo9evSAtbU1HB0d4enpiXfv3iE9PR0ODg44efKkMG1WVhacnZ1x6dIlAMA///yDxYsX8+b9KLm6BQD//vsvNm/ejO+//77AMijrMQsAbt26BWNjYxw4cAAVKlQocDt4zPp/ylCvgNJxzOrZsyemT5+eZ31v37795HYVN4bFYpCZmYkxY8agRo0aCAoKQvv27REYGCiMDw0NhY+PDzw9PXH8+HHMnz8f+/fvx+nTp2FsbIxGjRrhxIkTwvQnTpyApaUlatWqhcTERBgZGcmtT19fH8+fP89TjlmzZsHe3h7u7u5Ys2YNMjMzMWzYMKSlpWHnzp1YuXIlzp07hyVLluS7HRcuXMCiRYswdepUBAYGIjIyEk+ePBHGL1q0CPfv38eWLVtw5MgRODo6YtasWcjMzETnzp1x9+5d3L9/X5j+2LFj6Ny5MxITEwFAbjsMDAwAIN/tiI2NhUQiwW+//YYWLVqgW7duOHjwYIH7oDRSlnoF5OyTO3fuoGvXrmjVqhXmzp2L1NTUPNMZGxtjzZo1AIDg4GDY29sjKCgICxcuxNixY3Ho0CE0bdoUY8aMQUJCQr7rmjJlCrKzs7Fv3z6MHj0a27dvF8Y9evQIU6ZMwcCBA3Hs2DGsXLkSFy9exB9//AEtLS20bdtWbpsvXrwINTU1ODk5AQDWrVtXqC+a0q4k6xYA7NmzR3jPC6Ksxywgp+3jkiVLULly5U9uB49ZOZSlXgGl45hlZmaG+vXrC+Pu3buHS5cuoUmTJoV6D4oTw2IxuHjxIpKTkzFv3jyYmZlh0KBBaNu2rTC+XLlyWLRoEb7//nuYmJigQ4cOsLKywr179wAAnTt3xvHjx4XpPz5gpaWlQUNDQ259Ghoa+f7SrlChAtTV1VGuXDno6enhwoULSEhIgJ+fHywsLNCkSRPMnTsXe/bswbt37/LMv2/fPnTt2hU9evSAubk5fvnlF2hqagrjv/vuOyxYsACWlpaoXbs23N3dkZycjJcvX6JmzZqwsbERtuPJkye4ffs2OnTogPT0dKHcH28DgHy3Iy4uDhKJBKampggICECfPn0wZ84c/O9///vEnihdlKVeZWVl4fHjx8jKysIvv/yCRYsWISwsDD/88EOeaVVVVaGrqwsAMDQ0hIaGBnbu3IkhQ4agR48eMDU1xfTp01GvXr18G//fu3cP169fh4+PD8zNzdGpUycMGDBAGJ+dnY3Zs2ejb9++MDExQfPmzdG0aVO5bT579iwyMjIAAMePH0eHDh2gqqpauDe9jCjJulUUynrMKioes3IoS70qjcesV69eYfLkyXBwcFBI5zyGxWIQExOD2rVro1y5csIwa2tr4f8NGzZE/fr1sXr1anh4eKB9+/aIiIgQegN36NABT548wZ07d5CUlISwsDB06tQJAKCpqZnnCzwzM7NQbWFyT8PnfhAAwMHBAR8+fMhzmjx3ektLS+F1pUqV5NqG9OjRAw8ePICPjw/c3d2FD4RUKgUg/0E/duwYnJycoK+vn28wzP1/ftvRo0cPXLp0Ce7u7qhfvz6GDBmCfv36Yc+ePZ/c5tJEWeqVuro6Ll++jHXr1sHa2hrNmjXDr7/+ijNnzoj+0v5YbGwsbGxs5IbZ2dkhNjY2323W09NDtWrV8t3m2rVro0WLFli/fj08PT3RtWtXHDt2TNjmZs2aQUNDAxcuXEBWVhZOnTolbDP9v5KsW19CWY5ZRcVjVg5lqVel7ZiVlJSEYcOGQSaTYfXq1VBR+frRjWGxmPy3gay6urrw/wsXLsDNzQ1JSUlwcXHB6tWr4eDgIIyvXLkymjRpghMnTuDkyZOwtbVF1apVAQBVqlRBUlKS3LKTkpJgaGj4yTJ9/As7V+5BMvffomzHjBkzsHjxYlSsWBEDBgzAhg0b5Kbt1KkT7t69i4cPH+LEiRNCha9SpQoACJejP/5/ftshkUigp6cnN8zU1LRQH/LSRlnqlY6Ojty6zczMAKBQ+0SsHordOqmgbY6KikLnzp0RExMDR0dHLFq0SO7Aqqamhvbt2+PEiRO4ePEidHR05N4T+n8lVbe+hLIcs4qKx6z/pyz1qrQcsxISEjBo0CBkZmZix44dhWoWURIYFouBubk5Hjx4INfo9M6dO8L/9+3bh169emHBggXo06cPzMzM8OjRI7kK1qVLF5w9exbnz5+XO+1ua2uLa9euCa/T0tJw+/Zt2NrafrJcderUwYMHD5CcnCwMCw8Ph5qaGmrWrJnvdkRGRgqvU1NThYbFqampOHLkCFasWAEPDw+0a9cOKSkpAP7/g2JkZAQnJyccOHAAUVFRQtuwKlWqoFq1anLbce3aNVSrVi1PuzkAWLVqVZ4OCFFRUTA1Nf3kNpcmylKvYmJiYG9vL3cfxjt37kBNTU1oS/QxiUQi97pOnTqIiIiQGxYREYE6derkmbdevXpISUkR6t1/t/nw4cP47rvvsGzZMgwcOBA2NjZ4+PCh3DZ37doV//zzD86cOYMOHTrkKQ+VbN36EspyzCoqHrNyKEu9Ki3HrPfv32PUqFFQUVHBrl27hBMvisCwWAyaNm0KY2NjzJo1C7GxsQgKCsLff/8tjNfT08P169cRHR2Ne/fuwdvbG4mJiXKXAdu2bYsHDx4gNDRUrs1Mr169EBYWhoCAANy7dw8zZ86EiYkJnJ2d8y1LuXLl8ODBA7x8+RLNmjVDjRo1MGPGDERHR+Py5ctYuHAhunTpku+tIAYPHoxjx47hjz/+QGxsLObOnSvX3lBbWxsnT55EfHw8Lly4INyX6uPt6NKlC7Zt24ZmzZrJXUoaMGAAli5dipCQEISEhGDZsmVCDzQgpz1GbpskV1dXXLlyBZs3b8ajR4/w+++/49ChQ3B3dy/SfvnWKbJevXv3Dq9evQKQc4akVq1amDNnDu7evYurV69izpw56NOnj9w+zpV7KfvmzZvIyMjA8OHDsWvXLhw6dAj379/H0qVLERUVhd69e+eZ18zMDE2aNMFPP/2EqKgonDp1Sq6dkJ6eHqKjo3Hjxg3cv38fv/76KyIjI+W2uVGjRtDW1sbBgweLLcSUNiVZt4pKWY9Zn8JjVl6KrFel8Zi1YcMGPHr0CIsXLwaQc0UuMTGRvaG/Verq6tiwYQNSUlLQs2dP7NmzB4MGDRLGT5o0Cfr6+ujXrx9GjBgBTU1NDBgwQO7Xh46ODlq0aAE7Ozu5NjMmJiZYs2YNDhw4gN69eyM5ORlr164VPVvSp08fXLhwAaNGjYKqqqpwK4m+ffvC09MTbdq0Eb35qKOjI3x9fbFhwwb07t0blStXFtoDaWhowM/PDydOnEDnzp3x66+/Yvz48TA0NJTbju+//x5SqTTP5ZyRI0eiU6dOmDRpEqZMmYLu3bvL/RLv3bs3tmzZAgCwsbHBqlWrcPjwYXTp0gU7d+7EsmXLYG9vX5jdUWoosl5t2bJFODCqqKhg/fr10NHRwaBBgzBx4kTh4JgfCwsLNGvWDP3798f58+fRqVMnTJs2DatXr0a3bt0QGhqKLVu2CJeF/mvFihWoVKkS+vfvj+XLl8s9qWHIkCGws7PD8OHDMXDgQOHm4rdv3xamkUgk6NChA6pWrYqGDRt+xjtf+pVk3SoqZT1mfQqPWXkpsl6VxmPWiRMnkJ6ejj59+qB58+bC36JFiwr9vhQXiUxZ70ZZBvXv3x99+vT5pu/6/+DBA/To0QP//vsvypcvr+jiEEpHvSoqLy8v1KpVCx4eHoouSqlWGuoWj1nKpzTUq6JS9mOWmqILQDmPLwoLC0NsbOwXXc5RpNTUVAQHByMwMBCdO3fmQVcJlIZ6VVTh4eG4desWTp8+jSNHjii6OKVWaahbPGYpn9JQr4rqWzlmMSwqgcOHD+P06dNYsGDBN33Amj17NmrWrAk/Pz9FF4VQeupVUVy4cAFbtmzBtGnTYGJioujilFqlpW7xmKVcSku9Kopv5ZjFy9BEREREJIodXIiIiIhIFMMiEREREYliWCQiIiIiUQyLRERERCSKYZGIiIiIRDEsEhEREZEohkUiIiIiEsWwSERERESi/g8aoI2S3unmuwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(scegot_ot_times))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "offset = 0\n",
    "rects = ax.bar(x + offset, scegot_ot_times, width, label=\"scEGOT\")\n",
    "ax.bar_label(rects, padding=3)\n",
    "\n",
    "offset += width\n",
    "rects = ax.bar(x + offset, wot_ot_times, width, label=\"wot\")\n",
    "ax.bar_label(rects, padding=3)\n",
    "\n",
    "ax.set_ylabel(\"Time (s)\")\n",
    "ax.set_title(\"Compare OT time: scEGOT vs wot\")\n",
    "ax.legend()\n",
    "ax.set_xticks(\n",
    "    x + width / 2,\n",
    "    labels=[\n",
    "        f\"{scegot.day_names[i]} to {scegot.day_names[i+1]}\"\n",
    "        for i in range(len(scegot.day_names) - 1)\n",
    "    ],\n",
    ")\n",
    "fig.savefig(\"../figure/compare_ot_time.jpeg\", format=\"jpeg\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trajectorynet_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstrained\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m ax\u001b[38;5;241m.\u001b[39mbar(\n\u001b[1;32m      3\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscEGOT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrajectoryNet\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m----> 4\u001b[0m     [\u001b[38;5;28msum\u001b[39m(scegot_ot_times), \u001b[38;5;28msum\u001b[39m(wot_ot_times), trajectorynet_time],\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal time (s)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trajectorynet_time' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig, ax = plt.subplots(layout=\"constrained\")\n",
    "# ax.bar(\n",
    "#     [\"scEGOT\", \"wot\", \"TrajectoryNet\"],\n",
    "#     [sum(scegot_ot_times), sum(wot_ot_times), trajectorynet_time],\n",
    "# )\n",
    "# ax.set_ylabel(\"Total time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "rects = ax.bar(\n",
    "    [\"scEGOT\", \"wot\"],\n",
    "    [sum(scegot_ot_times), sum(wot_ot_times)],\n",
    ")\n",
    "for bar in rects:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, yval, f'{yval:.2f}', va='bottom', ha='center')\n",
    "ax.set_ylabel(\"Total time (s)\")\n",
    "ax.set_title(\"Compare OT total time: scEGOT vs wot\")\n",
    "fig.savefig(\"../figure/compare_ot_total_time.jpeg\", format=\"jpeg\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
